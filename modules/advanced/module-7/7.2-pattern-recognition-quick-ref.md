# Module 7.2 ‚Äì Wafer Map Pattern Recognition Quick Reference

## üöÄ Quick Start Commands

### Training Models

```bash
# Classical SVM (fast, interpretable)
python 7.2-pattern-recognition-pipeline.py train --approach classical --model svm --save svm_model.joblib

# Classical Random Forest (robust, feature importance)  
python 7.2-pattern-recognition-pipeline.py train --approach classical --model rf --n-estimators 200 --save rf_model.joblib

# Deep Learning CNN (high accuracy)
python 7.2-pattern-recognition-pipeline.py train --approach deep_learning --model cnn --epochs 20 --save cnn_model.joblib

# Small dataset for testing
python 7.2-pattern-recognition-pipeline.py train --dataset synthetic_wafer_small --approach classical --model svm
```

### Model Evaluation

```bash
# Evaluate saved model
python 7.2-pattern-recognition-pipeline.py evaluate --model-path svm_model.joblib --dataset synthetic_wafer

# Compare different approaches
python 7.2-pattern-recognition-pipeline.py evaluate --model-path rf_model.joblib --dataset synthetic_wafer
python 7.2-pattern-recognition-pipeline.py evaluate --model-path cnn_model.joblib --dataset synthetic_wafer
```

### Making Predictions

```bash
# Single wafer map prediction
python 7.2-pattern-recognition-pipeline.py predict --model-path svm_model.joblib --input-json '{"wafer_map": [[0,1,0],[1,1,1],[0,1,0]]}'

# From file
echo '{"wafer_map": [[0,1,0],[1,1,1],[0,1,0]]}' > wafer_input.json
python 7.2-pattern-recognition-pipeline.py predict --model-path cnn_model.joblib --input-file wafer_input.json
```

## üìä Pattern Types & Characteristics

| Pattern | Description | Typical Causes | SPC Action |
|---------|-------------|----------------|-------------|
| **Normal** | Sparse random defects | Particle contamination | Monitor baseline trends |
| **Center** | High density at wafer center | Chuck temperature, gas flow | Check center-to-edge uniformity |
| **Edge** | Defects at wafer perimeter | Edge bead removal, etch loading | Optimize edge processes |
| **Scratch** | Linear defect traces | Handling damage, robot issues | Inspect mechanical systems |
| **Ring** | Concentric/radial patterns | Vibration, non-uniform rotation | Mechanical maintenance |

## ‚öôÔ∏è Feature Engineering Cheat Sheet

### Classical Features (Total: ~1600 features)

```python
# Spatial Distribution (18 features)
radial_histogram[10]     # Defect density vs. radius  
angular_histogram[8]     # Defect density vs. angle

# Texture Analysis (5 features)
glcm_contrast           # Local variation intensity
glcm_homogeneity       # Distribution uniformity  
glcm_energy            # Pattern orderliness
glcm_correlation       # Spatial relationships
glcm_dissimilarity     # Pattern heterogeneity

# Shape Properties (6 features)  
total_area             # Total defect area
total_perimeter        # Total defect perimeter
n_components           # Number of connected regions
largest_area           # Size of biggest defect cluster
largest_perimeter      # Perimeter of biggest cluster
compactness           # Circular vs. irregular shape

# HOG Features (~1573 features)
hog_orientations[4]    # Edge direction histograms
hog_spatial_bins       # Local gradient distributions
```

### Deep Learning Features

```python
# CNN Architecture
Input: (1, H, W) single-channel wafer map
Conv1: 32 filters, 5x5 kernel
Conv2: 64 filters, 3x3 kernel  
Conv3: 128 filters, 3x3 kernel
FC: 256 ‚Üí 64 ‚Üí 5 classes
```

## üìà Manufacturing Metrics

### Standard ML Metrics
```python
metrics = {
    'roc_auc_weighted': 0.95,    # Multi-class ROC AUC
    'pr_auc_weighted': 0.92,     # Precision-Recall AUC  
    'f1_weighted': 0.88,         # Weighted F1 score
    'f1_macro': 0.85,            # Macro-averaged F1
    'accuracy': 0.89             # Overall accuracy
}
```

### Semiconductor-Specific Metrics
```python
manufacturing_metrics = {
    'pws': 0.89,                 # Prediction Within Spec (exact match)
    'estimated_loss': 12.5       # Average cost per misclassification
}
```

### Cost Matrix (Example)
```python
# Rows: True class, Columns: Predicted class
# Higher penalties for missing rare defects
cost_matrix = [
    [0, 10, 10, 10, 10],  # Normal: low cost to misclassify
    [50, 0, 15, 20, 25],  # Center: high cost to miss (FN)
    [50, 15, 0, 20, 25],  # Edge: high cost to miss
    [100, 20, 20, 0, 30], # Scratch: critical to detect  
    [75, 25, 25, 30, 0]   # Ring: moderate criticality
]
```

## üîß Model Configuration

### Classical Approach Parameters

```bash
# SVM Configuration
--C 1.0                    # Regularization strength
--model svm               # Support Vector Machine

# Random Forest Configuration  
--model rf
--n-estimators 100        # Number of trees
```

### Deep Learning Parameters

```bash
# CNN Training
--approach deep_learning
--model cnn
--epochs 20               # Training iterations
--batch-size 32          # Samples per gradient update
--learning-rate 0.001    # Optimizer step size
--no-focal-loss          # Disable focal loss (use cross-entropy)
```

### Data Configuration

```bash
# Dataset Options
--dataset synthetic_wafer        # Full dataset (600 samples, 64x64)
--dataset synthetic_wafer_small  # Fast testing (200 samples, 32x32)
```

## üè≠ Production Deployment

### Performance Requirements
- **Inference Time**: < 100ms per wafer map
- **Minimum F1-Score**: ‚â• 0.7 for production
- **Maximum False Negative Rate**: ‚â§ 0.1 for critical patterns

### Integration Pattern
```python
def fab_integration_example():
    """MES integration workflow"""
    
    # 1. Receive wafer map from inspection tool
    wafer_map = inspection_tool.get_wafer_map(wafer_id)
    
    # 2. Run pattern recognition
    result = pattern_model.predict(wafer_map)
    
    # 3. Apply business rules
    if result['pattern'] == 'Scratch' and result['confidence'] > 0.8:
        mes.hold_lot(lot_id, reason="Scratch pattern detected")
        
    elif result['pattern'] == 'Center' and result['confidence'] > 0.7:
        mes.flag_for_rework(wafer_id, reason="Center pattern")
        
    # 4. Log for SPC monitoring
    spc_system.log_pattern(wafer_id, result['pattern'], result['confidence'])
```

## üîç Model Explainability

### Classical Models (SHAP)
```python
# Feature importance analysis
import shap
explainer = shap.Explainer(classical_model)
shap_values = explainer(X_test)

# Top contributing features
shap.summary_plot(shap_values, X_test, feature_names=feature_names)
```

### Deep Learning (Grad-CAM)
```python
# Visual explanation for CNN predictions
gradcam_heatmap = generate_gradcam(cnn_model, wafer_map, predicted_class)
plt.imshow(wafer_map, alpha=0.7)
plt.imshow(gradcam_heatmap, alpha=0.3, cmap='jet')
```

## üö® Troubleshooting

### Common Issues

| Problem | Symptoms | Solution |
|---------|----------|----------|
| **Poor performance on rare classes** | Low F1 for minority patterns | Use focal loss, class weighting, SMOTE |
| **High false positive rate** | Too many normal wafers flagged | Adjust decision threshold, retrain with more data |
| **Slow inference** | > 100ms prediction time | Reduce image size, optimize feature extraction |
| **Model overfitting** | Train >> validation performance | Increase regularization, reduce model complexity |
| **Feature extraction errors** | GLCM computation fails | Check input data type, handle edge cases |

### Performance Optimization

```bash
# Fast training for development
python 7.2-pattern-recognition-pipeline.py train --dataset synthetic_wafer_small --epochs 5

# Production-ready training
python 7.2-pattern-recognition-pipeline.py train --dataset synthetic_wafer --epochs 50 --batch-size 64

# Memory-efficient inference
python 7.2-pattern-recognition-pipeline.py predict --model-path model.joblib --input-json '...' --batch-size 16
```

### Validation Checks

```python
# Model health checks
def validate_model_health(model_path, test_data):
    """Run validation checks before production deployment"""
    
    model = PatternRecognitionPipeline.load(model_path)
    
    # 1. Performance thresholds
    metrics = model.evaluate(test_data['X'], test_data['y'])
    assert metrics['f1_weighted'] >= 0.7, "F1 score too low"
    assert metrics['estimated_loss'] <= 20.0, "Cost too high"
    
    # 2. Inference speed
    start_time = time.time()
    predictions = model.predict(test_data['X'][:10])
    avg_time = (time.time() - start_time) / 10
    assert avg_time <= 0.1, "Inference too slow"
    
    # 3. Deterministic behavior
    pred1 = model.predict(test_data['X'][:5])
    pred2 = model.predict(test_data['X'][:5])
    assert np.array_equal(pred1, pred2), "Non-deterministic predictions"
    
    return True
```

## üìö Additional Resources

### Key Papers
- "Deep Learning for Semiconductor Manufacturing" (IEEE SEMI)
- "Wafer Map Pattern Recognition Using CNNs" (Journal of Manufacturing Science)
- "Explainable AI in Semiconductor Quality Control" (Nature Machine Intelligence)

### Tools & Libraries
- **Classical CV**: scikit-image, OpenCV, scikit-learn
- **Deep Learning**: PyTorch, torchvision  
- **Explainability**: SHAP, Grad-CAM
- **Manufacturing**: PyCIM, SEMI standards

### Best Practices
1. **Start Simple**: Begin with classical features, add DL if needed
2. **Validate Thoroughly**: Use hold-out test sets with real fab data
3. **Monitor Continuously**: Track model performance in production
4. **Document Everything**: Maintain model cards and decision logs
5. **Plan for Drift**: Implement retraining pipelines for new patterns

## üìû Quick Support

```bash
# Check model info
python 7.2-pattern-recognition-pipeline.py train --help

# Test installation
python -c "import torch; import cv2; import skimage; print('All dependencies OK')"

# Verify model file
python -c "from pathlib import Path; import joblib; print(joblib.load('model.joblib').keys())"
```
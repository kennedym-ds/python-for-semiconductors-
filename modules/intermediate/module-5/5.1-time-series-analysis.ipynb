{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module 5.1 \u2013 Time Series Analysis for Semiconductor Manufacturing\n",
        "\n",
        "This notebook demonstrates time series forecasting techniques for semiconductor manufacturing data using ARIMA and Seasonal ARIMA models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Configure plotting\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "sns.set_style('whitegrid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import time series modules\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "# Import our pipeline\n",
        "from time_series_pipeline import TimeSeriesPipeline, generate_semiconductor_time_series\n",
        "\n",
        "print(\"Time series libraries loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Generation and Exploration\n",
        "\n",
        "Let's generate synthetic semiconductor manufacturing time series data to demonstrate the concepts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate synthetic semiconductor time series data\n",
        "df = generate_semiconductor_time_series(n_periods=500, seed=42)\n",
        "print(f\"Generated {len(df)} time series observations\")\n",
        "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
        "print(f\"Frequency: {df.index.freq}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the complete time series\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "fig.suptitle('Semiconductor Manufacturing Time Series Data', fontsize=16)\n",
        "\n",
        "# Temperature\n",
        "axes[0,0].plot(df.index, df['temperature'], color='red', alpha=0.7)\n",
        "axes[0,0].set_title('Chamber Temperature (\u00b0C)')\n",
        "axes[0,0].set_ylabel('Temperature')\n",
        "\n",
        "# Pressure\n",
        "axes[0,1].plot(df.index, df['pressure'], color='blue', alpha=0.7)\n",
        "axes[0,1].set_title('Chamber Pressure (Torr)')\n",
        "axes[0,1].set_ylabel('Pressure')\n",
        "\n",
        "# Flow rate\n",
        "axes[1,0].plot(df.index, df['flow_rate'], color='green', alpha=0.7)\n",
        "axes[1,0].set_title('Gas Flow Rate (sccm)')\n",
        "axes[1,0].set_ylabel('Flow Rate')\n",
        "\n",
        "# Target yield\n",
        "axes[1,1].plot(df.index, df['target'], color='orange', alpha=0.7)\n",
        "axes[1,1].set_title('Yield Target (%)')\n",
        "axes[1,1].set_ylabel('Yield')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Stationarity Analysis\n",
        "\n",
        "Before fitting ARIMA models, we need to check if our time series is stationary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_stationarity(timeseries, title):\n",
        "    \"\"\"Perform ADF test and plot rolling statistics.\"\"\"\n",
        "    \n",
        "    # Rolling statistics\n",
        "    rolling_mean = timeseries.rolling(window=24).mean()  # 24-hour window\n",
        "    rolling_std = timeseries.rolling(window=24).std()\n",
        "    \n",
        "    # Plot\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    ax.plot(timeseries.index, timeseries, color='blue', label='Original', alpha=0.7)\n",
        "    ax.plot(rolling_mean.index, rolling_mean, color='red', label='Rolling Mean')\n",
        "    ax.plot(rolling_std.index, rolling_std, color='black', label='Rolling Std')\n",
        "    ax.legend(loc='best')\n",
        "    ax.set_title(f'Rolling Mean & Standard Deviation - {title}')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # ADF test\n",
        "    print(f'\\nAugmented Dickey-Fuller Test for {title}:')\n",
        "    dftest = adfuller(timeseries.dropna(), autolag='AIC')\n",
        "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
        "    for key,value in dftest[4].items():\n",
        "        dfoutput[f'Critical Value ({key})'] = value\n",
        "    print(dfoutput)\n",
        "    \n",
        "    if dftest[1] <= 0.05:\n",
        "        print(\"Result: Series is stationary\")\n",
        "    else:\n",
        "        print(\"Result: Series is non-stationary\")\n",
        "    \n",
        "    return dftest[1] <= 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check stationarity of target series\n",
        "target_series = df['target']\n",
        "is_stationary = check_stationarity(target_series, 'Yield Target')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Seasonal Decomposition\n",
        "\n",
        "Let's decompose the time series to understand its components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Seasonal decomposition\n",
        "decomposition = seasonal_decompose(target_series, model='additive', period=24)  # Daily seasonality\n",
        "\n",
        "fig, axes = plt.subplots(4, 1, figsize=(15, 12))\n",
        "fig.suptitle('Seasonal Decomposition of Yield Target', fontsize=16)\n",
        "\n",
        "decomposition.observed.plot(ax=axes[0], title='Original')\n",
        "decomposition.trend.plot(ax=axes[1], title='Trend')\n",
        "decomposition.seasonal.plot(ax=axes[2], title='Seasonal')\n",
        "decomposition.resid.plot(ax=axes[3], title='Residual')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Autocorrelation Analysis\n",
        "\n",
        "ACF and PACF plots help us determine appropriate ARIMA parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot ACF and PACF\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# ACF plot\n",
        "plot_acf(target_series.dropna(), ax=axes[0], lags=50, title='Autocorrelation Function')\n",
        "\n",
        "# PACF plot\n",
        "plot_pacf(target_series.dropna(), ax=axes[1], lags=50, title='Partial Autocorrelation Function')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Fitting and Comparison\n",
        "\n",
        "Let's fit different ARIMA models and compare their performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data for validation\n",
        "train_size = int(len(df) * 0.8)\n",
        "train_data = df.iloc[:train_size]\n",
        "test_data = df.iloc[train_size:]\n",
        "\n",
        "print(f\"Training data: {len(train_data)} observations\")\n",
        "print(f\"Test data: {len(test_data)} observations\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define models to compare\n",
        "models_to_test = [\n",
        "    {'name': 'ARIMA(1,1,1)', 'order': (1,1,1), 'seasonal_order': None},\n",
        "    {'name': 'ARIMA(2,1,2)', 'order': (2,1,2), 'seasonal_order': None},\n",
        "    {'name': 'SARIMA(1,1,1)(1,1,1,24)', 'order': (1,1,1), 'seasonal_order': (1,1,1,24)},\n",
        "    {'name': 'SARIMA(1,1,1)(0,1,1,24)', 'order': (1,1,1), 'seasonal_order': (0,1,1,24)}\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for model_config in models_to_test:\n",
        "    print(f\"\\nTraining {model_config['name']}...\")\n",
        "    \n",
        "    try:\n",
        "        # Initialize pipeline\n",
        "        pipeline = TimeSeriesPipeline(\n",
        "            model_type='sarima' if model_config['seasonal_order'] else 'arima',\n",
        "            order=model_config['order'],\n",
        "            seasonal_order=model_config['seasonal_order'],\n",
        "            auto_arima=False\n",
        "        )\n",
        "        \n",
        "        # Fit model\n",
        "        pipeline.fit(train_data, 'target')\n",
        "        \n",
        "        # Evaluate on test data\n",
        "        metrics = pipeline.evaluate(test_data, 'target', test_size=len(test_data))\n",
        "        \n",
        "        results.append({\n",
        "            'Model': model_config['name'],\n",
        "            'MAE': metrics['mae'],\n",
        "            'RMSE': metrics['rmse'],\n",
        "            'R\u00b2': metrics['r2'],\n",
        "            'MAPE': metrics['mape'],\n",
        "            'PWS': metrics['pws']\n",
        "        })\n",
        "        \n",
        "        print(f\"\u2713 {model_config['name']} - RMSE: {metrics['rmse']:.3f}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\u2717 {model_config['name']} - Failed: {str(e)}\")\n",
        "        \n",
        "# Display results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nModel Comparison Results:\")\n",
        "print(results_df.round(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Best Model Analysis and Forecasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select best model (lowest RMSE)\n",
        "if results:\n",
        "    best_model_row = results_df.loc[results_df['RMSE'].idxmin()]\n",
        "    print(f\"Best model: {best_model_row['Model']} (RMSE: {best_model_row['RMSE']:.3f})\")\n",
        "    \n",
        "    # Train best model on full training data\n",
        "    best_pipeline = TimeSeriesPipeline(\n",
        "        model_type='sarima',\n",
        "        order=(1,1,1),\n",
        "        seasonal_order=(1,1,1,24),  # Using SARIMA as it typically performs well\n",
        "        auto_arima=False\n",
        "    )\n",
        "    \n",
        "    best_pipeline.fit(train_data, 'target')\n",
        "else:\n",
        "    # Fallback to simple ARIMA\n",
        "    print(\"Using fallback ARIMA(1,1,1) model\")\n",
        "    best_pipeline = TimeSeriesPipeline(\n",
        "        model_type='arima',\n",
        "        order=(1,1,1),\n",
        "        auto_arima=False\n",
        "    )\n",
        "    best_pipeline.fit(train_data, 'target')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate forecasts\n",
        "forecast_horizon = len(test_data)\n",
        "forecast_result = best_pipeline.predict(horizon=forecast_horizon, return_conf_int=True)\n",
        "\n",
        "# Create forecast index\n",
        "forecast_index = test_data.index[:forecast_horizon]\n",
        "forecasts = pd.Series(forecast_result['forecasts'], index=forecast_index)\n",
        "lower_bound = pd.Series(forecast_result['confidence_intervals']['lower'], index=forecast_index)\n",
        "upper_bound = pd.Series(forecast_result['confidence_intervals']['upper'], index=forecast_index)\n",
        "\n",
        "print(f\"Generated {len(forecasts)} forecasts\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot forecasts vs actual\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "# Plot training data\n",
        "plt.plot(train_data.index, train_data['target'], label='Training Data', color='blue', alpha=0.7)\n",
        "\n",
        "# Plot actual test data\n",
        "plt.plot(test_data.index, test_data['target'], label='Actual', color='green', linewidth=2)\n",
        "\n",
        "# Plot forecasts\n",
        "plt.plot(forecasts.index, forecasts, label='Forecast', color='red', linewidth=2)\n",
        "\n",
        "# Plot confidence intervals\n",
        "plt.fill_between(forecasts.index, lower_bound, upper_bound, \n",
        "                color='red', alpha=0.2, label='95% Confidence Interval')\n",
        "\n",
        "plt.axvline(x=train_data.index[-1], color='black', linestyle='--', alpha=0.7, label='Train/Test Split')\n",
        "plt.title('Time Series Forecast vs Actual - Semiconductor Yield Target')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Yield (%)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Residual Diagnostics\n",
        "\n",
        "Let's analyze the model residuals to validate our assumptions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate residuals\n",
        "residuals = test_data['target'][:len(forecasts)] - forecasts\n",
        "\n",
        "# Residual analysis plots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "fig.suptitle('Residual Analysis', fontsize=16)\n",
        "\n",
        "# Residuals over time\n",
        "axes[0,0].plot(residuals.index, residuals, alpha=0.7)\n",
        "axes[0,0].axhline(y=0, color='red', linestyle='--')\n",
        "axes[0,0].set_title('Residuals Over Time')\n",
        "axes[0,0].set_ylabel('Residual')\n",
        "\n",
        "# Histogram of residuals\n",
        "axes[0,1].hist(residuals, bins=20, alpha=0.7, density=True)\n",
        "axes[0,1].set_title('Residual Distribution')\n",
        "axes[0,1].set_xlabel('Residual')\n",
        "axes[0,1].set_ylabel('Density')\n",
        "\n",
        "# Q-Q plot\n",
        "from scipy import stats\n",
        "stats.probplot(residuals, dist=\"norm\", plot=axes[1,0])\n",
        "axes[1,0].set_title('Q-Q Plot')\n",
        "\n",
        "# Residuals vs fitted\n",
        "axes[1,1].scatter(forecasts, residuals, alpha=0.7)\n",
        "axes[1,1].axhline(y=0, color='red', linestyle='--')\n",
        "axes[1,1].set_title('Residuals vs Fitted')\n",
        "axes[1,1].set_xlabel('Fitted Values')\n",
        "axes[1,1].set_ylabel('Residuals')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical tests on residuals\n",
        "from scipy.stats import jarque_bera, shapiro\n",
        "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "\n",
        "print(\"Residual Diagnostic Tests:\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Normality tests\n",
        "jb_stat, jb_pval = jarque_bera(residuals)\n",
        "print(f\"Jarque-Bera Test: statistic={jb_stat:.4f}, p-value={jb_pval:.4f}\")\n",
        "if jb_pval > 0.05:\n",
        "    print(\"\u2713 Residuals appear normally distributed\")\n",
        "else:\n",
        "    print(\"\u2717 Residuals may not be normally distributed\")\n",
        "\n",
        "# Autocorrelation test\n",
        "lb_result = acorr_ljungbox(residuals, lags=10, return_df=True)\n",
        "print(f\"\\nLjung-Box Test (lag 10): p-value={lb_result['lb_pvalue'].iloc[-1]:.4f}\")\n",
        "if lb_result['lb_pvalue'].iloc[-1] > 0.05:\n",
        "    print(\"\u2713 No significant autocorrelation in residuals\")\n",
        "else:\n",
        "    print(\"\u2717 Residuals show autocorrelation\")\n",
        "\n",
        "# Summary statistics\n",
        "print(f\"\\nResidual Summary Statistics:\")\n",
        "print(f\"Mean: {residuals.mean():.4f}\")\n",
        "print(f\"Std: {residuals.std():.4f}\")\n",
        "print(f\"Min: {residuals.min():.4f}\")\n",
        "print(f\"Max: {residuals.max():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Exogenous Variables Analysis\n",
        "\n",
        "Let's explore how including process parameters as exogenous variables affects forecast performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train model with exogenous variables\n",
        "exog_pipeline = TimeSeriesPipeline(\n",
        "    model_type='arima',\n",
        "    order=(1,1,1),\n",
        "    exog_features=['temperature', 'pressure'],\n",
        "    auto_arima=False\n",
        ")\n",
        "\n",
        "# Fit on training data\n",
        "exog_pipeline.fit(train_data, 'target')\n",
        "\n",
        "print(\"ARIMA model with exogenous variables trained successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate forecasts with exogenous variables\n",
        "# Use test data exogenous variables for forecasting\n",
        "test_exog = test_data[['temperature', 'pressure']].iloc[:forecast_horizon]\n",
        "\n",
        "exog_forecast_result = exog_pipeline.predict(\n",
        "    horizon=forecast_horizon, \n",
        "    exog_future=test_exog,\n",
        "    return_conf_int=True\n",
        ")\n",
        "\n",
        "exog_forecasts = pd.Series(exog_forecast_result['forecasts'], index=forecast_index)\n",
        "exog_lower = pd.Series(exog_forecast_result['confidence_intervals']['lower'], index=forecast_index)\n",
        "exog_upper = pd.Series(exog_forecast_result['confidence_intervals']['upper'], index=forecast_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare models with and without exogenous variables\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "# Plot actual data\n",
        "plt.plot(test_data.index, test_data['target'], label='Actual', color='green', linewidth=2)\n",
        "\n",
        "# Plot forecasts without exogenous variables\n",
        "plt.plot(forecasts.index, forecasts, label='ARIMA Forecast', color='red', linewidth=2, alpha=0.7)\n",
        "\n",
        "# Plot forecasts with exogenous variables\n",
        "plt.plot(exog_forecasts.index, exog_forecasts, label='ARIMA + Exog Forecast', \n",
        "         color='purple', linewidth=2, alpha=0.7)\n",
        "\n",
        "# Confidence intervals for exogenous model\n",
        "plt.fill_between(exog_forecasts.index, exog_lower, exog_upper, \n",
        "                color='purple', alpha=0.2, label='95% CI (Exog Model)')\n",
        "\n",
        "plt.title('Forecast Comparison: With vs Without Exogenous Variables')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Yield (%)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate and compare metrics\n",
        "actual_values = test_data['target'][:len(forecasts)]\n",
        "\n",
        "# Metrics for ARIMA without exogenous\n",
        "mae_basic = np.mean(np.abs(actual_values - forecasts))\n",
        "rmse_basic = np.sqrt(np.mean((actual_values - forecasts)**2))\n",
        "\n",
        "# Metrics for ARIMA with exogenous\n",
        "mae_exog = np.mean(np.abs(actual_values - exog_forecasts))\n",
        "rmse_exog = np.sqrt(np.mean((actual_values - exog_forecasts)**2))\n",
        "\n",
        "print(\"Model Comparison:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"ARIMA (basic):        MAE = {mae_basic:.3f}, RMSE = {rmse_basic:.3f}\")\n",
        "print(f\"ARIMA + Exogenous:    MAE = {mae_exog:.3f}, RMSE = {rmse_exog:.3f}\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "if rmse_exog < rmse_basic:\n",
        "    improvement = ((rmse_basic - rmse_exog) / rmse_basic) * 100\n",
        "    print(f\"\u2713 Exogenous variables improve RMSE by {improvement:.1f}%\")\n",
        "else:\n",
        "    degradation = ((rmse_exog - rmse_basic) / rmse_basic) * 100\n",
        "    print(f\"\u2717 Exogenous variables increase RMSE by {degradation:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Production Deployment Example\n",
        "\n",
        "Demonstrate how to save, load, and use the model in a production environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the best model\n",
        "model_path = Path('semiconductor_yield_forecast_model.joblib')\n",
        "best_pipeline.save(model_path)\n",
        "print(f\"Model saved to {model_path}\")\n",
        "\n",
        "# Load the model (simulating production environment)\n",
        "loaded_pipeline = TimeSeriesPipeline.load(model_path)\n",
        "print(\"Model loaded successfully\")\n",
        "\n",
        "# Verify the loaded model works\n",
        "test_forecast = loaded_pipeline.predict(horizon=5, return_conf_int=True)\n",
        "print(f\"\\nTest forecast (next 5 periods):\")\n",
        "for i, (pred, lower, upper) in enumerate(zip(\n",
        "    test_forecast['forecasts'],\n",
        "    test_forecast['confidence_intervals']['lower'],\n",
        "    test_forecast['confidence_intervals']['upper']\n",
        "print(f\"\\nTest forecast (next 5 periods):\")\n",
        "for i, (pred, lower, upper) in enumerate(zip(\n",
        "    test_forecast['forecasts'],\n",
        "    test_forecast['confidence_intervals']['lower'],\n",
        "    test_forecast['confidence_intervals']['upper']\n)):\n",
        "    print(f\"Period {i+1}: {pred:.2f} [{lower:.2f}, {upper:.2f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Key Insights and Recommendations\n",
        "\n",
        "Based on our analysis, here are the key takeaways for semiconductor time series forecasting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Key Insights from Time Series Analysis:\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\n1. SEASONALITY:\")\n",
        "print(\"   - Clear daily patterns in semiconductor data\")\n",
        "print(\"   - SARIMA models capture seasonality better than basic ARIMA\")\n",
        "print(\"   - Consider 24-hour cycles for hourly data\")\n",
        "\n",
        "print(\"\\n2. EXOGENOUS VARIABLES:\")\n",
        "if mae_exog < mae_basic:\n",
        "    print(\"   \u2713 Process parameters (temperature, pressure) improve forecasts\")\n",
        "    print(\"   \u2713 Include correlated process variables when available\")\n",
        "else:\n",
        "    print(\"   - Process parameters may add noise in this dataset\")\n",
        "    print(\"   - Careful selection of exogenous variables is important\")\n",
        "\n",
        "print(\"\\n3. MODEL VALIDATION:\")\n",
        "print(\"   - Always use time-ordered train/test splits\")\n",
        "print(\"   - Monitor residual autocorrelation\")\n",
        "print(\"   - Check prediction intervals for uncertainty quantification\")\n",
        "\n",
        "print(\"\\n4. PRODUCTION RECOMMENDATIONS:\")\n",
        "print(\"   - Retrain models regularly with new data\")\n",
        "print(\"   - Monitor forecast accuracy drift over time\")\n",
        "print(\"   - Implement alerts based on prediction intervals\")\n",
        "print(\"   - Consider ensemble methods for robustness\")\n",
        "\n",
        "print(\"\\n5. MANUFACTURING-SPECIFIC CONSIDERATIONS:\")\n",
        "print(\"   - Account for maintenance events and tool changes\")\n",
        "print(\"   - Consider forecast reconciliation with physical constraints\")\n",
        "print(\"   - Use PWS (Prediction Within Spec) for process control\")\n",
        "print(\"   - Integrate with existing SPC systems\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "\n",
        "1. **Data Generation**: Created realistic semiconductor time series with trends and seasonality\n",
        "2. **Stationarity Testing**: Used ADF tests to check stationarity requirements\n",
        "3. **Seasonal Decomposition**: Analyzed trend, seasonal, and residual components\n",
        "4. **Model Comparison**: Evaluated different ARIMA and SARIMA configurations\n",
        "5. **Forecasting**: Generated predictions with confidence intervals\n",
        "6. **Residual Analysis**: Validated model assumptions through diagnostic tests\n",
        "7. **Exogenous Variables**: Demonstrated incorporating process parameters\n",
        "8. **Production Workflow**: Showed model persistence and deployment patterns\n",
        "\n",
        "The techniques shown here can be applied to various semiconductor manufacturing time series problems including tool drift detection, SPC monitoring, and yield forecasting.\n",
        "\n",
        "**Next Steps**: \n",
        "- Explore more advanced models (VAR, state space models)\n",
        "- Implement real-time forecasting systems\n",
        "- Integrate with manufacturing execution systems (MES)\n",
        "- Develop automated model retraining pipelines"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}

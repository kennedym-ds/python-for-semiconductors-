# Module 5.1 – Time Series Analysis Quick Reference

## CLI Commands

### Basic Training
```bash
# Train ARIMA model on synthetic semiconductor data
python 5.1-time-series-pipeline.py train --dataset synthetic_semiconductor --model arima --save model.joblib

# Train with custom ARIMA order
python 5.1-time-series-pipeline.py train --dataset semiconductor_data --order 2,1,1 --save arima_211.joblib

# Train seasonal ARIMA model
python 5.1-time-series-pipeline.py train --dataset hourly_temp --model sarima --seasonal-order 1,1,1,24 --save sarima.joblib

# Train with exogenous variables
python 5.1-time-series-pipeline.py train --dataset process_data --exog-features temperature,pressure --save model_exog.joblib
```

### Model Evaluation  
```bash
# Evaluate model performance
python 5.1-time-series-pipeline.py evaluate --model-path model.joblib --dataset test_data

# Custom evaluation parameters
python 5.1-time-series-pipeline.py evaluate --model-path model.joblib --test-size 30 --tolerance 1.5 --cost-per-unit 2.0
```

### Forecasting
```bash
# Generate 12-period forecast
python 5.1-time-series-pipeline.py predict --model-path model.joblib --horizon 12

# Forecast with output file
python 5.1-time-series-pipeline.py predict --model-path model.joblib --horizon 24 --output forecasts.json

# Forecast with exogenous data
python 5.1-time-series-pipeline.py predict --model-path model_exog.joblib --data future_exog.csv --horizon 24
```

## Python API Usage

### Basic Pipeline
```python
from time_series_pipeline import TimeSeriesPipeline, generate_semiconductor_time_series

# Generate synthetic data
df = generate_semiconductor_time_series(n_periods=200)

# Train model
pipeline = TimeSeriesPipeline(model_type='arima', order=(1,1,1))
pipeline.fit(df, 'target')

# Make predictions
forecast = pipeline.predict(horizon=12, return_conf_int=True)
print(f"Next 12 forecasts: {forecast['forecasts']}")

# Evaluate performance
metrics = pipeline.evaluate(df, 'target', test_size=20)
print(f"RMSE: {metrics['rmse']:.3f}, PWS: {metrics['pws']:.1f}%")

# Save/load model
pipeline.save(Path('my_model.joblib'))
loaded_pipeline = TimeSeriesPipeline.load(Path('my_model.joblib'))
```

### Advanced Features
```python
# Seasonal ARIMA with exogenous variables
pipeline = TimeSeriesPipeline(
    model_type='sarima',
    order=(1,1,1),
    seasonal_order=(1,1,1,24),
    exog_features=['temperature', 'pressure']
)

# Fit with data
pipeline.fit(df, 'target')

# Predict with future exogenous data
future_exog = pd.DataFrame({
    'temperature': [450, 451, 452],
    'pressure': [2.5, 2.6, 2.4]
}, index=pd.date_range('2023-01-09 09:00:00', periods=3, freq='h'))

forecast = pipeline.predict(horizon=3, exog_future=future_exog)
```

## Model Types and Parameters

### ARIMA Models
| Model Type | Parameters | Use Case |
|------------|------------|----------|
| `arima` | `order=(p,d,q)` | Non-seasonal time series |
| `sarima` | `order=(p,d,q)`, `seasonal_order=(P,D,Q,s)` | Seasonal patterns |
| `auto_arima` | Auto-selected parameters | Automated model selection |

### Common ARIMA Orders
| Pattern | Order | Example Use Case |
|---------|-------|------------------|
| (1,0,0) | AR(1) | Stationary with immediate dependency |
| (0,1,1) | IMA(1,1) | Random walk with noise smoothing |
| (1,1,1) | ARIMA(1,1,1) | General purpose non-stationary |
| (2,1,2) | ARIMA(2,1,2) | Complex autocorrelation patterns |

### Seasonal Orders
| Frequency | Seasonal Period (s) | Example |
|-----------|---------------------|---------|
| Hourly with daily cycles | 24 | `(1,1,1,24)` |
| Daily with weekly cycles | 7 | `(1,1,1,7)` |
| Weekly with yearly cycles | 52 | `(1,1,1,52)` |
| Monthly with yearly cycles | 12 | `(1,1,1,12)` |

## Evaluation Metrics

### Standard Metrics
```python
metrics = {
    'mae': 1.23,        # Mean Absolute Error
    'rmse': 1.45,       # Root Mean Squared Error  
    'r2': 0.85,         # R-squared coefficient
    'mape': 2.1,        # Mean Absolute Percentage Error (%)
    'pws': 85.0,        # Prediction Within Spec (%)
    'estimated_loss': 15.4  # Cost-weighted error
}
```

### Manufacturing-Specific Metrics
- **PWS (Prediction Within Spec)**: Percentage of predictions within tolerance
- **Estimated Loss**: Sum of prediction errors weighted by cost per unit
- **Forecast Bias**: Mean(forecasts - actuals) to detect systematic errors

## Troubleshooting

### Common Issues and Solutions

#### 1. Non-Stationary Series Warning
**Problem**: "Series may not be stationary (ADF p-value: 0.15)"
**Solutions**:
- Increase differencing order: `order=(1,2,1)`
- Try log transformation for variance stabilization
- Use seasonal differencing: `seasonal_order=(0,1,0,24)`

#### 2. Poor Forecast Accuracy
**Problem**: High RMSE or low PWS scores
**Solutions**:
- Add exogenous variables: `exog_features=['temperature']`
- Try different model orders via grid search
- Check for outliers and missing data
- Increase training data size

#### 3. Model Fit Failures
**Problem**: "Failed to fit time series model"
**Solutions**:
- Disable auto_arima: `auto_arima=False`
- Simplify model order: `order=(1,1,1)`
- Check data quality (missing values, outliers)
- Ensure sufficient data points (>50 for ARIMA)

#### 4. Residual Autocorrelation
**Problem**: Ljung-Box test p-value < 0.05
**Solutions**:
- Increase AR order: `order=(2,1,1)`
- Add MA terms: `order=(1,1,2)`
- Include seasonal components
- Check for structural breaks

#### 5. Prediction Intervals Too Wide
**Problem**: Confidence intervals are too uncertain
**Solutions**:
- Add more training data
- Include relevant exogenous variables
- Use simpler model to reduce parameter uncertainty
- Check for forecast horizon appropriateness

### Performance Optimization

#### Speed Improvements
```python
# Disable expensive auto_arima
pipeline = TimeSeriesPipeline(auto_arima=False)

# Use simpler models for real-time applications
pipeline = TimeSeriesPipeline(order=(1,1,1))  # Simple ARIMA

# Reduce evaluation test size
metrics = pipeline.evaluate(df, test_size=10)  # Faster evaluation
```

#### Memory Efficiency
```python
# Generate smaller synthetic datasets
df = generate_semiconductor_time_series(n_periods=100)

# Save only necessary model components
pipeline.save(path)  # Optimized serialization
```

## Data Requirements

### Minimum Dataset Size
- **ARIMA**: ≥50 observations
- **Seasonal ARIMA**: ≥2 seasonal cycles (e.g., ≥48 hours for daily seasonality)
- **With exogenous variables**: ≥10 observations per parameter

### Data Quality Checklist
- [ ] Consistent time intervals (no missing timestamps)
- [ ] Reasonable missing data rate (<10%)
- [ ] Outliers identified and handled
- [ ] Sufficient history for seasonal patterns
- [ ] Exogenous variables available for forecast horizon

### Data Format Requirements
```python
# Required DataFrame structure
df = pd.DataFrame({
    'target': [95.2, 94.8, 95.1, ...],     # Target variable
    'temperature': [450.1, 450.5, ...],    # Optional exog features
    'pressure': [2.51, 2.49, ...]
}, index=pd.DatetimeIndex([...]))           # DatetimeIndex required
```

## Integration Examples

### Real-time Monitoring
```python
# Load trained model
pipeline = TimeSeriesPipeline.load('production_model.joblib')

# Generate alerts based on forecasts
forecast = pipeline.predict(horizon=1)
current_pred = forecast['forecasts'][0]
upper_limit = forecast['confidence_intervals']['upper'][0]

if upper_limit > ALARM_THRESHOLD:
    send_alert(f"Predicted value {current_pred:.2f} may exceed limit")
```

### Batch Processing
```python
# Process multiple time series
for tool_id in tool_list:
    data = load_tool_data(tool_id)
    pipeline = TimeSeriesPipeline()
    pipeline.fit(data, 'target')
    
    forecasts = pipeline.predict(horizon=24)
    save_forecasts(tool_id, forecasts)
```

### Model Comparison
```python
# Compare different model configurations
models = [
    {'order': (1,1,1), 'seasonal_order': None},
    {'order': (1,1,1), 'seasonal_order': (1,1,1,24)},
    {'order': (2,1,2), 'seasonal_order': (1,1,1,24)}
]

results = []
for config in models:
    pipeline = TimeSeriesPipeline(**config)
    pipeline.fit(train_data, 'target')
    metrics = pipeline.evaluate(test_data, 'target')
    results.append({'config': config, 'rmse': metrics['rmse']})

best_model = min(results, key=lambda x: x['rmse'])
print(f"Best configuration: {best_model['config']}")
```

## Deployment Checklist

### Model Development
- [ ] Data quality validated
- [ ] Stationarity achieved  
- [ ] Model order optimized
- [ ] Cross-validation performed
- [ ] Residuals pass diagnostic tests

### Production Readiness
- [ ] Model serialization tested
- [ ] Prediction API validated
- [ ] Performance benchmarks established
- [ ] Error handling implemented
- [ ] Monitoring framework setup

### Maintenance Plan
- [ ] Retraining schedule defined
- [ ] Performance degradation alerts
- [ ] Data drift detection
- [ ] Model versioning strategy
- [ ] Rollback procedures

---

**Related**: [5.1 Time Series Fundamentals](5.1-time-series-fundamentals.md) | [Analysis Notebook](5.1-time-series-analysis.ipynb)
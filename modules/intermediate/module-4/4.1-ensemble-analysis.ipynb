{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3448951",
   "metadata": {},
   "source": [
    "# Module 4.1: Ensemble Regression Analysis\n",
    "\n",
    "This notebook explores ensemble regression methods (Random Forest, Histogram Gradient Boosting, and optional XGBoost / LightGBM) in a semiconductor manufacturing context. We use a synthetic dataset representing engineered process signals and derived interaction features to predict a numerical target (e.g., critical dimension deviation or yield proxy).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1575160e",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook you will be able to:\n",
    "\n",
    "- Generate and inspect a synthetic regression dataset with engineered features.\n",
    "- Train and evaluate multiple ensemble regressors with a unified pipeline API.\n",
    "- Compare model performance using RMSE, MAE, and R².\n",
    "- Persist a trained model and reload it for inference.\n",
    "- Invoke the CLI pipeline (train / evaluate / predict) programmatically.\n",
    "- Interpret ensemble feature relationships and discuss manufacturing relevance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2019cf4",
   "metadata": {},
   "source": [
    "## Semiconductor Context\n",
    "\n",
    "In fabrication, predictive models help anticipate downstream parametric drift, identify process excursions, and optimize tool maintenance schedules. Ensemble regressors are strong baselines because:\n",
    "\n",
    "- They reduce variance (bagging) or bias (boosting) relative to single trees.\n",
    "- They naturally capture nonlinear interactions without explicit feature crafting.\n",
    "- They provide quick, robust performance for tabular, mixed-scale process features.\n",
    "\n",
    "We treat the synthetic dataset as a stand‑in for aggregated lot-level statistics (e.g., mean temperature offsets, pressure stability indices, spectral sensor transforms). The engineered features (`x1_x3`, `sin_x2`) mimic common manufacturing domain transformations (interaction & waveform decomposition).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6364daca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved pipeline path: C:\\Users\\Micha\\OneDrive\\Documents\\Projects\\python-for-semiconductors-\\modules\\intermediate\\module-4\\4.1-ensemble-pipeline.py\n",
      "Loaded EnsemblePipeline; optional libs -> HAS_XGB: False HAS_LGB: False\n"
     ]
    }
   ],
   "source": [
    "# Imports & Setup\n",
    "from __future__ import annotations\n",
    "import os, sys, json, subprocess, textwrap, math, runpy\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "CWD = Path(os.getcwd()).resolve()\n",
    "# If current dir is the module-4 folder, use it directly; else try to locate it.\n",
    "if CWD.name == 'module-4' and (CWD / '4.1-ensemble-pipeline.py').exists():\n",
    "    BASE_DIR = CWD\n",
    "elif (CWD / 'modules' / 'intermediate' / 'module-4' / '4.1-ensemble-pipeline.py').exists():\n",
    "    BASE_DIR = CWD / 'modules' / 'intermediate' / 'module-4'\n",
    "else:\n",
    "    # Fallback attempt: walk up a few levels\n",
    "    found = None\n",
    "    for up in [CWD] + list(CWD.parents)[:4]:\n",
    "        candidate = up / 'modules' / 'intermediate' / 'module-4' / '4.1-ensemble-pipeline.py'\n",
    "        if candidate.exists():\n",
    "            found = candidate.parent\n",
    "            break\n",
    "    if not found:\n",
    "        raise FileNotFoundError('Could not locate 4.1-ensemble-pipeline.py relative to working directory')\n",
    "    BASE_DIR = found\n",
    "\n",
    "PIPELINE_PATH = BASE_DIR / '4.1-ensemble-pipeline.py'\n",
    "print('Resolved pipeline path:', PIPELINE_PATH)\n",
    "\n",
    "ns = runpy.run_path(str(PIPELINE_PATH))\n",
    "EnsemblePipeline = ns['EnsemblePipeline']\n",
    "generate_regression_synthetic = ns['generate_regression_synthetic']\n",
    "TARGET_COLUMN = ns['TARGET_COLUMN']\n",
    "RANDOM_SEED = ns['RANDOM_SEED']\n",
    "\n",
    "sns.set_theme(context='notebook', style='whitegrid')\n",
    "np.random.seed(RANDOM_SEED)\n",
    "print('Loaded EnsemblePipeline; optional libs -> HAS_XGB:', ns.get('HAS_XGB'), 'HAS_LGB:', ns.get('HAS_LGB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e986baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Synthetic Dataset\n",
    "raw_df = generate_regression_synthetic(n=600, seed=RANDOM_SEED)\n",
    "print(\"Shape:\", raw_df.shape)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ba71fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Summary Statistics\n",
    "summary = raw_df.describe().T\n",
    "summary[['mean','std','min','max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686e0986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA: Feature Distributions & Correlation\n",
    "feature_cols = [c for c in raw_df.columns if c != TARGET_COLUMN]\n",
    "fig, axes = plt.subplots(len(feature_cols), 1, figsize=(6, 2.2*len(feature_cols)))\n",
    "for ax, col in zip(axes, feature_cols):\n",
    "    sns.histplot(raw_df[col], kde=True, ax=ax, color='#1f77b4')\n",
    "    ax.set_xlabel(col)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "corr = raw_df[feature_cols + [TARGET_COLUMN]].corr()\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(corr, cmap='coolwarm', center=0, annot=False)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2a1582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Baseline Random Forest\n",
    "from math import floor\n",
    "\n",
    "train_frac = 0.8\n",
    "cut = floor(train_frac * len(raw_df))\n",
    "train_df = raw_df.iloc[:cut].copy()\n",
    "val_df = raw_df.iloc[cut:].copy()\n",
    "\n",
    "X_train = train_df.drop(columns=[TARGET_COLUMN])\n",
    "X_val = val_df.drop(columns=[TARGET_COLUMN])\n",
    "y_train = train_df[TARGET_COLUMN].to_numpy()\n",
    "y_val = val_df[TARGET_COLUMN].to_numpy()\n",
    "\n",
    "rf_pipe = EnsemblePipeline(model='rf', n_estimators=300, max_depth=8)\n",
    "rf_pipe.fit(X_train, y_train)\n",
    "val_metrics = rf_pipe.evaluate(X_val, y_val)\n",
    "val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17f6354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Comparison Across Ensembles\n",
    "candidates = ['rf', 'hist_gb']\n",
    "if HAS_XGB:\n",
    "    candidates.append('xgb')\n",
    "if HAS_LGB:\n",
    "    candidates.append('lgbm')\n",
    "\n",
    "results = []\n",
    "for m in candidates:\n",
    "    pipe = EnsemblePipeline(model=m)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    metrics = pipe.evaluate(X_val, y_val)\n",
    "    row = {'model': m, **metrics}\n",
    "    results.append(row)\n",
    "\n",
    "comp_df = pd.DataFrame(results).sort_values('RMSE')\n",
    "comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20362363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persistence Demo (Save / Load / Predict)\n",
    "from pathlib import Path\n",
    "model_path = Path('temp_models/ensemble_rf.joblib')\n",
    "model_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "rf_pipe.save(model_path)\n",
    "reloaded = EnsemblePipeline.load(model_path)\n",
    "sample_pred = reloaded.predict(X_val.iloc[:1])[0]\n",
    "print(\"Reloaded model type:\", reloaded.metadata.model_type if reloaded.metadata else None)\n",
    "print(\"Sample prediction:\", float(sample_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb032ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLI Demonstration (Train -> Evaluate -> Predict)\n",
    "import json, subprocess, tempfile\n",
    "\n",
    "# Write a temp CSV for CLI demo\n",
    "csv_path = Path('temp_cli_train.csv')\n",
    "raw_df.to_csv(csv_path, index=False)\n",
    "model_out = Path('temp_models/cli_rf.joblib')\n",
    "\n",
    "train_cmd = [sys.executable, '4.1-ensemble-pipeline.py', 'train', '--model', 'rf', '--train', str(csv_path), '--model-out', str(model_out)]\n",
    "print('TRAIN CMD:', ' '.join(train_cmd))\n",
    "train_res = subprocess.run(train_cmd, capture_output=True, text=True, check=True)\n",
    "print('Train JSON:', train_res.stdout.strip())\n",
    "\n",
    "# Evaluate\n",
    "eval_cmd = [sys.executable, '4.1-ensemble-pipeline.py', 'evaluate', '--model-path', str(model_out), '--data', str(csv_path)]\n",
    "print('\\nEVAL CMD:', ' '.join(eval_cmd))\n",
    "eval_res = subprocess.run(eval_cmd, capture_output=True, text=True, check=True)\n",
    "print('Eval JSON:', eval_res.stdout.strip())\n",
    "\n",
    "# Predict (take first record sans target)\n",
    "record = raw_df.drop(columns=[TARGET_COLUMN]).iloc[0].to_dict()\n",
    "pred_cmd = [sys.executable, '4.1-ensemble-pipeline.py', 'predict', '--model-path', str(model_out), '--input-json', json.dumps(record)]\n",
    "print('\\nPRED CMD:', ' '.join(pred_cmd))\n",
    "pred_res = subprocess.run(pred_cmd, capture_output=True, text=True, check=True)\n",
    "print('Pred JSON:', pred_res.stdout.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06f2de3",
   "metadata": {},
   "source": [
    "### 12. Manufacturing-Oriented Metrics & Interpretation\n",
    "\n",
    "While our implemented regression metrics (MAE, RMSE, R²) describe statistical performance, semiconductor engineering decisions often require translating model error into process impact:\n",
    "\n",
    "- **Prediction Within Spec (PWS)**: Percentage of predictions whose absolute error is within an engineering tolerance band. For parametric tests (e.g., line width, film thickness) this tolerance could come from the process control plan. Example:\n",
    "  ```python\n",
    "  tolerance = 0.5  # nanometers, milliohms, etc.\n",
    "  pws = (np.abs(y_pred - y_true) <= tolerance).mean()\n",
    "  ```\n",
    "- **Estimated Loss / Cost of Error**: Map absolute error to monetary impact (scrap, rework, cycle time). A simple linear model might assume cost_per_unit * |error|; more advanced curves could be stepwise (no cost until spec boundary, then escalating).\n",
    "- **Stability / Drift Tracking**: Compare residual distributions by lot, tool, or time window to flag emerging drift.\n",
    "- **Actionability Thresholds**: Define when a prediction should trigger: (a) a re-measure, (b) an engineering review, (c) a tool maintenance event.\n",
    "\n",
    "These domain metrics are not yet coded into the pipeline but can be layered on top of predictions. Example enrichment function:\n",
    "```python\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ManufacturingEval:\n",
    "    mae: float\n",
    "    rmse: float\n",
    "    r2: float\n",
    "    pws: float\n",
    "    avg_cost: float\n",
    "\n",
    "def manufacturing_evaluate(y_true, y_pred, tolerance=0.5, cost_per_unit=2.0):\n",
    "    abs_err = np.abs(y_pred - y_true)\n",
    "    pws = (abs_err <= tolerance).mean()\n",
    "    avg_cost = (abs_err * cost_per_unit).mean()\n",
    "    return ManufacturingEval(\n",
    "        mae=float(abs_err.mean()),\n",
    "        rmse=float(np.sqrt(np.mean(abs_err**2))),\n",
    "        r2=float(1 - ((abs_err**2).sum() / ((y_true - y_true.mean())**2).sum())),\n",
    "        pws=float(pws),\n",
    "        avg_cost=float(avg_cost),\n",
    "    )\n",
    "```\n",
    "\n",
    "In a production extension of this module we would:\n",
    "1. Parameterize tolerance and cost models via a JSON/YAML config.\n",
    "2. Add these outputs to the pipeline `evaluate()` JSON.\n",
    "3. Log evaluation outputs over time for SPC-style monitoring.\n",
    "4. Couple to alerting (e.g., if PWS drops below 92%).\n",
    "\n",
    "For now, treat this section as a conceptual bridge between generic ML metrics and fab decision intelligence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042c2cd9",
   "metadata": {},
   "source": [
    "### 13. Conclusions & Next Steps\n",
    "\n",
    "**What we accomplished:**\n",
    "- Built and evaluated multiple ensemble regressors (RF, HistGB, optionally XGBoost / LightGBM).\n",
    "- Compared metrics (MAE, RMSE, R²) to choose candidates.\n",
    "- Demonstrated persistence (save/load) and CLI parity with programmatic API.\n",
    "- Outlined how to extend evaluation with manufacturing-aware KPIs (PWS, cost impact).\n",
    "\n",
    "**Key Takeaways:**\n",
    "- HistGradientBoosting is a strong default when XGBoost/LightGBM aren't installed, offering speed + accuracy.\n",
    "- Metric differences should be interpreted relative to process tolerance, not just raw absolute values.\n",
    "- A standardized CLI emitting JSON accelerates downstream automation (batch scoring, pipeline orchestration).\n",
    "\n",
    "**Recommended Extensions:**\n",
    "1. Add permutation/SHAP-based feature importance for interpretability.\n",
    "2. Introduce PWS and cost metrics directly into `evaluate()` pipeline method.\n",
    "3. Track evaluation outputs over time (lot / tool dimension) for drift signals.\n",
    "4. Integrate hyperparameter search (Optuna / randomized search) with reproducible seed control.\n",
    "5. Add residual diagnostics (QQ plot, residual vs. prediction) to probe model calibration.\n",
    "\n",
    "**Bridge to 4.2 (Unsupervised Analysis):**\n",
    "The next module (4.2) shifts from supervised yield/parameter prediction to pattern discovery and anomaly detection (clustering + isolation). You can:\n",
    "- Reuse the synthetic data generation pattern for unsupervised embeddings.\n",
    "- Combine ensemble residuals with clustering scores for hybrid monitoring.\n",
    "\n",
    "Proceed to open `4.2-unsupervised-analysis.ipynb` (to be created) and replicate the structure: data synthesis → exploratory structure → clustering / anomaly model comparison → manufacturing interpretation.\n",
    "\n",
    "> Save this notebook now so executed cell outputs (metrics tables, JSON CLI results) persist for later reference.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

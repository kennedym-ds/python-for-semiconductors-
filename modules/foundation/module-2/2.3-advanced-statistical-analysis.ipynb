{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15fad92",
   "metadata": {},
   "source": [
    "# 2.3 Advanced Statistical Analysis with ANOVA\n",
    "\n",
    "## ðŸ“š Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "- **Apply** one-way and two-way ANOVA to semiconductor manufacturing data\n",
    "- **Design** and analyze factorial experiments for process optimization\n",
    "- **Implement** Design of Experiments (DOE) principles\n",
    "- **Interpret** interaction effects and their manufacturing implications\n",
    "- **Validate** ANOVA assumptions and apply appropriate diagnostics\n",
    "- **Calculate** effect sizes and assess practical significance\n",
    "- **Perform** post-hoc comparisons with multiple testing corrections\n",
    "\n",
    "## ðŸŽ¯ What You'll Analyze\n",
    "\n",
    "Using the **SECOM dataset** and carefully designed synthetic experiments, we'll explore:\n",
    "1. **Tool comparison studies** with one-way ANOVA\n",
    "2. **Multi-factor process optimization** with two-way ANOVA and interactions\n",
    "3. **Factorial design analysis** for efficient screening\n",
    "4. **Mixed-effects modeling** for hierarchical manufacturing data\n",
    "5. **Response surface methodology** for process optimization\n",
    "\n",
    "Let's start by loading our libraries and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154caf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries for statistical analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import f_oneway, shapiro, levene, kruskal\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd, MultiComparison\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.stats.power import FTestAnovaPower\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure plotting and suppress warnings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_palette(\"Set2\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")\n",
    "print(\"ðŸ“Š Ready for advanced statistical analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c30a69e",
   "metadata": {},
   "source": [
    "## ðŸ­ Loading and Preparing Data\n",
    "\n",
    "We'll use the SECOM dataset as our foundation and create additional structured experimental data to demonstrate various ANOVA techniques. The SECOM data will serve as a base for tool comparison studies, while we'll generate factorial experimental data for DOE demonstrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8a0adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SECOM data (using the same loader from 2.2)\n",
    "def load_secom_for_anova():\n",
    "    \"\"\"Load and preprocess SECOM data for ANOVA analysis.\"\"\"\n",
    "    DATA_DIR = Path('../../datasets').resolve()\n",
    "    SECOM_DATA_FILE = DATA_DIR / 'secom.data'\n",
    "    SECOM_LABEL_FILE = DATA_DIR / 'secom_labels.data'\n",
    "    \n",
    "    if SECOM_DATA_FILE.exists() and SECOM_LABEL_FILE.exists():\n",
    "        # Load real SECOM data\n",
    "        X = pd.read_csv(SECOM_DATA_FILE, sep=\" \", header=None, na_values='NaN')\n",
    "        labels = pd.read_csv(SECOM_LABEL_FILE, sep=\" \", header=None, na_values='NaN')\n",
    "        \n",
    "        # Basic preprocessing\n",
    "        X = X.loc[:, X.notna().sum() > len(X) * 0.6]  # Keep columns with <40% missing\n",
    "        X = X.fillna(X.median())  # Median imputation\n",
    "        \n",
    "        # Select representative features for analysis\n",
    "        feature_variance = X.var()\n",
    "        top_features = feature_variance.nlargest(20).index\n",
    "        X_selected = X[top_features]\n",
    "        \n",
    "        # Add synthetic grouping variables for ANOVA\n",
    "        n_samples = len(X_selected)\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        # Create tool assignments (4 tools)\n",
    "        tool_assignments = np.random.choice(['Tool_A', 'Tool_B', 'Tool_C', 'Tool_D'], \n",
    "                                          size=n_samples, p=[0.3, 0.25, 0.25, 0.2])\n",
    "        \n",
    "        # Create lot assignments (simulate batch structure)\n",
    "        n_lots = 20\n",
    "        lot_size = n_samples // n_lots\n",
    "        lot_assignments = np.repeat(range(n_lots), lot_size)[:n_samples]\n",
    "        \n",
    "        # Create final analysis dataset\n",
    "        anova_data = pd.DataFrame({\n",
    "            'tool': tool_assignments,\n",
    "            'lot': lot_assignments,\n",
    "            'quality_flag': labels.iloc[:, 0].values[:n_samples],\n",
    "            'primary_response': X_selected.iloc[:, 0],  # Main response variable\n",
    "            'secondary_response': X_selected.iloc[:, 1]  # Secondary response\n",
    "        })\n",
    "        \n",
    "        return anova_data, X_selected\n",
    "    else:\n",
    "        # Generate synthetic data if SECOM not available\n",
    "        print(\"ðŸ”„ SECOM data not found, generating synthetic semiconductor data...\")\n",
    "        return generate_synthetic_semiconductor_data()\n",
    "\n",
    "def generate_synthetic_semiconductor_data():\n",
    "    \"\"\"Generate realistic synthetic semiconductor manufacturing data.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    n_samples = 800\n",
    "    \n",
    "    # Tool effects (different means for each tool)\n",
    "    tool_effects = {'Tool_A': 0, 'Tool_B': 2.5, 'Tool_C': -1.2, 'Tool_D': 1.8}\n",
    "    tools = list(tool_effects.keys())\n",
    "    \n",
    "    # Generate data with tool effects\n",
    "    data_list = []\n",
    "    for i, tool in enumerate(tools):\n",
    "        n_tool = n_samples // 4\n",
    "        base_response = np.random.normal(100 + tool_effects[tool], 5, n_tool)\n",
    "        \n",
    "        # Add some correlation structure\n",
    "        secondary = base_response * 0.7 + np.random.normal(0, 2, n_tool)\n",
    "        \n",
    "        tool_data = pd.DataFrame({\n",
    "            'tool': tool,\n",
    "            'lot': np.random.randint(0, 20, n_tool),\n",
    "            'quality_flag': np.random.choice([0, 1], n_tool, p=[0.93, 0.07]),\n",
    "            'primary_response': base_response,\n",
    "            'secondary_response': secondary\n",
    "        })\n",
    "        data_list.append(tool_data)\n",
    "    \n",
    "    anova_data = pd.concat(data_list, ignore_index=True)\n",
    "    \n",
    "    # Create feature matrix for consistency\n",
    "    n_features = 20\n",
    "    X_selected = pd.DataFrame(\n",
    "        np.random.normal(0, 1, (n_samples, n_features)),\n",
    "        columns=[f'feature_{i}' for i in range(n_features)]\n",
    "    )\n",
    "    \n",
    "    return anova_data, X_selected\n",
    "\n",
    "# Load the data\n",
    "data, feature_matrix = load_secom_for_anova()\n",
    "print(f\"ðŸ“¦ Data loaded: {len(data)} samples\")\n",
    "print(f\"ðŸ”§ Tools: {data['tool'].unique()}\")\n",
    "print(f\"ðŸ“Š Response variable range: {data['primary_response'].min():.2f} - {data['primary_response'].max():.2f}\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e1fe2f",
   "metadata": {},
   "source": [
    "## ðŸ“Š 1. One-Way ANOVA: Tool Comparison Study\n",
    "\n",
    "We'll start with a fundamental question in semiconductor manufacturing: **\"Do different tools produce significantly different results?\"**\n",
    "\n",
    "This is a classic one-way ANOVA application where:\n",
    "- **Factor**: Tool (categorical with 4 levels)\n",
    "- **Response**: Primary process measurement (continuous)\n",
    "- **Null Hypothesis**: All tools have the same mean response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04e36ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory data analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Box plot by tool\n",
    "sns.boxplot(data=data, x='tool', y='primary_response', ax=axes[0,0])\n",
    "axes[0,0].set_title('Response Distribution by Tool')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Histogram of overall response\n",
    "axes[0,1].hist(data['primary_response'], bins=30, alpha=0.7, edgecolor='black')\n",
    "axes[0,1].set_title('Overall Response Distribution')\n",
    "axes[0,1].set_xlabel('Primary Response')\n",
    "\n",
    "# Sample sizes by tool\n",
    "tool_counts = data['tool'].value_counts()\n",
    "axes[1,0].bar(tool_counts.index, tool_counts.values)\n",
    "axes[1,0].set_title('Sample Size by Tool')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Response vs tool (scatter with jitter)\n",
    "for i, tool in enumerate(data['tool'].unique()):\n",
    "    tool_data = data[data['tool'] == tool]\n",
    "    x_jitter = np.random.normal(i, 0.1, len(tool_data))\n",
    "    axes[1,1].scatter(x_jitter, tool_data['primary_response'], alpha=0.6, label=tool)\n",
    "\n",
    "axes[1,1].set_xticks(range(len(data['tool'].unique())))\n",
    "axes[1,1].set_xticklabels(data['tool'].unique())\n",
    "axes[1,1].set_title('Individual Observations by Tool')\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Descriptive statistics\n",
    "print(\"ðŸ“Š Descriptive Statistics by Tool:\")\n",
    "print(data.groupby('tool')['primary_response'].describe().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2d26a5",
   "metadata": {},
   "source": [
    "### Performing One-Way ANOVA\n",
    "\n",
    "We'll use multiple approaches to conduct the one-way ANOVA and verify our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4bb060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Using scipy's f_oneway\n",
    "tool_groups = [data[data['tool'] == tool]['primary_response'] for tool in data['tool'].unique()]\n",
    "f_stat_scipy, p_value_scipy = f_oneway(*tool_groups)\n",
    "\n",
    "print(\"ðŸ”¬ One-Way ANOVA Results (scipy):\")\n",
    "print(f\"F-statistic: {f_stat_scipy:.4f}\")\n",
    "print(f\"p-value: {p_value_scipy:.6f}\")\n",
    "print(f\"Significant at Î±=0.05: {'Yes' if p_value_scipy < 0.05 else 'No'}\")\n",
    "\n",
    "# Method 2: Using statsmodels (more detailed output)\n",
    "model = ols('primary_response ~ C(tool)', data=data).fit()\n",
    "anova_results = anova_lm(model, typ=2)\n",
    "\n",
    "print(\"\\nðŸ“ˆ Detailed ANOVA Table (statsmodels):\")\n",
    "print(anova_results)\n",
    "\n",
    "# Calculate effect size (eta-squared)\n",
    "ss_between = anova_results.loc['C(tool)', 'sum_sq']\n",
    "ss_total = anova_results['sum_sq'].sum()\n",
    "eta_squared = ss_between / ss_total\n",
    "\n",
    "print(f\"\\nðŸ“Š Effect Size:\")\n",
    "print(f\"Eta-squared (Î·Â²): {eta_squared:.4f}\")\n",
    "\n",
    "# Interpretation of effect size\n",
    "if eta_squared < 0.01:\n",
    "    effect_interpretation = \"Small effect\"\n",
    "elif eta_squared < 0.06:\n",
    "    effect_interpretation = \"Medium effect\"\n",
    "else:\n",
    "    effect_interpretation = \"Large effect\"\n",
    "\n",
    "print(f\"Effect size interpretation: {effect_interpretation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190c0a4e",
   "metadata": {},
   "source": [
    "### ANOVA Assumption Checking\n",
    "\n",
    "Before interpreting results, we must validate the key assumptions of ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7d52f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract residuals from the model\n",
    "residuals = model.resid\n",
    "fitted_values = model.fittedvalues\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Normality check - Q-Q plot\n",
    "from scipy.stats import probplot\n",
    "probplot(residuals, dist=\"norm\", plot=axes[0,0])\n",
    "axes[0,0].set_title(\"Q-Q Plot: Normality of Residuals\")\n",
    "\n",
    "# 2. Normality check - Histogram\n",
    "axes[0,1].hist(residuals, bins=30, alpha=0.7, edgecolor='black')\n",
    "axes[0,1].set_title(\"Histogram of Residuals\")\n",
    "axes[0,1].set_xlabel(\"Residuals\")\n",
    "\n",
    "# 3. Homoscedasticity check - Residuals vs Fitted\n",
    "axes[0,2].scatter(fitted_values, residuals, alpha=0.6)\n",
    "axes[0,2].axhline(y=0, color='red', linestyle='--')\n",
    "axes[0,2].set_title(\"Residuals vs Fitted Values\")\n",
    "axes[0,2].set_xlabel(\"Fitted Values\")\n",
    "axes[0,2].set_ylabel(\"Residuals\")\n",
    "\n",
    "# 4. Boxplot of residuals by group\n",
    "data_with_residuals = data.copy()\n",
    "data_with_residuals['residuals'] = residuals\n",
    "sns.boxplot(data=data_with_residuals, x='tool', y='residuals', ax=axes[1,0])\n",
    "axes[1,0].set_title(\"Residuals by Tool\")\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 5. Scale-Location plot\n",
    "import numpy as np\n",
    "sqrt_abs_residuals = np.sqrt(np.abs(residuals))\n",
    "axes[1,1].scatter(fitted_values, sqrt_abs_residuals, alpha=0.6)\n",
    "axes[1,1].set_title(\"Scale-Location Plot\")\n",
    "axes[1,1].set_xlabel(\"Fitted Values\")\n",
    "axes[1,1].set_ylabel(\"âˆš|Residuals|\")\n",
    "\n",
    "# 6. Independence check - Residuals vs Order\n",
    "axes[1,2].plot(residuals, alpha=0.6)\n",
    "axes[1,2].axhline(y=0, color='red', linestyle='--')\n",
    "axes[1,2].set_title(\"Residuals vs Observation Order\")\n",
    "axes[1,2].set_xlabel(\"Observation Order\")\n",
    "axes[1,2].set_ylabel(\"Residuals\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical tests for assumptions\n",
    "print(\"ðŸ” Assumption Testing:\")\n",
    "\n",
    "# Shapiro-Wilk test for normality (use sample if data is large)\n",
    "if len(residuals) > 5000:\n",
    "    sample_residuals = np.random.choice(residuals, 5000, replace=False)\n",
    "else:\n",
    "    sample_residuals = residuals\n",
    "\n",
    "shapiro_stat, shapiro_p = shapiro(sample_residuals)\n",
    "print(f\"Shapiro-Wilk normality test: W={shapiro_stat:.4f}, p={shapiro_p:.6f}\")\n",
    "\n",
    "# Levene's test for equal variances\n",
    "levene_stat, levene_p = levene(*tool_groups)\n",
    "print(f\"Levene's test for equal variances: W={levene_stat:.4f}, p={levene_p:.6f}\")\n",
    "\n",
    "# Interpretation\n",
    "print(\"\\nðŸ“ Assumption Interpretation:\")\n",
    "print(f\"Normality: {'âœ… Satisfied' if shapiro_p > 0.05 else 'âŒ Violated'} (p={shapiro_p:.6f})\")\n",
    "print(f\"Equal variances: {'âœ… Satisfied' if levene_p > 0.05 else 'âŒ Violated'} (p={levene_p:.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606af08c",
   "metadata": {},
   "source": [
    "### Post-Hoc Analysis: Which Tools Differ?\n",
    "\n",
    "When ANOVA is significant, we need post-hoc tests to identify which specific tools differ from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ac02c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tukey's HSD (Honestly Significant Difference)\n",
    "tukey_results = pairwise_tukeyhsd(data['primary_response'], data['tool'])\n",
    "print(\"ðŸŽ¯ Tukey's HSD Post-Hoc Test:\")\n",
    "print(tukey_results)\n",
    "\n",
    "# Create a more detailed comparison\n",
    "mc = MultiComparison(data['primary_response'], data['tool'])\n",
    "tukey_detailed = mc.tukeyhsd()\n",
    "\n",
    "print(\"\\nðŸ“Š Detailed Pairwise Comparisons:\")\n",
    "print(tukey_detailed.summary())\n",
    "\n",
    "# Visualize the results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Confidence intervals for differences\n",
    "tukey_detailed.plot_simultaneous(ax=ax1)\n",
    "ax1.set_title(\"Tukey HSD: Simultaneous Confidence Intervals\")\n",
    "\n",
    "# Plot 2: Tool means with confidence intervals\n",
    "tool_means = data.groupby('tool')['primary_response'].mean()\n",
    "tool_stds = data.groupby('tool')['primary_response'].std()\n",
    "tool_ns = data.groupby('tool')['primary_response'].count()\n",
    "tool_ses = tool_stds / np.sqrt(tool_ns)\n",
    "\n",
    "x_pos = range(len(tool_means))\n",
    "ax2.bar(x_pos, tool_means, yerr=tool_ses*1.96, capsize=5, alpha=0.7)\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(tool_means.index, rotation=45)\n",
    "ax2.set_title(\"Tool Means with 95% Confidence Intervals\")\n",
    "ax2.set_ylabel(\"Primary Response\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary of significant differences\n",
    "print(\"\\nðŸ” Summary of Significant Differences:\")\n",
    "pairwise_data = tukey_detailed.summary().data[1:]  # Skip header\n",
    "for row in pairwise_data:\n",
    "    group1, group2, meandiff, p_adj, lower, upper, reject = row\n",
    "    if reject:\n",
    "        print(f\"  {group1} vs {group2}: Mean difference = {meandiff:.3f}, p = {p_adj:.6f} â­\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d48e7ba",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ 2. Two-Way ANOVA: Multi-Factor Analysis\n",
    "\n",
    "Now we'll examine how two factors simultaneously affect our response. We'll create a factorial experiment examining the effects of tool and lot (representing different batches or time periods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b18249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create balanced subset for cleaner two-way ANOVA demonstration\n",
    "# Select subset with balanced design (equal observations per cell)\n",
    "lot_tool_counts = data.groupby(['lot', 'tool']).size().unstack(fill_value=0)\n",
    "print(\"ðŸ“Š Original Lot Ã— Tool Counts:\")\n",
    "print(lot_tool_counts.head())\n",
    "\n",
    "# For demonstration, let's create a more balanced dataset\n",
    "# Select lots that have reasonable representation across tools\n",
    "good_lots = lot_tool_counts[(lot_tool_counts > 5).all(axis=1)].index[:8]\n",
    "balanced_data = data[data['lot'].isin(good_lots)].copy()\n",
    "\n",
    "# Convert lot to categorical for cleaner analysis\n",
    "balanced_data['lot'] = balanced_data['lot'].astype(str)\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Balanced dataset: {len(balanced_data)} observations\")\n",
    "print(\"Tool Ã— Lot combinations:\")\n",
    "print(pd.crosstab(balanced_data['tool'], balanced_data['lot']))\n",
    "\n",
    "# Descriptive statistics\n",
    "print(\"\\nðŸ“Š Mean Response by Tool and Lot:\")\n",
    "pivot_means = balanced_data.pivot_table(values='primary_response', \n",
    "                                       index='tool', \n",
    "                                       columns='lot', \n",
    "                                       aggfunc='mean')\n",
    "print(pivot_means.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239bf194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform two-way ANOVA\n",
    "model_2way = ols('primary_response ~ C(tool) + C(lot) + C(tool):C(lot)', \n",
    "                 data=balanced_data).fit()\n",
    "\n",
    "anova_2way = anova_lm(model_2way, typ=2)\n",
    "print(\"ðŸ“Š Two-Way ANOVA Results:\")\n",
    "print(anova_2way)\n",
    "\n",
    "# Calculate effect sizes for each factor\n",
    "ss_tool = anova_2way.loc['C(tool)', 'sum_sq']\n",
    "ss_lot = anova_2way.loc['C(lot)', 'sum_sq']\n",
    "ss_interaction = anova_2way.loc['C(tool):C(lot)', 'sum_sq']\n",
    "ss_total = anova_2way['sum_sq'].sum()\n",
    "\n",
    "eta2_tool = ss_tool / ss_total\n",
    "eta2_lot = ss_lot / ss_total\n",
    "eta2_interaction = ss_interaction / ss_total\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Effect Sizes:\")\n",
    "print(f\"Tool effect (Î·Â²): {eta2_tool:.4f}\")\n",
    "print(f\"Lot effect (Î·Â²): {eta2_lot:.4f}\")\n",
    "print(f\"Interaction effect (Î·Â²): {eta2_interaction:.4f}\")\n",
    "\n",
    "# Interpretation\n",
    "print(f\"\\nðŸ” Interpretation:\")\n",
    "print(f\"Tool effect: {'Significant' if anova_2way.loc['C(tool)', 'PR(>F)'] < 0.05 else 'Not significant'}\")\n",
    "print(f\"Lot effect: {'Significant' if anova_2way.loc['C(lot)', 'PR(>F)'] < 0.05 else 'Not significant'}\")\n",
    "print(f\"Interaction: {'Significant' if anova_2way.loc['C(tool):C(lot)', 'PR(>F)'] < 0.05 else 'Not significant'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f502df46",
   "metadata": {},
   "source": [
    "### Visualizing Interactions\n",
    "\n",
    "Interaction plots help us understand how factors work together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47932fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interaction plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Tool as x-axis, separate lines for each lot\n",
    "tool_lot_means = balanced_data.groupby(['tool', 'lot'])['primary_response'].mean().unstack()\n",
    "\n",
    "for lot in tool_lot_means.columns:\n",
    "    axes[0].plot(tool_lot_means.index, tool_lot_means[lot], \n",
    "                marker='o', label=f'Lot {lot}')\n",
    "\n",
    "axes[0].set_xlabel('Tool')\n",
    "axes[0].set_ylabel('Mean Primary Response')\n",
    "axes[0].set_title('Interaction Plot: Tool Ã— Lot')\n",
    "axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Lot as x-axis, separate lines for each tool\n",
    "lot_tool_means = balanced_data.groupby(['lot', 'tool'])['primary_response'].mean().unstack()\n",
    "\n",
    "for tool in lot_tool_means.columns:\n",
    "    axes[1].plot(lot_tool_means.index, lot_tool_means[tool], \n",
    "                marker='o', label=tool)\n",
    "\n",
    "axes[1].set_xlabel('Lot')\n",
    "axes[1].set_ylabel('Mean Primary Response')\n",
    "axes[1].set_title('Interaction Plot: Lot Ã— Tool')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical interpretation of interaction\n",
    "interaction_p = anova_2way.loc['C(tool):C(lot)', 'PR(>F)']\n",
    "print(f\"ðŸ”„ Interaction Analysis:\")\n",
    "print(f\"p-value for interaction: {interaction_p:.6f}\")\n",
    "\n",
    "if interaction_p < 0.05:\n",
    "    print(\"âš ï¸  Significant interaction detected!\")\n",
    "    print(\"   The effect of tool depends on the lot (or vice versa)\")\n",
    "    print(\"   Main effects should be interpreted cautiously\")\n",
    "else:\n",
    "    print(\"âœ… No significant interaction\")\n",
    "    print(\"   Main effects can be interpreted independently\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d17adf",
   "metadata": {},
   "source": [
    "## ðŸ§ª 3. Factorial Design Analysis\n",
    "\n",
    "Let's demonstrate a proper factorial design analysis using simulated experimental data. This shows how to efficiently study multiple factors and their interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70906d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a 2^3 factorial design for process optimization\n",
    "# Factors: Temperature (Low/High), Pressure (Low/High), Flow Rate (Low/High)\n",
    "\n",
    "def generate_factorial_experiment():\n",
    "    \"\"\"Generate a 2^3 factorial design with realistic semiconductor process data.\"\"\"\n",
    "    np.random.seed(123)\n",
    "    \n",
    "    # Design matrix (2^3 = 8 runs, with replication)\n",
    "    from itertools import product\n",
    "    \n",
    "    factors = ['Temperature', 'Pressure', 'Flow_Rate']\n",
    "    levels = [['Low', 'High']] * 3\n",
    "    \n",
    "    # Create full factorial design\n",
    "    design_points = list(product(*levels))\n",
    "    \n",
    "    # Add replications (3 replicates per condition)\n",
    "    n_reps = 3\n",
    "    factorial_data = []\n",
    "    \n",
    "    for rep in range(n_reps):\n",
    "        for i, (temp, press, flow) in enumerate(design_points):\n",
    "            # Simulate realistic effects\n",
    "            # Main effects\n",
    "            temp_effect = 5 if temp == 'High' else 0\n",
    "            press_effect = 3 if press == 'High' else 0\n",
    "            flow_effect = 2 if flow == 'High' else 0\n",
    "            \n",
    "            # Interaction effects\n",
    "            temp_press_effect = 2 if (temp == 'High' and press == 'High') else 0\n",
    "            temp_flow_effect = -1 if (temp == 'High' and flow == 'High') else 0\n",
    "            \n",
    "            # Base response + effects + random error\n",
    "            response = (85 + temp_effect + press_effect + flow_effect + \n",
    "                       temp_press_effect + temp_flow_effect + \n",
    "                       np.random.normal(0, 2))\n",
    "            \n",
    "            factorial_data.append({\n",
    "                'Run': i + 1,\n",
    "                'Rep': rep + 1,\n",
    "                'Temperature': temp,\n",
    "                'Pressure': press,\n",
    "                'Flow_Rate': flow,\n",
    "                'Yield': response\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(factorial_data)\n",
    "\n",
    "factorial_df = generate_factorial_experiment()\n",
    "print(\"ðŸ§ª Factorial Design Experiment (2Â³ with 3 replicates)\")\n",
    "print(f\"Total runs: {len(factorial_df)}\")\n",
    "print(\"\\nDesign matrix:\")\n",
    "print(factorial_df.groupby(['Temperature', 'Pressure', 'Flow_Rate'])['Yield'].mean().round(2))\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst few experimental runs:\")\n",
    "print(factorial_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368853f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the factorial design\n",
    "model_factorial = ols('Yield ~ C(Temperature) * C(Pressure) * C(Flow_Rate)', \n",
    "                     data=factorial_df).fit()\n",
    "\n",
    "anova_factorial = anova_lm(model_factorial, typ=2)\n",
    "print(\"ðŸ”¬ Three-Factor Factorial ANOVA:\")\n",
    "print(anova_factorial)\n",
    "\n",
    "# Calculate effect magnitudes\n",
    "print(\"\\nðŸ“Š Effect Magnitudes:\")\n",
    "effects = {}\n",
    "\n",
    "# Extract coefficients (effects are half the coefficient values in coded designs)\n",
    "coeffs = model_factorial.params\n",
    "print(\"\\nModel Coefficients:\")\n",
    "for param, coeff in coeffs.items():\n",
    "    if param != 'Intercept':\n",
    "        effects[param] = coeff\n",
    "        significance = \"***\" if param in model_factorial.pvalues and model_factorial.pvalues[param] < 0.001 else \\\n",
    "                      \"**\" if param in model_factorial.pvalues and model_factorial.pvalues[param] < 0.01 else \\\n",
    "                      \"*\" if param in model_factorial.pvalues and model_factorial.pvalues[param] < 0.05 else \"\"\n",
    "        print(f\"{param}: {coeff:.3f} {significance}\")\n",
    "\n",
    "# Create effects plot (Pareto chart)\n",
    "effect_names = []\n",
    "effect_values = []\n",
    "effect_pvalues = []\n",
    "\n",
    "for param in model_factorial.params.index[1:]:  # Skip intercept\n",
    "    if param in model_factorial.pvalues:\n",
    "        effect_names.append(param.replace('C(', '').replace(')', '').replace('[T.High]', ''))\n",
    "        effect_values.append(abs(model_factorial.params[param]))\n",
    "        effect_pvalues.append(model_factorial.pvalues[param])\n",
    "\n",
    "# Sort by effect magnitude\n",
    "sorted_indices = np.argsort(effect_values)[::-1]\n",
    "sorted_names = [effect_names[i] for i in sorted_indices]\n",
    "sorted_values = [effect_values[i] for i in sorted_indices]\n",
    "sorted_pvalues = [effect_pvalues[i] for i in sorted_indices]\n",
    "\n",
    "# Plot effects\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "colors = ['red' if p < 0.05 else 'blue' for p in sorted_pvalues]\n",
    "bars = ax.bar(range(len(sorted_names)), sorted_values, color=colors, alpha=0.7)\n",
    "\n",
    "ax.set_xticks(range(len(sorted_names)))\n",
    "ax.set_xticklabels(sorted_names, rotation=45, ha='right')\n",
    "ax.set_ylabel('|Effect Size|')\n",
    "ax.set_title('Pareto Chart of Effects (Red = Significant)')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add significance line (arbitrary threshold for visualization)\n",
    "significance_threshold = 1.5\n",
    "ax.axhline(y=significance_threshold, color='orange', linestyle='--', \n",
    "           label=f'Practical significance threshold')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a227df4",
   "metadata": {},
   "source": [
    "## ðŸ“Š 4. Advanced Analysis: Mixed Effects and Power Analysis\n",
    "\n",
    "Let's explore more advanced topics including mixed-effects models for hierarchical data and power analysis for experiment planning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb4172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed-effects model: Tool as fixed effect, Lot as random effect\n",
    "# This accounts for the hierarchical structure where lots are random samples\n",
    "\n",
    "try:\n",
    "    import statsmodels.formula.api as smf\n",
    "    \n",
    "    # Fit mixed-effects model\n",
    "    mixed_model = smf.mixedlm(\"primary_response ~ C(tool)\", \n",
    "                            data=data, \n",
    "                            groups=data[\"lot\"]).fit()\n",
    "    \n",
    "    print(\"ðŸ—ï¸ Mixed-Effects Model Results:\")\n",
    "    print(mixed_model.summary())\n",
    "    \n",
    "    # Compare with fixed-effects ANOVA\n",
    "    print(\"\\nðŸ”„ Model Comparison:\")\n",
    "    print(f\"Fixed-effects AIC: {model.aic:.2f}\")\n",
    "    print(f\"Mixed-effects AIC: {mixed_model.aic:.2f}\")\n",
    "    print(f\"Better model: {'Mixed-effects' if mixed_model.aic < model.aic else 'Fixed-effects'}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"âš ï¸ Mixed-effects analysis requires additional packages\")\n",
    "    print(\"For production use, install: pip install statsmodels[mixed]\")\n",
    "\n",
    "# Power Analysis for Future Experiments\n",
    "print(\"\\nâš¡ Power Analysis for Experiment Planning:\")\n",
    "\n",
    "def power_analysis_anova(effect_size, n_groups=4, alpha=0.05, power=0.80):\n",
    "    \"\"\"Calculate required sample size for ANOVA.\"\"\"\n",
    "    power_calc = FTestAnovaPower()\n",
    "    \n",
    "    # Calculate required sample size\n",
    "    n_per_group = power_calc.solve_power(\n",
    "        effect_size=effect_size,\n",
    "        nobs=None,\n",
    "        alpha=alpha,\n",
    "        power=power,\n",
    "        k_groups=n_groups\n",
    "    )\n",
    "    \n",
    "    return int(np.ceil(n_per_group))\n",
    "\n",
    "# Test different scenarios\n",
    "effect_sizes = [0.1, 0.25, 0.4]  # Small, medium, large\n",
    "effect_labels = ['Small', 'Medium', 'Large']\n",
    "\n",
    "print(\"Required sample sizes per group:\")\n",
    "print(\"Effect Size | Power=0.80 | Power=0.90\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "for effect_size, label in zip(effect_sizes, effect_labels):\n",
    "    n_80 = power_analysis_anova(effect_size, power=0.80)\n",
    "    n_90 = power_analysis_anova(effect_size, power=0.90)\n",
    "    print(f\"{label:10} | {n_80:8} | {n_90:8}\")\n",
    "\n",
    "# Calculate achieved power from our current study\n",
    "observed_f = f_stat_scipy\n",
    "df_num = len(data['tool'].unique()) - 1\n",
    "df_den = len(data) - len(data['tool'].unique())\n",
    "\n",
    "# Estimate effect size from our data\n",
    "n_per_group = len(data) / len(data['tool'].unique())\n",
    "effect_size_observed = np.sqrt(eta_squared / (1 - eta_squared))\n",
    "\n",
    "power_calc = FTestAnovaPower()\n",
    "achieved_power = power_calc.solve_power(\n",
    "    effect_size=effect_size_observed,\n",
    "    nobs=n_per_group,\n",
    "    alpha=0.05,\n",
    "    power=None,\n",
    "    k_groups=len(data['tool'].unique())\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸ“Š Current Study Power Analysis:\")\n",
    "print(f\"Observed effect size: {effect_size_observed:.3f}\")\n",
    "print(f\"Achieved statistical power: {achieved_power:.3f}\")\n",
    "print(f\"Power interpretation: {'Excellent' if achieved_power > 0.9 else 'Good' if achieved_power > 0.8 else 'Moderate' if achieved_power > 0.6 else 'Low'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d0bd8d",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ 5. Process Optimization Example\n",
    "\n",
    "Let's demonstrate how to use ANOVA results for actual process optimization, including response surface methodology concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f88de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response surface analysis using factorial data\n",
    "# This shows how to move from factorial screening to optimization\n",
    "\n",
    "# Fit second-order model to factorial data (demonstration)\n",
    "# In practice, you'd use Central Composite Design or Box-Behnken\n",
    "\n",
    "# Convert categorical factors to numerical for RSM\n",
    "factorial_df_numeric = factorial_df.copy()\n",
    "factorial_df_numeric['Temp_coded'] = factorial_df_numeric['Temperature'].map({'Low': -1, 'High': 1})\n",
    "factorial_df_numeric['Press_coded'] = factorial_df_numeric['Pressure'].map({'Low': -1, 'High': 1})\n",
    "factorial_df_numeric['Flow_coded'] = factorial_df_numeric['Flow_Rate'].map({'Low': -1, 'High': 1})\n",
    "\n",
    "# Fit model with interaction terms\n",
    "rsm_model = ols('Yield ~ Temp_coded + Press_coded + Flow_coded + ' +\n",
    "                'I(Temp_coded*Press_coded) + I(Temp_coded*Flow_coded) + I(Press_coded*Flow_coded)',\n",
    "                data=factorial_df_numeric).fit()\n",
    "\n",
    "print(\"ðŸŽ¯ Response Surface Model Summary:\")\n",
    "print(rsm_model.summary())\n",
    "\n",
    "# Predict optimal conditions\n",
    "# For this linear model, optimal is at the corners\n",
    "temp_range = np.linspace(-1, 1, 10)\n",
    "press_range = np.linspace(-1, 1, 10)\n",
    "\n",
    "# Create prediction grid (fixing flow at high level)\n",
    "temp_grid, press_grid = np.meshgrid(temp_range, press_range)\n",
    "flow_fixed = 1  # High level\n",
    "\n",
    "# Predict responses\n",
    "predictions = []\n",
    "for i in range(len(temp_range)):\n",
    "    for j in range(len(press_range)):\n",
    "        pred_data = pd.DataFrame({\n",
    "            'Temp_coded': [temp_grid[j, i]],\n",
    "            'Press_coded': [press_grid[j, i]], \n",
    "            'Flow_coded': [flow_fixed]\n",
    "        })\n",
    "        pred = rsm_model.predict(pred_data)\n",
    "        predictions.append(pred[0])\n",
    "\n",
    "predictions = np.array(predictions).reshape(temp_grid.shape)\n",
    "\n",
    "# Visualize response surface\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Contour plot\n",
    "ax1 = fig.add_subplot(131)\n",
    "contour = ax1.contour(temp_grid, press_grid, predictions, levels=10)\n",
    "ax1.clabel(contour, inline=True, fontsize=8)\n",
    "ax1.set_xlabel('Temperature (coded)')\n",
    "ax1.set_ylabel('Pressure (coded)')\n",
    "ax1.set_title('Response Contours (Flow = High)')\n",
    "\n",
    "# 3D surface plot\n",
    "ax2 = fig.add_subplot(132, projection='3d')\n",
    "surf = ax2.plot_surface(temp_grid, press_grid, predictions, alpha=0.7, cmap='viridis')\n",
    "ax2.set_xlabel('Temperature')\n",
    "ax2.set_ylabel('Pressure')\n",
    "ax2.set_zlabel('Yield')\n",
    "ax2.set_title('Response Surface')\n",
    "\n",
    "# Optimization recommendations\n",
    "ax3 = fig.add_subplot(133)\n",
    "im = ax3.imshow(predictions, extent=[-1, 1, -1, 1], origin='lower', cmap='RdYlGn')\n",
    "ax3.set_xlabel('Temperature (coded)')\n",
    "ax3.set_ylabel('Pressure (coded)')\n",
    "ax3.set_title('Optimization Heatmap')\n",
    "plt.colorbar(im, ax=ax3, label='Predicted Yield')\n",
    "\n",
    "# Mark optimal point\n",
    "max_idx = np.unravel_index(np.argmax(predictions), predictions.shape)\n",
    "optimal_temp = temp_grid[max_idx]\n",
    "optimal_press = press_grid[max_idx]\n",
    "ax3.plot(optimal_temp, optimal_press, 'r*', markersize=15, label='Optimum')\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print optimization results\n",
    "max_yield = np.max(predictions)\n",
    "print(f\"\\nðŸŽ¯ Optimization Results:\")\n",
    "print(f\"Predicted maximum yield: {max_yield:.2f}\")\n",
    "print(f\"Optimal temperature (coded): {optimal_temp:.2f}\")\n",
    "print(f\"Optimal pressure (coded): {optimal_press:.2f}\")\n",
    "print(f\"Optimal flow rate (coded): {flow_fixed}\")\n",
    "\n",
    "# Translate back to actual units (example)\n",
    "print(f\"\\nðŸ”§ Recommended Process Conditions:\")\n",
    "temp_actual = \"High\" if optimal_temp > 0 else \"Low\"\n",
    "press_actual = \"High\" if optimal_press > 0 else \"Low\"\n",
    "flow_actual = \"High\"\n",
    "print(f\"Temperature: {temp_actual}\")\n",
    "print(f\"Pressure: {press_actual}\")\n",
    "print(f\"Flow Rate: {flow_actual}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e73e51",
   "metadata": {},
   "source": [
    "## âœ… Summary and Manufacturing Insights\n",
    "\n",
    "### Key Findings from Our Analysis\n",
    "\n",
    "**Tool Comparison (One-Way ANOVA):**\n",
    "- Significant differences between tools detected\n",
    "- Effect size indicates practical importance\n",
    "- Post-hoc tests identify specific tool pairs that differ\n",
    "- Recommendations for tool matching or calibration\n",
    "\n",
    "**Multi-Factor Analysis (Two-Way ANOVA):**\n",
    "- Both tool and lot effects contribute to variation\n",
    "- Interaction effects show how factors work together\n",
    "- Hierarchical structure requires mixed-effects modeling\n",
    "\n",
    "**Factorial Design:**\n",
    "- Efficient screening of multiple factors\n",
    "- Interaction effects revealed optimization opportunities\n",
    "- Statistical significance vs. practical importance\n",
    "\n",
    "**Process Optimization:**\n",
    "- Response surface methodology guides improvement\n",
    "- Optimal conditions identified through systematic experimentation\n",
    "- Cost-benefit analysis of process changes\n",
    "\n",
    "### ðŸš€ Best Practices for Manufacturing ANOVA\n",
    "\n",
    "1. **Design Planning:**\n",
    "   - Power analysis before experiments\n",
    "   - Balanced designs when possible\n",
    "   - Control for known sources of variation\n",
    "\n",
    "2. **Assumption Validation:**\n",
    "   - Always check normality, homoscedasticity, independence\n",
    "   - Use robust alternatives when assumptions violated\n",
    "   - Consider transformations for non-normal data\n",
    "\n",
    "3. **Effect Size Reporting:**\n",
    "   - Statistical significance â‰  practical importance\n",
    "   - Report confidence intervals, not just p-values\n",
    "   - Consider engineering tolerances and costs\n",
    "\n",
    "4. **Multiple Comparisons:**\n",
    "   - Control family-wise error rate\n",
    "   - Use appropriate post-hoc procedures\n",
    "   - Consider practical significance thresholds\n",
    "\n",
    "### ðŸ”œ Next Steps (Module 3.1)\n",
    "\n",
    "In the next module, we'll extend these statistical foundations to **regression analysis for process engineers**, where we'll build predictive models and explore relationships between continuous variables.\n",
    "\n",
    "### ðŸ“š Additional Exercises\n",
    "\n",
    "1. **Robustness Testing:** Apply Kruskal-Wallis test when normality is violated\n",
    "2. **Sample Size Planning:** Calculate required samples for detecting 10% differences\n",
    "3. **Cost Analysis:** Incorporate economic factors into optimization decisions\n",
    "4. **Temporal Analysis:** Add time trends to mixed-effects models\n",
    "5. **Multiple Responses:** Extend to MANOVA for multiple quality characteristics"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# Data Quality Quick Reference Guide

**Module 2.1 - Data Quality Analysis for Semiconductor Manufacturing**

## Six Dimensions of Data Quality

### üéØ 1. Completeness
**What**: Extent to which data is present and not missing
```python
# Check missing data
missing_pct = (df.isnull().sum() / len(df)) * 100
overall_completeness = 100 - (df.isnull().sum().sum() / df.size) * 100
```

**Thresholds**:
- ‚úÖ Excellent: >95% complete
- ‚ö†Ô∏è Acceptable: 90-95% complete  
- ‚ùå Poor: <90% complete

---

### üîç 2. Accuracy
**What**: How well data represents the true real-world values
```python
# Outlier detection with IQR
Q1, Q3 = df[col].quantile([0.25, 0.75])
IQR = Q3 - Q1
outliers = (df[col] < Q1 - 1.5*IQR) | (df[col] > Q3 + 1.5*IQR)

# Z-score method
from scipy import stats
z_scores = np.abs(stats.zscore(df[col]))
outliers_zscore = z_scores > 3
```

**Thresholds**:
- ‚úÖ Good: <5% outliers
- ‚ö†Ô∏è Moderate: 5-10% outliers
- ‚ùå Poor: >10% outliers

---

### üîÑ 3. Consistency
**What**: Data follows uniform formats and scales across the dataset
```python
# Check scale consistency
ranges = df.std()
scale_ratio = ranges.max() / ranges.min()

# Correlation analysis
corr_matrix = df.corr().abs()
high_corr = corr_matrix > 0.95
```

**Warning Signs**:
- Scale ratios >100x
- High correlations (>0.95)
- Mixed data types for similar measures

---

### ‚úÖ 4. Validity
**What**: Data conforms to defined formats and business rules
```python
# Check finite values
finite_pct = np.isfinite(df.select_dtypes(include=[np.number])).sum().sum()

# Domain-specific checks
temp_columns = [col for col in df.columns if 'temp' in col.lower()]
valid_temps = df[temp_columns] > -273.15  # Above absolute zero
```

**Common Checks**:
- Finite values (no inf/-inf)
- Physical constraints (e.g., temperature > absolute zero)
- Format validation (e.g., sensor naming conventions)

---

### üé≤ 5. Uniqueness
**What**: Data records are distinct and not duplicated
```python
# Duplicate analysis
duplicate_count = df.duplicated().sum()
duplicate_rate = (duplicate_count / len(df)) * 100

# Column uniqueness
uniqueness_ratio = df.nunique() / df.count()
```

**Thresholds**:
- ‚úÖ Good: <1% duplicates
- ‚ö†Ô∏è Moderate: 1-5% duplicates
- ‚ùå Poor: >5% duplicates

---

### ‚è∞ 6. Timeliness
**What**: Data is current and available when needed
```python
# Find timestamp columns
timestamp_cols = [col for col in df.columns 
                 if 'time' in col.lower() or 'date' in col.lower()]

# Temporal analysis
if timestamp_cols:
    ts = pd.to_datetime(df[timestamp_cols[0]])
    span_days = (ts.max() - ts.min()).days
```

---

## Quick Assessment Workflow

### 1. Load and Inspect
```python
import pandas as pd
import numpy as np
from scipy import stats

# Load data
df = pd.read_csv('your_data.csv')
print(f"Shape: {df.shape}")
print(f"Memory: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
```

### 2. Completeness Check
```python
# Missing data overview
missing_summary = {
    'total_missing': df.isnull().sum().sum(),
    'missing_pct': (df.isnull().sum().sum() / df.size) * 100,
    'cols_with_missing': (df.isnull().sum() > 0).sum(),
    'worst_columns': df.isnull().sum().sort_values(ascending=False).head()
}
print(missing_summary)
```

### 3. Accuracy Check
```python
# Quick outlier detection
numeric_cols = df.select_dtypes(include=[np.number]).columns
outlier_summary = {}

for col in numeric_cols:
    if df[col].notna().sum() > 0:
        Q1, Q3 = df[col].quantile([0.25, 0.75])
        IQR = Q3 - Q1
        outliers = ((df[col] < Q1 - 1.5*IQR) | (df[col] > Q3 + 1.5*IQR)).sum()
        outlier_summary[col] = (outliers / df[col].notna().sum()) * 100

# Show top outlier columns
sorted_outliers = sorted(outlier_summary.items(), key=lambda x: x[1], reverse=True)
print("Top outlier columns:", sorted_outliers[:5])
```

### 4. Consistency Check
```python
# Scale analysis
scales = df[numeric_cols].std()
print(f"Scale ratio: {scales.max() / scales.min():.1f}")

# High correlation check
corr_matrix = df[numeric_cols].corr().abs()
np.fill_diagonal(corr_matrix.values, 0)
high_corr_pairs = []
for i in range(len(corr_matrix.columns)):
    for j in range(i+1, len(corr_matrix.columns)):
        if corr_matrix.iloc[i, j] > 0.95:
            high_corr_pairs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))

print(f"High correlation pairs: {len(high_corr_pairs)}")
```

### 5. Quick Quality Score
```python
def quick_quality_score(df):
    # Completeness (30%)
    completeness = ((df.size - df.isnull().sum().sum()) / df.size) * 100
    
    # Accuracy (30%) - based on outlier rate
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    total_outliers = 0
    total_values = 0
    
    for col in numeric_cols:
        if df[col].notna().sum() > 0:
            Q1, Q3 = df[col].quantile([0.25, 0.75])
            IQR = Q3 - Q1
            outliers = ((df[col] < Q1 - 1.5*IQR) | (df[col] > Q3 + 1.5*IQR)).sum()
            total_outliers += outliers
            total_values += df[col].notna().sum()
    
    accuracy = 100 - (total_outliers / total_values * 100) if total_values > 0 else 100
    
    # Validity (20%) - finite values
    validity = (np.isfinite(df[numeric_cols]).sum().sum() / df[numeric_cols].size) * 100 if len(numeric_cols) > 0 else 100
    
    # Uniqueness (20%) - duplicate rate
    uniqueness = 100 - (df.duplicated().sum() / len(df) * 100)
    
    # Weighted score
    score = (completeness * 0.3 + accuracy * 0.3 + validity * 0.2 + uniqueness * 0.2)
    return min(max(score, 0), 100)

quality_score = quick_quality_score(df)
print(f"Quick Quality Score: {quality_score:.1f}/100")
```

---

## Production Framework Usage

### Import and Initialize
```python
from data_quality_framework import DataQualityFramework

# Initialize with custom thresholds
config = {
    'thresholds': {
        'completeness_critical': 95.0,
        'outlier_rate_warning': 5.0,
        'correlation_threshold': 0.95
    }
}

dq = DataQualityFramework(config)
```

### Load Data and Assess
```python
# Load data
dq.load_data('secom_data.csv', target_column='Pass/Fail')

# Full assessment
report = dq.assess_all_dimensions()

print(f"Overall Score: {report.overall_score:.1f}")
print(f"Recommendations: {len(report.recommendations)}")
```

### Export Results
```python
# Export report
dq.export_report('quality_report.json', format='json')
dq.export_report('quality_report.html', format='html')

# Generate visualizations
figures = dq.create_visualizations('quality_plots/')
```

---

## Command Line Usage

```bash
# Basic assessment
python 2.1-data-quality-framework.py --input data.csv --output report

# With configuration
python 2.1-data-quality-framework.py --input data.csv --config config.yaml --visualize

# HTML report with visualizations
python 2.1-data-quality-framework.py --input data.csv --output report --format html --visualize
```

---

## Common Issues & Solutions

### üö® High Missing Data Rate
**Problem**: >10% missing values
**Solutions**:
- Check sensor calibration
- Implement missing data imputation
- Consider removing columns with >50% missing

### üö® Excessive Outliers
**Problem**: >5% outlier rate
**Solutions**:
- Investigate process anomalies
- Review sensor accuracy
- Implement outlier handling procedures

### üö® Scale Inconsistency
**Problem**: Feature scales vary by >100x
**Solutions**:
- Apply StandardScaler or MinMaxScaler
- Review measurement units
- Normalize features before analysis

### üö® High Correlation
**Problem**: Features with >95% correlation
**Solutions**:
- Remove redundant features
- Apply PCA for dimensionality reduction
- Review sensor placement

---

## Key Metrics Targets

| Dimension | Excellent | Good | Acceptable | Poor |
|-----------|-----------|------|------------|------|
| Completeness | >95% | 90-95% | 80-90% | <80% |
| Accuracy (Outliers) | <2% | 2-5% | 5-10% | >10% |
| Uniqueness (Duplicates) | <0.5% | 0.5-1% | 1-5% | >5% |
| Validity (Finite Values) | >99% | 95-99% | 90-95% | <90% |

---

**üí° Pro Tips**:
- Always assess data quality before analysis
- Document quality issues and remediation steps
- Set up automated quality monitoring for production
- Quality thresholds should be domain-specific
- Regular quality assessments prevent model degradation

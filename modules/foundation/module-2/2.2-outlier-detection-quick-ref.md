# 2.2 Outlier Detection Quick Reference

## 🚀 Quick Start

### Essential Imports

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.ensemble import IsolationForest
from sklearn.svm import OneClassSVM
from sklearn.neighbors import LocalOutlierFactor
from sklearn.preprocessing import StandardScaler
```

### Load Sample Data

```python
# Load semiconductor dataset
data = pd.read_csv('secom_data.csv')
# Remove missing values for demo
data_clean = data.dropna()
```

## 📊 Statistical Methods

### 1. Z-Score Detection

```python
# Basic Z-score
z_scores = np.abs(stats.zscore(data_clean))
outliers = (z_scores > 3).any(axis=1)

# For single column
outliers_single = np.abs(stats.zscore(data_clean['sensor_001'])) > 3
```

### 2. Modified Z-Score (Robust)

```python
def modified_zscore(data, threshold=3.5):
    median = np.median(data)
    mad = np.median(np.abs(data - median))
    modified_z = 0.6745 * (data - median) / mad
    return np.abs(modified_z) > threshold

outliers = modified_zscore(data_clean['sensor_001'])
```

### 3. IQR Method

```python
def iqr_outliers(data, k=1.5):
    Q1 = data.quantile(0.25)
    Q3 = data.quantile(0.75)
    IQR = Q3 - Q1
    return (data < Q1 - k*IQR) | (data > Q3 + k*IQR)

outliers = iqr_outliers(data_clean['sensor_001'])
```

### 4. Mahalanobis Distance

```python
from scipy.spatial.distance import mahalanobis

def mahalanobis_outliers(data, threshold_percentile=95):
    mean = data.mean().values
    cov = data.cov().values
    inv_cov = np.linalg.pinv(cov)

    distances = []
    for _, row in data.iterrows():
        dist = mahalanobis(row.values, mean, inv_cov)
        distances.append(dist)

    threshold = np.percentile(distances, threshold_percentile)
    return np.array(distances) > threshold

outliers = mahalanobis_outliers(data_clean[['sensor_001', 'sensor_002']])
```

## 🤖 Machine Learning Methods

### 1. Isolation Forest

```python
# Basic usage
iso_forest = IsolationForest(contamination=0.1, random_state=42)
outliers = iso_forest.fit_predict(data_clean) == -1

# With scores
scores = iso_forest.decision_function(data_clean)
```

### 2. One-Class SVM

```python
# Scale data first
scaler = StandardScaler()
data_scaled = scaler.fit_transform(data_clean)

# Apply One-Class SVM
oc_svm = OneClassSVM(nu=0.1, kernel='rbf')
outliers = oc_svm.fit_predict(data_scaled) == -1
```

### 3. Local Outlier Factor

```python
# Apply LOF
lof = LocalOutlierFactor(n_neighbors=20, contamination=0.1)
outliers = lof.fit_predict(data_clean) == -1

# Get scores
scores = lof.negative_outlier_factor_
```

## ⏱️ Time Series Methods

### 1. EWMA Control Chart

```python
def ewma_outliers(data, lambda_param=0.2, L=3.0):
    n = len(data)
    ewma = np.zeros(n)
    ewma[0] = data[0]

    for t in range(1, n):
        ewma[t] = lambda_param * data[t] + (1 - lambda_param) * ewma[t-1]

    mean_data = np.mean(data)
    std_data = np.std(data)
    variance_factor = lambda_param / (2 - lambda_param)

    ucl = mean_data + L * std_data * np.sqrt(variance_factor)
    lcl = mean_data - L * std_data * np.sqrt(variance_factor)

    return (ewma > ucl) | (ewma < lcl)

outliers = ewma_outliers(data_clean['sensor_001'])
```

### 2. CUSUM Control Chart

```python
def cusum_outliers(data, h=5, k=0.5):
    target_mean = np.mean(data)
    std_dev = np.std(data)
    standardized = (data - target_mean) / std_dev

    n = len(data)
    c_plus = np.zeros(n)
    c_minus = np.zeros(n)

    for i in range(1, n):
        c_plus[i] = max(0, c_plus[i-1] + standardized.iloc[i] - k)
        c_minus[i] = min(0, c_minus[i-1] + standardized.iloc[i] + k)

    return (c_plus > h) | (c_minus < -h)

outliers = cusum_outliers(data_clean['sensor_001'])
```

## 🏭 Manufacturing-Specific Methods

### 1. Recipe-Aware Detection

```python
def recipe_aware_outliers(data, recipe_col, method='isolation_forest'):
    outliers = np.zeros(len(data), dtype=bool)

    for recipe in data[recipe_col].unique():
        if pd.isna(recipe):
            continue

        mask = data[recipe_col] == recipe
        recipe_data = data[mask].drop(columns=[recipe_col])

        if method == 'isolation_forest':
            iso_forest = IsolationForest(contamination=0.1)
            recipe_outliers = iso_forest.fit_predict(recipe_data) == -1
        elif method == 'zscore':
            z_scores = np.abs(stats.zscore(recipe_data))
            recipe_outliers = (z_scores > 3).any(axis=1)

        outliers[mask] = recipe_outliers

    return outliers

# Usage
outliers = recipe_aware_outliers(data, 'recipe_type')
```

### 2. Physics-Based Validation

```python
def physics_validation(data, statistical_outliers):
    """Validate outliers using process physics"""
    validated = statistical_outliers.copy()

    # Example: Temperature-Pressure relationship
    if 'temperature' in data.columns and 'pressure' in data.columns:
        # High temp should correlate with high pressure
        temp_high = data['temperature'] > data['temperature'].quantile(0.9)
        pressure_low = data['pressure'] < data['pressure'].quantile(0.1)
        physics_outliers = temp_high & pressure_low
        validated = validated | physics_outliers

    return validated

validated_outliers = physics_validation(data_clean, statistical_outliers)
```

## 📊 Visualization Quick Plots

### 1. Outlier Scatter Plot

```python
def plot_outliers_2d(data, outliers, x_col, y_col):
    plt.figure(figsize=(10, 6))

    # Normal points
    plt.scatter(data[~outliers][x_col], data[~outliers][y_col],
               alpha=0.6, label='Normal', s=20)

    # Outliers
    plt.scatter(data[outliers][x_col], data[outliers][y_col],
               color='red', alpha=0.8, label='Outliers', s=40)

    plt.xlabel(x_col)
    plt.ylabel(y_col)
    plt.legend()
    plt.title('Outlier Detection Results')
    plt.show()

plot_outliers_2d(data_clean, outliers, 'sensor_001', 'sensor_002')
```

### 2. Time Series Outlier Plot

```python
def plot_time_series_outliers(data, outliers, time_col=None):
    plt.figure(figsize=(12, 6))

    if time_col:
        x = data[time_col]
    else:
        x = range(len(data))

    plt.plot(x, data, 'b-', alpha=0.7, label='Data')
    plt.scatter(x[outliers], data[outliers],
               color='red', s=50, label='Outliers', zorder=5)

    plt.xlabel('Time' if time_col else 'Index')
    plt.ylabel('Value')
    plt.legend()
    plt.title('Time Series Outlier Detection')
    plt.show()

plot_time_series_outliers(data_clean['sensor_001'], outliers)
```

### 3. Outlier Score Distribution

```python
def plot_outlier_scores(scores, outliers, method_name):
    plt.figure(figsize=(10, 6))

    plt.hist(scores[~outliers], bins=50, alpha=0.7,
             label='Normal', density=True)
    plt.hist(scores[outliers], bins=50, alpha=0.7,
             label='Outliers', density=True)

    plt.xlabel('Outlier Score')
    plt.ylabel('Density')
    plt.legend()
    plt.title(f'{method_name} Score Distribution')
    plt.show()

# Usage with Isolation Forest
iso_forest = IsolationForest(contamination=0.1)
outliers = iso_forest.fit_predict(data_clean) == -1
scores = iso_forest.decision_function(data_clean)
plot_outlier_scores(scores, outliers, 'Isolation Forest')
```

## 🎯 Method Comparison

### Quick Comparison Function

```python
def compare_methods(data, methods=['zscore', 'iqr', 'isolation_forest']):
    results = {}

    for method in methods:
        if method == 'zscore':
            z_scores = np.abs(stats.zscore(data))
            outliers = (z_scores > 3).any(axis=1)
        elif method == 'iqr':
            outliers = np.zeros(len(data), dtype=bool)
            for col in data.columns:
                col_outliers = iqr_outliers(data[col])
                outliers = outliers | col_outliers
        elif method == 'isolation_forest':
            iso_forest = IsolationForest(contamination=0.1)
            outliers = iso_forest.fit_predict(data) == -1
        elif method == 'lof':
            lof = LocalOutlierFactor(contamination=0.1)
            outliers = lof.fit_predict(data) == -1

        results[method] = {
            'outliers': outliers,
            'count': outliers.sum(),
            'percentage': outliers.sum() / len(data) * 100
        }

    return results

# Compare methods
comparison = compare_methods(data_clean)
for method, result in comparison.items():
    print(f"{method}: {result['count']} outliers ({result['percentage']:.2f}%)")
```

### Consensus Outlier Detection

```python
def consensus_outliers(data, methods=['zscore', 'iqr', 'isolation_forest'],
                      threshold=0.5):
    """Find outliers that multiple methods agree on"""
    comparison = compare_methods(data, methods)

    # Create voting matrix
    n_points = len(data)
    votes = np.zeros(n_points)

    for method, result in comparison.items():
        votes += result['outliers'].astype(int)

    # Consensus based on threshold
    consensus_threshold = len(methods) * threshold
    consensus_outliers = votes >= consensus_threshold

    return consensus_outliers, votes

outliers, votes = consensus_outliers(data_clean)
print(f"Consensus outliers: {outliers.sum()}")
```

## 🔧 Performance Tips

### 1. Memory Efficient Processing

```python
# For large datasets, process in chunks
def detect_outliers_chunked(data, chunk_size=1000, method='isolation_forest'):
    outliers = []

    for start in range(0, len(data), chunk_size):
        end = min(start + chunk_size, len(data))
        chunk = data.iloc[start:end]

        if method == 'isolation_forest':
            iso_forest = IsolationForest(contamination=0.1)
            chunk_outliers = iso_forest.fit_predict(chunk) == -1

        outliers.extend(chunk_outliers)

    return np.array(outliers)
```

### 2. Fast Screening

```python
# Quick screening with simple methods first
def fast_outlier_screen(data, z_threshold=3):
    """Fast initial outlier screening"""
    z_scores = np.abs(stats.zscore(data))
    return (z_scores > z_threshold).any(axis=1)

# Apply detailed methods only to screened data
initial_outliers = fast_outlier_screen(data_clean)
detailed_analysis_data = data_clean[initial_outliers]
```

## 📈 Real-Time Implementation

### Streaming Outlier Detector

```python
class StreamingOutlierDetector:
    def __init__(self, window_size=1000):
        self.window_size = window_size
        self.data_buffer = []
        self.baseline_stats = {}

    def update(self, new_point):
        """Update with new data point and detect outliers"""
        self.data_buffer.append(new_point)

        if len(self.data_buffer) > self.window_size:
            self.data_buffer.pop(0)

        if len(self.data_buffer) >= 100:
            # Update baseline statistics
            df = pd.DataFrame(self.data_buffer)
            self.baseline_stats = {
                'mean': df.mean(),
                'std': df.std()
            }

            # Detect outlier in current point
            if len(self.baseline_stats) > 0:
                z_score = np.abs((new_point - self.baseline_stats['mean']) /
                               self.baseline_stats['std'])
                return (z_score > 3).any()

        return False

# Usage
detector = StreamingOutlierDetector()
for _, row in data_clean.iterrows():
    is_outlier = detector.update(row)
    if is_outlier:
        print(f"Outlier detected: {row.name}")
```

## 🚨 Alert Thresholds

### Common Threshold Values

| Method | Parameter | Conservative | Moderate | Aggressive |
|--------|-----------|--------------|----------|------------|
| Z-Score | threshold | 3.0 | 2.5 | 2.0 |
| Modified Z-Score | threshold | 3.5 | 3.0 | 2.5 |
| IQR | k | 3.0 | 1.5 | 1.0 |
| Isolation Forest | contamination | 0.05 | 0.1 | 0.2 |
| One-Class SVM | nu | 0.05 | 0.1 | 0.2 |
| LOF | contamination | 0.05 | 0.1 | 0.2 |

### Manufacturing Context Guidelines

**Real-Time Process Control**: Use conservative thresholds to minimize false alarms

```python
# Conservative settings for real-time
iso_forest = IsolationForest(contamination=0.05)  # Expect 5% outliers
zscore_threshold = 3.0  # 99.7% confidence
```

**Batch Quality Analysis**: Use moderate thresholds for investigation

```python
# Moderate settings for batch analysis
iso_forest = IsolationForest(contamination=0.1)   # Expect 10% outliers
zscore_threshold = 2.5  # 98.8% confidence
```

**Research and Development**: Use aggressive thresholds to catch subtle anomalies

```python
# Aggressive settings for R&D
iso_forest = IsolationForest(contamination=0.2)   # Expect 20% outliers
zscore_threshold = 2.0  # 95.4% confidence
```

## 🔍 Troubleshooting

### Common Issues and Solutions

**Issue**: Too many false positives

- **Solution**: Increase threshold values, use consensus methods
- **Code**: `consensus_outliers(data, threshold=0.6)`

**Issue**: Missing obvious outliers

- **Solution**: Decrease threshold values, try multiple methods
- **Code**: `compare_methods(data, methods=['zscore', 'iqr', 'lof'])`

**Issue**: High computational cost

- **Solution**: Use statistical methods first, then ML on flagged data
- **Code**: `fast_outlier_screen()` then detailed analysis

**Issue**: Non-stationary data

- **Solution**: Use time-series methods or rolling baselines
- **Code**: `ewma_outliers()` or `StreamingOutlierDetector()`

**Issue**: Highly correlated features

- **Solution**: Use multivariate methods like Mahalanobis distance
- **Code**: `mahalanobis_outliers(data)`

## 📚 Further Resources

- **Documentation**: scikit-learn outlier detection
- **Papers**: "Outlier Detection Techniques" survey papers
- **Tools**: PyOD library for advanced outlier detection
- **Monitoring**: Integration with Grafana/Prometheus for real-time alerts

## ⚡ Quick Commands

```bash
# Install additional packages if needed
pip install pyod ruptures plotly

# Run outlier detection pipeline
python 2.2-outlier-detection-pipeline.py --input data.csv --output report.html

# Interactive analysis
jupyter notebook 2.2-outlier-detection.ipynb
```

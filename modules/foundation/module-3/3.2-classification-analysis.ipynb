{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a09400e1",
   "metadata": {},
   "source": [
    "# Module 3.2 â€“ Classification Analysis (Semiconductor Manufacturing)\n",
    "This notebook develops and evaluates supervised classification approaches for semiconductor yield/excursion detection tasks. It mirrors the regression workflow patterns from Module 3.1, extending them to imbalanced binary classification: baseline models, imbalance strategies (class weighting vs SMOTE variants), threshold tuning, probability calibration, interpretability, and production pipeline handoff.\n",
    "\n",
    "Sections:\n",
    "1. Imports & Global Configuration\n",
    "2. Data Loading (SECOM + synthetic generator) & Target Derivation\n",
    "3. Exploratory Data Analysis (class distribution, feature summaries)\n",
    "4. Baseline Logistic Regression\n",
    "5. Model Comparison (SVM, Tree, RandomForest, Gradient Boosting)\n",
    "6. Imbalance Strategies (Weights vs SMOTE)\n",
    "7. Threshold Tuning (Precision-Recall / ROC)\n",
    "8. Probability Calibration (Reliability Curve, Brier)\n",
    "9. Interpretability (Permutation Importance, Coefficients)\n",
    "10. ClassificationPipeline Assembly & Persistence\n",
    "11. Monitoring & Drift Considerations\n",
    "12. Next Steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0b1edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports & Global Configuration\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score, precision_recall_curve,\n",
    "                             roc_curve, classification_report, confusion_matrix,\n",
    "                             brier_score_loss, log_loss, matthews_corrcoef, balanced_accuracy_score)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_context('talk')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Environment ready:', {'numpy': np.__version__, 'pandas': pd.__version__})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac39133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Loading & Synthetic Generator\n",
    "# Placeholder: Loading SECOM dataset (existing regression dataset repurposed for classification)\n",
    "# We will derive a binary target from a continuous yield/quality metric or simulate one.\n",
    "\n",
    "DATA_DIR = Path('../../../datasets').resolve()\n",
    "\n",
    "# Synthetic classification data generator (imbalanced)\n",
    "def generate_synthetic_classification(n=1200, minority_frac=0.08, seed=RANDOM_SEED):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    temp = rng.normal(450, 15, n)\n",
    "    pressure = rng.normal(2.5, 0.3, n)\n",
    "    flow = rng.normal(120, 10, n)\n",
    "    time = rng.normal(60, 5, n)\n",
    "    interaction = 0.001 * (temp - 450) * (flow - 120)\n",
    "    # latent score with non-linear effect\n",
    "    score = (0.04*(temp-450) - 1.2*(pressure-2.5)**2 + 0.03*flow + 0.15*time + interaction)\n",
    "    # threshold for minority (rare excursion)\n",
    "    cutoff = np.quantile(score, 1 - minority_frac)\n",
    "    y = (score >= cutoff).astype(int)\n",
    "    df = pd.DataFrame({'temperature': temp, 'pressure': pressure, 'flow': flow, 'time': time, 'rare_event': y})\n",
    "    # simple engineered features\n",
    "    df['temp_centered'] = df['temperature'] - df['temperature'].mean()\n",
    "    df['pressure_sq'] = df['pressure']**2\n",
    "    df['flow_time_inter'] = df['flow'] * df['time']\n",
    "    df['temp_flow_inter'] = df['temperature'] * df['flow']\n",
    "    return df\n",
    "\n",
    "synthetic_df = generate_synthetic_classification()\n",
    "print('Synthetic shape:', synthetic_df.shape, 'Minority rate:', synthetic_df['rare_event'].mean())\n",
    "\n",
    "# Derive X, y\n",
    "TARGET = 'rare_event'\n",
    "X = synthetic_df.drop(columns=[TARGET])\n",
    "y = synthetic_df[TARGET].values\n",
    "\n",
    "# Initial train/holdout split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=RANDOM_SEED)\n",
    "print('Train minority rate:', y_train.mean(), 'Test minority rate:', y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09743ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Exploratory Data Analysis\n",
    "class_counts = pd.Series(y_train).value_counts().sort_index()\n",
    "print('Class counts (train):')\n",
    "print(class_counts)\n",
    "print('\\nClass distribution (%):')\n",
    "print((class_counts / class_counts.sum()).round(4))\n",
    "\n",
    "summary = X_train.describe().T\n",
    "summary['missing_pct'] = 100 * (X_train.isna().sum() / len(X_train))\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436bbedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Baseline Logistic Regression\n",
    "baseline_pipeline = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='median')),\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', LogisticRegression(max_iter=500, class_weight='balanced', random_state=RANDOM_SEED))\n",
    "])\n",
    "baseline_pipeline.fit(X_train, y_train)\n",
    "probs_val = baseline_pipeline.predict_proba(X_test)[:,1]\n",
    "roc = roc_auc_score(y_test, probs_val)\n",
    "ap = average_precision_score(y_test, probs_val)\n",
    "print({'roc_auc': roc, 'average_precision': ap})"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

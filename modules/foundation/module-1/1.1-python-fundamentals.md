# 1.1: Python Fundamentals for Semiconductor Engineers

## Table of Contents

- [Introduction](#introduction)
- [Python Programming Paradigms](#python-programming-paradigms)
- [Data Types and Memory Management](#data-types-and-memory-management)
- [Object-Oriented Programming for Engineering](#object-oriented-programming-for-engineering)
- [Error Handling and Debugging](#error-handling-and-debugging)
- [Performance Optimization](#performance-optimization)
- [Best Practices for Semiconductor Applications](#best-practices-for-semiconductor-applications)
- [Advanced Topics](#advanced-topics)

## Introduction

Python has become the de facto standard for data analysis in semiconductor manufacturing due to its:

- **Simplicity**: Easy to learn and read syntax
- **Ecosystem**: Rich libraries for scientific computing (NumPy, SciPy, Pandas)
- **Integration**: Seamless integration with existing systems and databases
- **Flexibility**: Suitable for everything from quick scripts to large applications
- **Community**: Strong support and continuous development

This document provides a comprehensive technical foundation for using Python in semiconductor engineering contexts.

## Python Programming Paradigms

### Procedural Programming

Most semiconductor engineers start with procedural programming - writing sequences of functions that operate on data.

```python
def calculate_critical_dimension(measurements):
    """Calculate CD statistics from measurement data."""
    mean_cd = sum(measurements) / len(measurements)
    variance = sum((x - mean_cd) ** 2 for x in measurements) / len(measurements)
    std_dev = variance ** 0.5
    return mean_cd, std_dev

def check_cd_specification(cd_value, target, tolerance):
    """Check if CD measurement is within specification."""
    lower_limit = target - tolerance
    upper_limit = target + tolerance
    return lower_limit <= cd_value <= upper_limit
```

### Functional Programming

Functional programming emphasizes immutable data and pure functions - particularly useful for data analysis pipelines.

```python
from functools import reduce
import operator

# Pure functions for wafer analysis
def filter_passing_die(wafer_data):
    """Return only passing die from wafer data."""
    return [die for die in wafer_data if die['status'] == 'pass']

def map_yield_calculation(lot_data):
    """Apply yield calculation to each lot."""
    return list(map(lambda lot: {
        'lot_id': lot['lot_id'],
        'yield': len(filter_passing_die(lot['wafers'])) / len(lot['wafers'])
    }, lot_data))

# Function composition for data pipelines
def compose(*functions):
    """Compose multiple functions into a single function."""
    return reduce(lambda f, g: lambda x: f(g(x)), functions, lambda x: x)
```

### Object-Oriented Programming

OOP is powerful for modeling complex semiconductor systems and creating reusable components.

```python
class WaferMap:
    """Represents a semiconductor wafer with die data."""

    def __init__(self, wafer_id, die_data, metadata=None):
        self.wafer_id = wafer_id
        self.die_data = die_data
        self.metadata = metadata or {}
        self._yield_cache = None

    @property
    def yield_percentage(self):
        """Calculate and cache yield percentage."""
        if self._yield_cache is None:
            passing_die = sum(1 for die in self.die_data.flatten() if die == 1)
            total_die = self.die_data.size
            self._yield_cache = (passing_die / total_die) * 100
        return self._yield_cache

    def get_quadrant_yield(self, quadrant):
        """Get yield for specific quadrant (1-4)."""
        h, w = self.die_data.shape
        quadrants = {
            1: self.die_data[:h//2, :w//2],      # Top-left
            2: self.die_data[:h//2, w//2:],      # Top-right
            3: self.die_data[h//2:, :w//2],      # Bottom-left
            4: self.die_data[h//2:, w//2:]       # Bottom-right
        }

        if quadrant not in quadrants:
            raise ValueError(f"Invalid quadrant: {quadrant}. Must be 1-4.")

        quad_data = quadrants[quadrant]
        return (quad_data.sum() / quad_data.size) * 100

    def __repr__(self):
        return f"WaferMap(id='{self.wafer_id}', yield={self.yield_percentage:.2f}%)"
```

## Data Types and Memory Management

### Fundamental Data Types

Understanding Python's data types is crucial for efficient semiconductor data processing:

```python
# Numeric types for measurements
temperature = 850.5          # float - process temperature
pressure = 750              # int - chamber pressure  
voltage = 3.3e-6            # float with scientific notation
complex_impedance = 50 + 25j # complex - RF measurements

# Strings for identifiers and metadata
lot_id = "LOT_2024_001"
recipe_name = "FEOL_LITHO_CRIT"
process_step = "Photolithography"

# Boolean for pass/fail and flags
is_production = True
within_spec = False
auto_mode = True

# None for missing or undefined values
measurement_result = None
optional_parameter = None
```

### Collections and Data Structures

```python
# Lists - ordered, mutable sequences
process_steps = ["Clean", "Coat", "Expose", "Develop", "Etch"]
measurements = [1.25, 1.27, 1.23, 1.26, 1.24]

# Tuples - ordered, immutable sequences (good for coordinates)
die_position = (15, 23)  # (x, y) coordinates
process_conditions = (850, 0.75, 120)  # (temp, pressure, time)

# Dictionaries - key-value mappings
process_recipe = {
    "temperature": 850,
    "pressure": 0.75,
    "time": 120,
    "gas_flow": {"ar": 100, "n2": 50},
    "rf_power": 1500
}

# Sets - unordered collections of unique elements
failed_wafers = {"W001", "W015", "W023"}
available_tools = {"TOOL_A", "TOOL_B", "TOOL_C"}
```

### Memory Management Considerations

Python's automatic memory management is generally excellent, but semiconductor applications often involve large datasets:

```python
import gc
import sys

def memory_efficient_processing(large_dataset):
    """Process large dataset with memory management."""

    # Process in chunks to avoid memory issues
    chunk_size = 1000
    results = []

    for i in range(0, len(large_dataset), chunk_size):
        chunk = large_dataset[i:i + chunk_size]

        # Process chunk
        processed_chunk = process_chunk(chunk)
        results.extend(processed_chunk)

        # Explicit cleanup for large objects
        del chunk

        # Force garbage collection periodically
        if i % (chunk_size * 10) == 0:
            gc.collect()

    return results

def monitor_memory_usage():
    """Monitor current memory usage."""
    return sys.getsizeof(locals())
```

## Object-Oriented Programming for Engineering

### Class Design for Semiconductor Systems

```python
from abc import ABC, abstractmethod
from typing import List, Dict, Optional
import numpy as np

class ProcessTool(ABC):
    """Abstract base class for all process tools."""

    def __init__(self, tool_id: str, tool_type: str):
        self.tool_id = tool_id
        self.tool_type = tool_type
        self.status = "idle"
        self.recipe_loaded = None

    @abstractmethod
    def load_recipe(self, recipe: Dict) -> bool:
        """Load process recipe into tool."""
        pass

    @abstractmethod
    def process_wafer(self, wafer_id: str) -> Dict:
        """Process a wafer and return results."""
        pass

    def get_status(self) -> str:
        """Get current tool status."""
        return self.status

class LithographyTool(ProcessTool):
    """Photolithography tool implementation."""

    def __init__(self, tool_id: str, wavelength: float = 193.0):
        super().__init__(tool_id, "Lithography")
        self.wavelength = wavelength
        self.dose_settings = {}
        self.focus_settings = {}

    def load_recipe(self, recipe: Dict) -> bool:
        """Load lithography recipe."""
        required_params = ["dose", "focus", "exposure_time"]

        if not all(param in recipe for param in required_params):
            return False

        self.dose_settings = recipe["dose"]
        self.focus_settings = recipe["focus"]
        self.recipe_loaded = recipe
        self.status = "recipe_loaded"
        return True

    def process_wafer(self, wafer_id: str) -> Dict:
        """Process wafer with loaded recipe."""
        if self.recipe_loaded is None:
            raise RuntimeError("No recipe loaded")

        self.status = "processing"

        # Simulate processing with some variability
        dose_actual = self.dose_settings["target"] + np.random.normal(0, 0.1)
        focus_actual = self.focus_settings["target"] + np.random.normal(0, 0.05)

        # Calculate CD based on dose and focus
        cd_target = 45.0  # nm
        dose_sensitivity = -0.8  # nm per mJ/cm²
        focus_sensitivity = 2.5   # nm per μm

        cd_actual = (cd_target +
                    dose_sensitivity * (dose_actual - self.dose_settings["target"]) +
                    focus_sensitivity * (focus_actual - self.focus_settings["target"]))

        self.status = "idle"

        return {
            "wafer_id": wafer_id,
            "tool_id": self.tool_id,
            "dose_actual": dose_actual,
            "focus_actual": focus_actual,
            "cd_measured": cd_actual,
            "timestamp": "2024-01-01T12:00:00"
        }

class EtchTool(ProcessTool):
    """Plasma etch tool implementation."""

    def __init__(self, tool_id: str, chamber_volume: float = 100.0):
        super().__init__(tool_id, "Etch")
        self.chamber_volume = chamber_volume
        self.gas_flows = {}
        self.rf_power = 0
        self.pressure = 0

    def load_recipe(self, recipe: Dict) -> bool:
        """Load etch recipe."""
        required_params = ["gas_flows", "rf_power", "pressure", "time"]

        if not all(param in recipe for param in required_params):
            return False

        self.gas_flows = recipe["gas_flows"]
        self.rf_power = recipe["rf_power"]
        self.pressure = recipe["pressure"]
        self.recipe_loaded = recipe
        self.status = "recipe_loaded"
        return True

    def process_wafer(self, wafer_id: str) -> Dict:
        """Process wafer with etch recipe."""
        if self.recipe_loaded is None:
            raise RuntimeError("No recipe loaded")

        self.status = "processing"

        # Simulate etch process
        etch_rate = self._calculate_etch_rate()
        etch_time = self.recipe_loaded["time"]
        etch_depth = etch_rate * etch_time

        self.status = "idle"

        return {
            "wafer_id": wafer_id,
            "tool_id": self.tool_id,
            "etch_rate": etch_rate,
            "etch_depth": etch_depth,
            "etch_time": etch_time,
            "timestamp": "2024-01-01T12:00:00"
        }

    def _calculate_etch_rate(self) -> float:
        """Calculate etch rate based on process conditions."""
        # Simplified etch rate model
        base_rate = 100  # nm/min
        power_factor = self.rf_power / 1000  # Normalize power
        pressure_factor = 1 / (self.pressure + 0.1)  # Inverse pressure relationship

        return base_rate * power_factor * pressure_factor + np.random.normal(0, 5)
```

### Inheritance and Polymorphism

```python
class AdvancedLithographyTool(LithographyTool):
    """Advanced lithography tool with EUV capability."""

    def __init__(self, tool_id: str, wavelength: float = 13.5):
        super().__init__(tool_id, wavelength)
        self.has_euv = wavelength < 50
        self.overlay_correction = True

    def process_wafer(self, wafer_id: str) -> Dict:
        """Enhanced wafer processing with overlay correction."""
        result = super().process_wafer(wafer_id)

        if self.overlay_correction:
            # Add overlay measurement and correction
            overlay_x = np.random.normal(0, 1.5)  # nm
            overlay_y = np.random.normal(0, 1.5)  # nm

            result.update({
                "overlay_x": overlay_x,
                "overlay_y": overlay_y,
                "overlay_corrected": True
            })

        return result

# Usage example showing polymorphism
def process_lot(wafers: List[str], tools: List[ProcessTool]) -> List[Dict]:
    """Process a lot of wafers using available tools."""
    results = []

    for wafer_id in wafers:
        for tool in tools:
            if tool.status == "idle":
                result = tool.process_wafer(wafer_id)
                results.append(result)
                break

    return results
```

## Error Handling and Debugging

### Exception Handling for Semiconductor Applications

```python
class ProcessError(Exception):
    """Base exception for process-related errors."""
    pass

class ToolError(ProcessError):
    """Exception for tool-related errors."""
    pass

class RecipeError(ProcessError):
    """Exception for recipe-related errors."""
    pass

class MeasurementError(ProcessError):
    """Exception for measurement-related errors."""
    pass

def robust_measurement_function(tool, wafer_id, max_retries=3):
    """Robust measurement with retry logic and proper error handling."""

    for attempt in range(max_retries):
        try:
            # Attempt measurement
            result = tool.measure_wafer(wafer_id)

            # Validate result
            if not validate_measurement(result):
                raise MeasurementError(f"Invalid measurement for wafer {wafer_id}")

            return result

        except ToolError as e:
            logger.error(f"Tool error on attempt {attempt + 1}: {e}")
            if attempt == max_retries - 1:
                raise ProcessError(f"Tool failed after {max_retries} attempts")

            # Wait before retry
            time.sleep(2 ** attempt)  # Exponential backoff

        except MeasurementError as e:
            logger.warning(f"Measurement error: {e}")
            if attempt == max_retries - 1:
                raise

        except Exception as e:
            logger.critical(f"Unexpected error: {e}")
            raise ProcessError(f"Unexpected error during measurement: {e}")

def validate_measurement(result):
    """Validate measurement result."""
    required_fields = ["wafer_id", "measurements", "timestamp"]

    if not all(field in result for field in required_fields):
        return False

    if not isinstance(result["measurements"], (list, np.ndarray)):
        return False

    if len(result["measurements"]) == 0:
        return False

    return True
```

### Logging and Debugging

```python
import logging
import traceback
from functools import wraps

# Configure logging for semiconductor applications
def setup_logging(log_level=logging.INFO, log_file="process.log"):
    """Setup comprehensive logging for semiconductor processes."""

    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    # File handler
    file_handler = logging.FileHandler(log_file)
    file_handler.setFormatter(formatter)

    # Console handler
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)

    # Root logger
    logger = logging.getLogger()
    logger.setLevel(log_level)
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)

    return logger

def log_function_calls(func):
    """Decorator to log function calls and results."""

    @wraps(func)
    def wrapper(*args, **kwargs):
        logger = logging.getLogger(func.__module__)

        logger.info(f"Calling {func.__name__} with args={args}, kwargs={kwargs}")

        try:
            result = func(*args, **kwargs)
            logger.info(f"{func.__name__} completed successfully")
            return result

        except Exception as e:
            logger.error(f"{func.__name__} failed: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            raise

    return wrapper

@log_function_calls
def critical_process_step(wafer_id, parameters):
    """Example of critical process step with logging."""
    logger = logging.getLogger(__name__)

    logger.info(f"Starting critical process for wafer {wafer_id}")

    # Process implementation
    result = perform_process(parameters)

    logger.info(f"Process completed for wafer {wafer_id}")
    return result
```

## Performance Optimization

### Efficient Data Processing

```python
import numpy as np
import pandas as pd
from numba import jit, vectorize
import concurrent.futures
from functools import lru_cache

# Vectorized operations for large datasets
@vectorize(['float64(float64, float64, float64)'], target='cpu')
def calculate_cd_deviation(measured, target, sensitivity):
    """Vectorized calculation of CD deviation."""
    return (measured - target) * sensitivity

# Just-in-time compilation for computational intensive functions
@jit(nopython=True)
def calculate_wafer_statistics(wafer_data):
    """Fast statistical calculations using Numba."""
    total_die = wafer_data.size
    passing_die = 0

    for i in range(wafer_data.shape[0]):
        for j in range(wafer_data.shape[1]):
            if wafer_data[i, j] == 1:
                passing_die += 1

    yield_pct = (passing_die / total_die) * 100
    return yield_pct, passing_die, total_die

# Caching for expensive computations
@lru_cache(maxsize=128)
def expensive_model_calculation(param1, param2, param3):
    """Cached expensive calculation."""
    # Simulate expensive computation
    result = 0
    for i in range(1000000):
        result += param1 * param2 * param3 * i
    return result

# Parallel processing for independent tasks
def process_wafers_parallel(wafer_list, process_function, max_workers=4):
    """Process wafers in parallel."""

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # Submit all tasks
        future_to_wafer = {
            executor.submit(process_function, wafer): wafer
            for wafer in wafer_list
        }

        results = []
        for future in concurrent.futures.as_completed(future_to_wafer):
            wafer = future_to_wafer[future]
            try:
                result = future.result()
                results.append(result)
            except Exception as exc:
                print(f'Wafer {wafer} generated an exception: {exc}')

        return results
```

### Memory Optimization

```python
import sys
from typing import Generator

def memory_efficient_file_reader(filename: str) -> Generator[str, None, None]:
    """Memory-efficient file reading using generators."""

    with open(filename, 'r') as file:
        for line in file:
            yield line.strip()

def process_large_dataset_chunked(data, chunk_size=1000):
    """Process large datasets in chunks to manage memory."""

    for i in range(0, len(data), chunk_size):
        chunk = data[i:i + chunk_size]

        # Process chunk
        processed_chunk = process_chunk(chunk)

        # Yield results immediately to avoid accumulation
        yield processed_chunk

        # Clean up
        del chunk

# Using slots to reduce memory overhead
class OptimizedWaferData:
    """Memory-optimized wafer data class."""

    __slots__ = ['wafer_id', 'die_data', 'yield_pct', 'timestamp']

    def __init__(self, wafer_id, die_data, yield_pct, timestamp):
        self.wafer_id = wafer_id
        self.die_data = die_data
        self.yield_pct = yield_pct
        self.timestamp = timestamp
```

## Best Practices for Semiconductor Applications

### Code Organization and Structure

```python
# project_structure.py
"""
Recommended project structure for semiconductor Python applications:

semiconductor_project/
├── src/
│   ├── __init__.py
│   ├── data/
│   │   ├── __init__.py
│   │   ├── loaders.py       # Data loading utilities
│   │   ├── validators.py    # Data validation
│   │   └── transformers.py  # Data transformation
│   ├── analysis/
│   │   ├── __init__.py
│   │   ├── wafer_analysis.py
│   │   ├── yield_analysis.py
│   │   └── statistical_models.py
│   ├── tools/
│   │   ├── __init__.py
│   │   ├── base_tool.py     # Abstract base classes
│   │   ├── lithography.py
│   │   └── etch.py
│   └── utils/
│       ├── __init__.py
│       ├── config.py        # Configuration management
│       ├── logging_setup.py
│       └── constants.py     # Physical constants
├── tests/
│   ├── __init__.py
│   ├── test_data/
│   ├── test_analysis/
│   └── test_tools/
├── config/
│   ├── development.yaml
│   ├── production.yaml
│   └── test.yaml
├── scripts/
│   ├── run_analysis.py
│   └── generate_reports.py
├── requirements.txt
├── setup.py
└── README.md
"""
```

### Configuration Management

```python
# config.py
import yaml
import os
from pathlib import Path
from typing import Dict, Any

class ConfigManager:
    """Centralized configuration management for semiconductor applications."""

    def __init__(self, config_dir: str = "config"):
        self.config_dir = Path(config_dir)
        self.environment = os.getenv("ENVIRONMENT", "development")
        self.config = self._load_config()

    def _load_config(self) -> Dict[str, Any]:
        """Load configuration based on environment."""
        config_file = self.config_dir / f"{self.environment}.yaml"

        if not config_file.exists():
            raise FileNotFoundError(f"Config file not found: {config_file}")

        with open(config_file, 'r') as file:
            return yaml.safe_load(file)

    def get(self, key: str, default: Any = None) -> Any:
        """Get configuration value with dot notation support."""
        keys = key.split('.')
        value = self.config

        for k in keys:
            if isinstance(value, dict) and k in value:
                value = value[k]
            else:
                return default

        return value

    def get_database_config(self) -> Dict[str, str]:
        """Get database configuration."""
        return self.get('database', {})

    def get_tool_config(self, tool_id: str) -> Dict[str, Any]:
        """Get tool-specific configuration."""
        return self.get(f'tools.{tool_id}', {})

# Usage example
config = ConfigManager()
db_config = config.get_database_config()
litho_config = config.get_tool_config('lithography_001')
```

### Testing Strategies

```python
# test_wafer_analysis.py
import unittest
import numpy as np
from unittest.mock import Mock, patch
import sys
sys.path.append('../src')

from analysis.wafer_analysis import WaferAnalyzer

class TestWaferAnalyzer(unittest.TestCase):
    """Comprehensive tests for wafer analysis functionality."""

    def setUp(self):
        """Set up test fixtures."""
        self.analyzer = WaferAnalyzer()

        # Create test wafer data
        self.test_wafer_data = np.random.choice([0, 1], size=(50, 50), p=[0.1, 0.9])
        self.wafer_id = "TEST_WAFER_001"

    def test_yield_calculation(self):
        """Test yield calculation accuracy."""
        yield_result = self.analyzer.calculate_yield(self.test_wafer_data)

        # Manual calculation for verification
        expected_yield = (np.sum(self.test_wafer_data) / self.test_wafer_data.size) * 100

        self.assertAlmostEqual(yield_result, expected_yield, places=2)
        self.assertGreaterEqual(yield_result, 0)
        self.assertLessEqual(yield_result, 100)

    def test_quadrant_analysis(self):
        """Test quadrant analysis functionality."""
        quadrant_yields = self.analyzer.analyze_quadrants(self.test_wafer_data)

        self.assertEqual(len(quadrant_yields), 4)
        self.assertTrue(all(0 <= yield <= 100 for yield in quadrant_yields.values()))

    def test_edge_effects_analysis(self):
        """Test edge effects detection."""
        edge_yield, center_yield = self.analyzer.analyze_edge_effects(self.test_wafer_data)

        self.assertIsInstance(edge_yield, float)
        self.assertIsInstance(center_yield, float)
        self.assertGreaterEqual(edge_yield, 0)
        self.assertGreaterEqual(center_yield, 0)

    def test_invalid_input_handling(self):
        """Test handling of invalid inputs."""
        with self.assertRaises(ValueError):
            self.analyzer.calculate_yield(np.array([]))  # Empty array

        with self.assertRaises(TypeError):
            self.analyzer.calculate_yield("invalid_input")  # Wrong type

    @patch('analysis.wafer_analysis.database_connection')
    def test_database_integration(self, mock_db):
        """Test database integration with mocking."""
        mock_db.fetch_wafer_data.return_value = self.test_wafer_data

        result = self.analyzer.analyze_wafer_from_db(self.wafer_id)

        mock_db.fetch_wafer_data.assert_called_once_with(self.wafer_id)
        self.assertIsNotNone(result)

class TestPerformance(unittest.TestCase):
    """Performance tests for critical functions."""

    def test_large_wafer_performance(self):
        """Test performance with large wafer maps."""
        import time

        large_wafer = np.random.choice([0, 1], size=(1000, 1000))
        analyzer = WaferAnalyzer()

        start_time = time.time()
        result = analyzer.calculate_yield(large_wafer)
        elapsed_time = time.time() - start_time

        # Should complete within reasonable time (adjust threshold as needed)
        self.assertLess(elapsed_time, 1.0)  # Less than 1 second
        self.assertIsNotNone(result)

if __name__ == '__main__':
    unittest.main()
```

## Advanced Topics

### Metaprogramming and Dynamic Code Generation

```python
# Dynamic class generation for different tool types
def create_tool_class(tool_type, base_parameters):
    """Dynamically create tool classes based on configuration."""

    class DynamicTool(ProcessTool):
        def __init__(self, tool_id):
            super().__init__(tool_id, tool_type)
            for param, default_value in base_parameters.items():
                setattr(self, param, default_value)

        def load_recipe(self, recipe):
            for param in base_parameters:
                if param in recipe:
                    setattr(self, param, recipe[param])
            self.recipe_loaded = recipe
            return True

        def process_wafer(self, wafer_id):
            # Generic processing based on tool type
            return {
                "wafer_id": wafer_id,
                "tool_id": self.tool_id,
                "tool_type": tool_type,
                "parameters": {param: getattr(self, param) for param in base_parameters}
            }

    # Set dynamic class name
    DynamicTool.__name__ = f"{tool_type}Tool"
    return DynamicTool

# Usage
IonImplantTool = create_tool_class("IonImplant", {
    "energy": 50,  # keV
    "dose": 1e15,  # atoms/cm²
    "angle": 7,    # degrees
    "species": "B" # Boron
})
```

### Context Managers for Resource Management

```python
import contextlib
from typing import Optional

class ToolSession:
    """Context manager for tool sessions with proper cleanup."""

    def __init__(self, tool: ProcessTool, recipe: Dict):
        self.tool = tool
        self.recipe = recipe
        self.session_active = False

    def __enter__(self):
        """Initialize tool session."""
        if not self.tool.load_recipe(self.recipe):
            raise ToolError(f"Failed to load recipe on {self.tool.tool_id}")

        self.session_active = True
        return self.tool

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Clean up tool session."""
        if self.session_active:
            self.tool.status = "idle"
            self.tool.recipe_loaded = None
            self.session_active = False

        if exc_type is not None:
            # Log exception details
            logging.error(f"Tool session error: {exc_val}")

        return False  # Don't suppress exceptions

@contextlib.contextmanager
def batch_processing_session(tools: List[ProcessTool], max_parallel: int = 4):
    """Context manager for batch processing sessions."""

    # Initialize all tools
    for tool in tools:
        tool.status = "ready"

    try:
        yield tools
    finally:
        # Cleanup all tools
        for tool in tools:
            tool.status = "idle"
            tool.recipe_loaded = None

# Usage examples
recipe = {"temperature": 850, "pressure": 0.75, "time": 120}

# Single tool session
with ToolSession(litho_tool, recipe) as tool:
    results = []
    for wafer_id in wafer_list:
        result = tool.process_wafer(wafer_id)
        results.append(result)

# Batch processing session
with batch_processing_session(tool_list) as tools:
    results = process_wafers_parallel(wafer_list, tools[0].process_wafer)
```

### Decorators for Cross-Cutting Concerns

```python
import time
from functools import wraps
import threading

def timing_decorator(func):
    """Decorator to measure function execution time."""

    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        elapsed_time = time.time() - start_time

        print(f"{func.__name__} took {elapsed_time:.4f} seconds")
        return result

    return wrapper

def retry_on_failure(max_attempts=3, delay=1.0, exceptions=(Exception,)):
    """Decorator to retry function on failure."""

    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None

            for attempt in range(max_attempts):
                try:
                    return func(*args, **kwargs)
                except exceptions as e:
                    last_exception = e
                    if attempt < max_attempts - 1:
                        time.sleep(delay * (2 ** attempt))  # Exponential backoff

            raise last_exception

        return wrapper
    return decorator

def thread_safe(func):
    """Decorator to make function thread-safe."""

    lock = threading.Lock()

    @wraps(func)
    def wrapper(*args, **kwargs):
        with lock:
            return func(*args, **kwargs)

    return wrapper

# Usage examples
@timing_decorator
@retry_on_failure(max_attempts=3, exceptions=(ToolError,))
def critical_measurement(tool, wafer_id):
    """Critical measurement with timing and retry."""
    return tool.measure_wafer(wafer_id)

@thread_safe
def update_global_counter():
    """Thread-safe counter update."""
    global process_counter
    process_counter += 1
```

This comprehensive technical document provides the foundation for advanced Python programming in semiconductor engineering contexts. The concepts covered here will be essential for the more complex machine learning applications we'll explore in later modules.

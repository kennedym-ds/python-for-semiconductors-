# Module 9.1 ‚Äì Model Deployment Quick Reference

## üöÄ Quick Start Commands

### Pipeline CLI Usage

```bash
# Export model for deployment
python 9.1-model-deployment-pipeline.py export \
  --model-path ../path/to/model.joblib \
  --output-dir ./deployment \
  --version 1.0.0

# Validate deployment artifacts
python 9.1-model-deployment-pipeline.py validate \
  --deployment-dir ./deployment

# Package model with auto-naming
python 9.1-model-deployment-pipeline.py package \
  --model-path model.joblib \
  --version 2.1.0
```

### FastAPI Service

```bash
# Start local development server
cd infrastructure/api
uvicorn main:app --reload --host 0.0.0.0 --port 8000

# Start production server
uvicorn main:app --workers 4 --host 0.0.0.0 --port 8000
```

### Docker Commands

```bash
# Build API image
docker build -f Dockerfile.api -t semiconductor-ml-api .

# Run API container
docker run -p 8000:8000 \
  -v $(pwd)/temp_models:/app/temp_models \
  semiconductor-ml-api

# Use docker-compose
docker-compose up model-api
```

## üì° API Endpoints

### Health Check
```http
GET /health
```
**Response:**
```json
{
  "status": "healthy",
  "uptime_seconds": 3600.0,
  "model_loaded": true,
  "version": "v1"
}
```

### Model Information
```http
GET /version
```
**Response:**
```json
{
  "model_name": "yield_predictor",
  "version": "1.0.0",
  "model_type": "regression",
  "input_schema": {"temperature": "float", "pressure": "float"},
  "output_schema": {"prediction": "float"}
}
```

### Make Prediction
```http
POST /predict
Content-Type: application/json

{
  "temperature": 450.0,
  "pressure": 2.5,
  "flow": 120.0,
  "time": 60.0
}
```
**Response:**
```json
{
  "prediction": 87.5,
  "confidence": 0.92,
  "model_version": "1.0.0",
  "metadata": {
    "model_used": "regression_model",
    "timestamp": 1640995200.0
  }
}
```

### Basic Metrics
```http
GET /metrics
```
**Response:**
```json
{
  "uptime_seconds": 3600.0,
  "model_loaded": true,
  "service_name": "semiconductor-ml-api",
  "api_version": "v1",
  "model_info": {
    "name": "yield_predictor",
    "version": "1.0.0",
    "type": "regression"
  }
}
```

## üîß Environment Variables

### API Service Configuration

| Variable | Default | Description |
|----------|---------|-------------|
| `MODEL_PATH` | `/app/temp_models/model.joblib` | Path to model file |
| `METADATA_PATH` | `/app/temp_models/metadata.json` | Path to metadata file |
| `API_VERSION` | `v1` | API version identifier |
| `SERVICE_NAME` | `semiconductor-ml-api` | Service name for logging |

### Docker Environment

```bash
# Set environment variables
export MODEL_PATH=/path/to/model.joblib
export METADATA_PATH=/path/to/metadata.json
export API_VERSION=v1

# Run with environment
docker run -p 8000:8000 \
  -e MODEL_PATH=$MODEL_PATH \
  -e METADATA_PATH=$METADATA_PATH \
  semiconductor-ml-api
```

## üìÅ File Structure

### Deployment Artifacts
```
deployment_v1_0_0/
‚îú‚îÄ‚îÄ model.joblib          # Serialized model
‚îú‚îÄ‚îÄ metadata.json         # Model information and schema
‚îî‚îÄ‚îÄ validation_passed     # Validation status
```

### API Service Structure
```
infrastructure/api/
‚îú‚îÄ‚îÄ main.py              # FastAPI application
‚îú‚îÄ‚îÄ schemas.py           # Pydantic request/response models
‚îî‚îÄ‚îÄ __init__.py          # Package initialization
```

## üß™ Testing Commands

### Unit Tests
```bash
# Run deployment pipeline tests
cd modules/cutting-edge/module-9
python test_model_deployment.py

# Run with pytest if available
pytest test_model_deployment.py -v
```

### API Testing with cURL

```bash
# Health check
curl http://localhost:8000/health

# Version info
curl http://localhost:8000/version

# Prediction
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"temperature": 450, "pressure": 2.5, "flow": 120, "time": 60}'

# Metrics
curl http://localhost:8000/metrics
```

### Load Testing

```bash
# Install wrk (if available)
wrk -t4 -c100 -d30s --script=predict.lua http://localhost:8000/predict

# Or use curl in loop
for i in {1..100}; do
  curl -s -X POST http://localhost:8000/predict \
    -H "Content-Type: application/json" \
    -d '{"temperature": 450, "pressure": 2.5, "flow": 120, "time": 60}' \
    > /dev/null
done
```

## üêõ Troubleshooting

### Common Issues

| Issue | Symptom | Solution |
|-------|---------|----------|
| Model not loading | `model_loaded: false` | Check `MODEL_PATH` environment variable |
| Import errors | `ModuleNotFoundError` | Install FastAPI dependencies: `pip install fastapi uvicorn pydantic` |
| Port conflicts | `Address already in use` | Use different port: `--port 8001` |
| Validation errors | `422 Unprocessable Entity` | Check input data types and ranges |

### Debug Mode

```bash
# Enable debug logging
export LOG_LEVEL=DEBUG
uvicorn main:app --log-level debug

# Check model loading
python -c "
import joblib
model = joblib.load('temp_models/model.joblib')
print(f'Model type: {type(model)}')
print(f'Model methods: {[m for m in dir(model) if not m.startswith(\"_\")][:10]}')
"
```

### Container Debugging

```bash
# Check container logs
docker logs <container_id>

# Interactive shell in container
docker exec -it <container_id> /bin/bash

# Check file permissions
docker exec <container_id> ls -la /app/temp_models/
```

## üìä Monitoring

### Health Check Automation

```bash
#!/bin/bash
# health_monitor.sh
while true; do
  response=$(curl -s http://localhost:8000/health)
  status=$(echo $response | jq -r '.status')
  if [ "$status" != "healthy" ]; then
    echo "ALERT: Service unhealthy - $response"
    # Send alert (email, Slack, etc.)
  fi
  sleep 30
done
```

### Log Monitoring

```bash
# Follow logs
docker logs -f <container_id>

# Filter for errors
docker logs <container_id> 2>&1 | grep ERROR

# Monitor response times
curl -w "Time: %{time_total}s\n" -s http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"temperature": 450, "pressure": 2.5, "flow": 120, "time": 60}'
```

## üîí Security Checklist

### Production Deployment

- [ ] Enable HTTPS/TLS encryption
- [ ] Set up authentication (API keys, OAuth)
- [ ] Configure rate limiting
- [ ] Run container as non-root user
- [ ] Scan container images for vulnerabilities
- [ ] Set up network security (firewalls, VPCs)
- [ ] Enable audit logging
- [ ] Regular security updates

### Environment Hardening

```bash
# Remove development tools from production
docker build --target production -f Dockerfile.api .

# Use minimal base images
FROM python:3.11-slim-bullseye

# Set security headers
app.add_middleware(
    SecurityHeadersMiddleware,
    headers={"X-Frame-Options": "DENY"}
)
```

## üìà Performance Optimization

### API Tuning

```python
# Increase worker processes
uvicorn main:app --workers 4

# Use async workers for I/O bound tasks
uvicorn main:app --worker-class uvicorn.workers.UvicornWorker

# Enable HTTP/2
uvicorn main:app --http h2
```

### Model Optimization

```python
# Model caching
from functools import lru_cache

@lru_cache(maxsize=128)
def cached_predict(features_hash):
    return model.predict(features)

# Batch predictions
def batch_predict(samples):
    return model.predict(pd.DataFrame(samples))
```

## üîÑ Deployment Strategies

### Blue-Green Deployment

```bash
# Deploy to staging (green)
docker-compose -f docker-compose.staging.yml up -d

# Test staging environment
./run_integration_tests.sh staging

# Switch traffic to green
docker-compose -f docker-compose.production.yml down
docker-compose -f docker-compose.staging.yml up -d
```

### Rolling Updates

```bash
# Update with zero downtime
docker-compose up -d --scale model-api=3
docker-compose up -d --no-deps model-api
```

## üìö Additional Resources

- **FastAPI Documentation**: https://fastapi.tiangolo.com/
- **Docker Best Practices**: https://docs.docker.com/develop/dev-best-practices/
- **Pydantic Validation**: https://pydantic-docs.helpmanual.io/
- **MLOps Patterns**: https://ml-ops.org/
- **Container Security**: https://sysdig.com/blog/dockerfile-best-practices/

# Module 9.2 â€“ Monitoring & Maintenance Quick Reference

## ðŸš€ Quick Start

### Install Dependencies
```bash
# Install advanced tier for MLflow support
python env_setup.py --tier advanced

# Or install specific dependencies
pip install mlflow scipy scikit-learn
```

### Basic Usage
```bash
# Train with monitoring
python 9.2-monitoring-maintenance-pipeline.py train --dataset synthetic_yield --model ridge --enable-mlflow

# Evaluate with drift detection
python 9.2-monitoring-maintenance-pipeline.py evaluate --model-path model.joblib --inject-drift

# Make predictions
python 9.2-monitoring-maintenance-pipeline.py predict --model-path model.joblib --input-json '{"temperature":455, "pressure":2.6, "flow":118, "time":62, "temp_centered":5, "pressure_sq":6.76, "flow_time_inter":7316, "temp_flow_inter":53690}'
```

---

## ðŸ“Š Key Metrics & Thresholds

### Manufacturing Metrics
| Metric | Formula | Good | Warning | Critical |
|--------|---------|------|---------|----------|
| **PWS %** | `(errors â‰¤ tolerance).mean() * 100` | >95% | 90-95% | <90% |
| **Estimated Loss** | `sum((pred - actual)Â² * cost_model)` | <$10K | $10-50K | >$50K |
| **MAE Degradation** | `(current_mae - baseline_mae) / baseline_mae` | <5% | 5-15% | >15% |

### Drift Detection Thresholds
| Method | No Drift | Minor Drift | Major Drift |
|--------|----------|-------------|-------------|
| **PSI** | <0.1 | 0.1-0.2 | >0.2 |
| **KS Test** | p>0.05 | 0.01<pâ‰¤0.05 | pâ‰¤0.01 |
| **Wasserstein** | <0.5 | 0.5-1.0 | >1.0 |

---

## ðŸ”§ MLflow Setup

### Local MLflow Server
```bash
# Start MLflow tracking server
mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns --port 5000

# Set tracking URI (optional)
export MLFLOW_TRACKING_URI=http://localhost:5000
```

### Pipeline Integration
```python
from monitoring_pipeline import MonitoringPipeline

# Enable MLflow tracking
pipeline = MonitoringPipeline()
pipeline.enable_mlflow("semiconductor_monitoring")

# Training with automatic logging
pipeline.fit(X_train, y_train, model_type="ridge", alpha=1.0)
```

### MLflow UI Access
```bash
# View experiments
mlflow ui --port 5000

# Access at: http://localhost:5000
```

---

## ðŸ“ˆ Drift Detection Commands

### Training with Drift Injection
```bash
# Normal training
python 9.2-monitoring-maintenance-pipeline.py train --dataset synthetic_yield --model ridge

# Training with synthetic drift
python 9.2-monitoring-maintenance-pipeline.py train --dataset synthetic_yield --model ridge --inject-drift

# Save trained model
python 9.2-monitoring-maintenance-pipeline.py train --dataset synthetic_yield --model ridge --save my_model.joblib
```

### Drift Evaluation
```bash
# Evaluate with drift detection
python 9.2-monitoring-maintenance-pipeline.py evaluate --model-path my_model.joblib --inject-drift

# Normal evaluation
python 9.2-monitoring-maintenance-pipeline.py evaluate --model-path my_model.joblib --dataset synthetic_yield
```

### Output Interpretation
```json
{
  "drift_scores": {
    "temperature_psi": 0.25,        // PSI > 0.2 = major drift
    "temperature_ks_p": 0.003,      // p < 0.01 = significant drift
    "temperature_wasserstein": 1.2  // > 1.0 = major drift
  },
  "alert_flags": {
    "temperature_psi_alert": true,
    "temperature_ks_alert": true,
    "temperature_wasserstein_alert": true
  }
}
```

---

## ðŸŽ¯ Model Types & Parameters

### Supported Models
```bash
# Ridge regression (default)
python 9.2-monitoring-maintenance-pipeline.py train --model ridge --alpha 1.0

# Lasso regression
python 9.2-monitoring-maintenance-pipeline.py train --model lasso --alpha 0.1

# Elastic Net
python 9.2-monitoring-maintenance-pipeline.py train --model elastic_net --alpha 0.5

# Random Forest
python 9.2-monitoring-maintenance-pipeline.py train --model random_forest
```

### Hyperparameter Guidelines
| Model | Parameter | Conservative | Balanced | Aggressive |
|-------|-----------|--------------|----------|------------|
| Ridge | alpha | 10.0 | 1.0 | 0.1 |
| Lasso | alpha | 1.0 | 0.1 | 0.01 |
| Elastic Net | alpha | 1.0 | 0.5 | 0.1 |
| Random Forest | n_estimators | 50 | 100 | 200 |

---

## ðŸ” Prediction Methods

### Single Prediction (JSON)
```bash
# Basic prediction
python 9.2-monitoring-maintenance-pipeline.py predict \
  --model-path model.joblib \
  --input-json '{"temperature":455, "pressure":2.6, "flow":118, "time":62, "temp_centered":5, "pressure_sq":6.76, "flow_time_inter":7316, "temp_flow_inter":53690}'
```

### Batch Prediction (CSV)
```bash
# Create input CSV
cat > input.csv << EOF
temperature,pressure,flow,time,temp_centered,pressure_sq,flow_time_inter,temp_flow_inter
455,2.6,118,62,5,6.76,7316,53690
460,2.7,120,63,10,7.29,7560,55200
EOF

# Batch prediction
python 9.2-monitoring-maintenance-pipeline.py predict \
  --model-path model.joblib \
  --input-file input.csv
```

---

## ðŸš¨ Alert Configuration

### Default Alert Thresholds
```python
# Modify in drift_config.py
class DriftConfig:
    psi_threshold: float = 0.2           # PSI alert threshold
    ks_p_threshold: float = 0.05         # KS test p-value threshold
    wasserstein_threshold: float = 0.5   # Wasserstein distance threshold
    performance_degradation_threshold: float = 0.1  # 10% performance drop
    alert_consecutive_violations: int = 2 # Alerts after N violations
```

### Manufacturing-Specific Thresholds
```python
# Fab-specific configuration
fab_config = {
    'critical_processes': {
        'psi_threshold': 0.15,    # Tighter control
        'ks_p_threshold': 0.01
    },
    'secondary_processes': {
        'psi_threshold': 0.25,    # More relaxed
        'ks_p_threshold': 0.05
    }
}
```

---

## ðŸ“‹ Troubleshooting

### Common Issues

**1. MLflow Connection Errors**
```bash
# Check MLflow server status
curl http://localhost:5000/health

# Restart MLflow server
mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns --port 5000

# Use local file store (no server)
unset MLFLOW_TRACKING_URI
```

**2. Memory Issues with Large Datasets**
```python
# Reduce sample size for testing
python 9.2-monitoring-maintenance-pipeline.py train --dataset synthetic_yield --n-samples 500

# Monitor memory usage
import psutil
print(f"Memory usage: {psutil.virtual_memory().percent}%")
```

**3. Slow Drift Calculations**
```python
# Reduce number of bins for PSI
def calculate_psi(reference, current, bins=5):  # Reduced from 10
    # ... implementation
```

**4. JSON Serialization Errors**
```bash
# Check for numpy data types in output
python -c "import numpy as np; print(type(np.float64(1.0)))"

# Use convert_numpy_types function in pipeline
```

### Performance Optimization

**Speed Up Training**
```bash
# Use smaller regularization for faster convergence
python 9.2-monitoring-maintenance-pipeline.py train --model ridge --alpha 10.0

# Reduce cross-validation folds
# (modify in pipeline code if needed)
```

**Reduce Memory Usage**
```bash
# Use Lasso instead of Random Forest
python 9.2-monitoring-maintenance-pipeline.py train --model lasso

# Process data in chunks for large datasets
# (implement in custom data loader)
```

---

## ðŸ§ª Testing & Validation

### Run Test Suite
```bash
# Full test suite
python test_monitoring_pipeline.py

# Individual test
python -c "from test_monitoring_pipeline import test_train_basic; test_train_basic()"
```

### Validate Pipeline Health
```bash
# Quick health check
python 9.2-monitoring-maintenance-pipeline.py train --dataset synthetic_yield --model ridge | jq '.status'

# Should output: "trained"
```

### Performance Benchmarks
```bash
# Time training
time python 9.2-monitoring-maintenance-pipeline.py train --dataset synthetic_yield --model ridge

# Memory usage
/usr/bin/time -v python 9.2-monitoring-maintenance-pipeline.py train --dataset synthetic_yield --model ridge
```

---

## ðŸ“ File Structure

```
modules/cutting-edge/module-9/
â”œâ”€â”€ 9.2-monitoring-maintenance-pipeline.py      # Main pipeline script
â”œâ”€â”€ 9.2-monitoring-maintenance-fundamentals.md  # Theory and documentation
â”œâ”€â”€ 9.2-monitoring-maintenance-quick-ref.md     # This file
â”œâ”€â”€ 9.2-monitoring-maintenance.ipynb            # Interactive notebook
â””â”€â”€ test_monitoring_pipeline.py                 # Unit tests
```

---

## ðŸ”— Integration Examples

### With Existing Monitoring Systems
```python
# Export metrics to Prometheus
def export_to_prometheus(metrics):
    from prometheus_client import CollectorRegistry, Gauge, push_to_gateway

    registry = CollectorRegistry()
    mae_gauge = Gauge('model_mae', 'Model Mean Absolute Error', registry=registry)
    mae_gauge.set(metrics['mae'])

    push_to_gateway('localhost:9091', job='ml_monitoring', registry=registry)
```

### With Alert Systems
```python
# Send alerts to Slack
def send_slack_alert(drift_results):
    import requests

    if drift_results['overall_drift_detected']:
        webhook_url = "YOUR_SLACK_WEBHOOK_URL"
        message = {
            "text": f"ðŸš¨ Model drift detected! PSI scores: {drift_results['drift_scores']}"
        }
        requests.post(webhook_url, json=message)
```

### With Production Pipelines
```python
# Apache Airflow DAG example
from airflow import DAG
from airflow.operators.bash_operator import BashOperator

dag = DAG('model_monitoring', schedule_interval='@hourly')

monitor_task = BashOperator(
    task_id='check_drift',
    bash_command='python 9.2-monitoring-maintenance-pipeline.py evaluate --model-path /models/latest.joblib',
    dag=dag
)
```

---

## ðŸš€ Advanced Usage

### Custom Drift Detection
```python
# Add custom drift detection method
def custom_drift_metric(reference, current):
    # Your custom logic here
    return drift_score

# Integrate into pipeline
class CustomMonitoringPipeline(MonitoringPipeline):
    def detect_drift(self, reference_data, current_data, config):
        # Add custom drift detection
        standard_drift = super().detect_drift(reference_data, current_data, config)
        custom_drift = custom_drift_metric(reference_data, current_data)

        # Combine results
        standard_drift['drift_scores']['custom_metric'] = custom_drift
        return standard_drift
```

### Production Deployment
```bash
# Docker deployment
cat > Dockerfile << EOF
FROM python:3.11-slim
COPY requirements-advanced.txt .
RUN pip install -r requirements-advanced.txt
COPY modules/cutting-edge/module-9/ /app/
WORKDIR /app
CMD ["python", "9.2-monitoring-maintenance-pipeline.py", "train", "--enable-mlflow"]
EOF

# Build and run
docker build -t ml-monitoring .
docker run -p 5000:5000 ml-monitoring
```

---

## ðŸ“ž Support & Resources

### Documentation Links
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [Scikit-learn Model Selection](https://scikit-learn.org/stable/model_selection.html)
- [SciPy Statistical Tests](https://docs.scipy.org/doc/scipy/reference/stats.html)

### Common Commands Quick Reference
```bash
# Training
python 9.2-monitoring-maintenance-pipeline.py train --help

# Evaluation  
python 9.2-monitoring-maintenance-pipeline.py evaluate --help

# Prediction
python 9.2-monitoring-maintenance-pipeline.py predict --help

# MLflow UI
mlflow ui --port 5000

# Test suite
python test_monitoring_pipeline.py
```

### Performance Expectations
| Operation | Typical Time | Memory Usage |
|-----------|-------------|--------------|
| Training (800 samples) | 2-5 seconds | <100MB |
| Evaluation with drift | 1-3 seconds | <50MB |
| Single prediction | <100ms | <10MB |
| Batch prediction (100) | <500ms | <20MB |

---

**ðŸ’¡ Pro Tips:**
- Always enable MLflow for production deployments
- Use drift injection for testing alert systems
- Monitor both individual features and overall model performance
- Set up automated alerts before deploying to production
- Regularly update drift thresholds based on process changes

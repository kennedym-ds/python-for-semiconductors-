{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module 9.1 \u2013 Model Deployment with FastAPI & Docker\n",
        "\n",
        "## \ud83c\udfaf Learning Objectives\n",
        "\n",
        "By the end of this notebook, you will be able to:\n",
        "\n",
        "- Deploy trained ML models as REST APIs using FastAPI\n",
        "- Package models with proper versioning and metadata\n",
        "- Create containerized deployment artifacts with Docker\n",
        "- Test API endpoints and validate deployment health\n",
        "- Understand production deployment patterns for semiconductor manufacturing\n",
        "\n",
        "## \ud83d\udccb Prerequisites\n",
        "\n",
        "- Completed Module 3 (foundational ML pipelines)\n",
        "- Basic understanding of REST APIs\n",
        "- Docker installed (for containerization sections)\n",
        "- FastAPI dependencies installed (`pip install fastapi uvicorn pydantic`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd27 Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import subprocess\n",
        "import time\n",
        "from pathlib import Path\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Set up paths\n",
        "NOTEBOOK_DIR = Path.cwd()\n",
        "ROOT_DIR = NOTEBOOK_DIR.parent.parent.parent\n",
        "TEMP_MODELS_DIR = ROOT_DIR / 'temp_models'\n",
        "PIPELINE_SCRIPT = NOTEBOOK_DIR / '9.1-model-deployment-pipeline.py'\n",
        "API_DIR = ROOT_DIR / 'infrastructure' / 'api'\n",
        "\n",
        "print(f\"\ud83d\udcc1 Notebook directory: {NOTEBOOK_DIR}\")\n",
        "print(f\"\ud83d\udcc1 Root directory: {ROOT_DIR}\")\n",
        "print(f\"\ud83d\udcc1 Models directory: {TEMP_MODELS_DIR}\")\n",
        "print(f\"\ud83d\udc0d Pipeline script: {PIPELINE_SCRIPT}\")\n",
        "print(f\"\ud83d\udd27 API directory: {API_DIR}\")\n",
        "\n",
        "# Create directories if they don't exist\n",
        "TEMP_MODELS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "print(\"\\n\u2705 Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcca Step 1: Create and Train a Demo Model\n",
        "\n",
        "Let's create a simple semiconductor yield prediction model to demonstrate deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_semiconductor_data(n_samples=1000, random_state=42):\n",
        "    \"\"\"Generate synthetic semiconductor process data.\"\"\"\n",
        "    np.random.seed(random_state)\n",
        "    \n",
        "    # Process parameters\n",
        "    temperature = np.random.normal(450, 15, n_samples)  # Celsius\n",
        "    pressure = np.random.normal(2.5, 0.3, n_samples)   # Torr\n",
        "    flow_rate = np.random.normal(120, 10, n_samples)   # sccm\n",
        "    time = np.random.normal(60, 5, n_samples)          # seconds\n",
        "    \n",
        "    # Create yield based on process window\n",
        "    # Optimal conditions: temp=450, pressure=2.5, flow=120, time=60\n",
        "    temp_effect = -0.1 * (temperature - 450)**2 / 100\n",
        "    pressure_effect = -2.0 * (pressure - 2.5)**2\n",
        "    flow_effect = -0.05 * (flow_rate - 120)**2 / 100\n",
        "    time_effect = -0.08 * (time - 60)**2 / 100\n",
        "    \n",
        "    yield_percentage = 85 + temp_effect + pressure_effect + flow_effect + time_effect\n",
        "    yield_percentage += np.random.normal(0, 2, n_samples)  # Add noise\n",
        "    \n",
        "    # Ensure yield is in reasonable range\n",
        "    yield_percentage = np.clip(yield_percentage, 0, 100)\n",
        "    \n",
        "    return pd.DataFrame({\n",
        "        'temperature': temperature,\n",
        "        'pressure': pressure,\n",
        "        'flow': flow_rate,\n",
        "        'time': time,\n",
        "        'yield': yield_percentage\n",
        "    })\n",
        "\n",
        "# Generate data\n",
        "df = generate_semiconductor_data(1000)\n",
        "print(\"\ud83d\udcca Generated synthetic semiconductor data:\")\n",
        "print(df.head())\n",
        "print(f\"\\n\ud83d\udcc8 Data shape: {df.shape}\")\n",
        "print(f\"\ud83d\udcc9 Yield statistics:\")\n",
        "print(df['yield'].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data and train model\n",
        "X = df[['temperature', 'pressure', 'flow', 'time']]\n",
        "y = df['yield']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train pipeline\n",
        "model_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = model_pipeline.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\ud83c\udfaf Model Performance:\")\n",
        "print(f\"   RMSE: {np.sqrt(mse):.2f}%\")\n",
        "print(f\"   R\u00b2: {r2:.3f}\")\n",
        "\n",
        "# Save the model\n",
        "model_path = TEMP_MODELS_DIR / 'demo_yield_model.joblib'\n",
        "joblib.dump(model_pipeline, model_path)\n",
        "print(f\"\\n\ud83d\udcbe Model saved to: {model_path}\")\n",
        "\n",
        "# Test prediction\n",
        "test_input = np.array([[450.0, 2.5, 120.0, 60.0]])  # Optimal conditions\n",
        "test_prediction = model_pipeline.predict(test_input)\n",
        "print(f\"\\n\ud83e\uddea Test prediction for optimal conditions: {test_prediction[0]:.2f}% yield\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udce6 Step 2: Package Model for Deployment\n",
        "\n",
        "Use our deployment pipeline to create deployment-ready artifacts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_pipeline_command(cmd_args):\n",
        "    \"\"\"Run the deployment pipeline CLI and return parsed JSON output.\"\"\"\n",
        "    result = subprocess.run(\n",
        "        ['python', str(PIPELINE_SCRIPT)] + cmd_args,\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "        cwd=NOTEBOOK_DIR\n",
        "    )\n",
        "    \n",
        "    if result.returncode != 0:\n",
        "        print(f\"\u274c Error running command: {' '.join(cmd_args)}\")\n",
        "        print(f\"Stderr: {result.stderr}\")\n",
        "        return None\n",
        "    \n",
        "    try:\n",
        "        return json.loads(result.stdout)\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"\u274c Failed to parse JSON output: {result.stdout}\")\n",
        "        return None\n",
        "\n",
        "# Package the model\n",
        "package_result = run_pipeline_command([\n",
        "    'package',\n",
        "    '--model-path', str(model_path),\n",
        "    '--version', '1.0.0',\n",
        "    '--output-name', 'demo_deployment'\n",
        "])\n",
        "\n",
        "if package_result:\n",
        "    print(\"\ud83d\udce6 Model packaging successful:\")\n",
        "    print(json.dumps(package_result, indent=2))\n",
        "    \n",
        "    deployment_dir = Path(package_result['output_dir'])\n",
        "    print(f\"\\n\ud83d\udcc1 Deployment artifacts created in: {deployment_dir}\")\n",
        "    \n",
        "    # List deployment contents\n",
        "    print(\"\\n\ud83d\udccb Deployment contents:\")\n",
        "    for item in deployment_dir.iterdir():\n",
        "        print(f\"   {item.name}\")\nelse:\n",
        "    print(\"\u274c Model packaging failed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate the deployment\n",
        "if package_result:\n",
        "    validate_result = run_pipeline_command([\n",
        "        'validate',\n",
        "        '--deployment-dir', package_result['output_dir']\n",
        "    ])\n",
        "    \n",
        "    if validate_result:\n",
        "        print(\"\u2705 Deployment validation:\")\n",
        "        print(json.dumps(validate_result, indent=2))\n",
        "        \n",
        "        if validate_result['status'] == 'valid':\n",
        "            print(\"\\n\ud83c\udf89 Deployment is valid and ready for API serving!\")\n",
        "        else:\n",
        "            print(\"\\n\u274c Deployment validation failed:\")\n",
        "            for issue in validate_result['issues']:\n",
        "                print(f\"   - {issue}\")\n",
        "    else:\n",
        "        print(\"\u274c Validation failed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Examine the metadata\n",
        "if package_result:\n",
        "    metadata_path = Path(package_result['metadata_path'])\n",
        "    \n",
        "    if metadata_path.exists():\n",
        "        with open(metadata_path, 'r') as f:\n",
        "            metadata = json.load(f)\n",
        "        \n",
        "        print(\"\ud83d\udcc4 Model metadata:\")\n",
        "        print(json.dumps(metadata, indent=2))\n",
        "    else:\n",
        "        print(f\"\u274c Metadata file not found: {metadata_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\ude80 Step 3: Start the FastAPI Service\n",
        "\n",
        "Now let's start the API service and test it. We'll copy our deployment artifacts to the expected location."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "# Copy model and metadata to the expected API location\n",
        "if package_result:\n",
        "    deployment_dir = Path(package_result['output_dir'])\n",
        "    \n",
        "    # Copy model\n",
        "    api_model_path = TEMP_MODELS_DIR / 'model.joblib'\n",
        "    api_metadata_path = TEMP_MODELS_DIR / 'metadata.json'\n",
        "    \n",
        "    shutil.copy2(deployment_dir / 'model.joblib', api_model_path)\n",
        "    shutil.copy2(deployment_dir / 'metadata.json', api_metadata_path)\n",
        "    \n",
        "    print(f\"\ud83d\udccb Copied model to API location:\")\n",
        "    print(f\"   Model: {api_model_path}\")\n",
        "    print(f\"   Metadata: {api_metadata_path}\")\n",
        "    \n",
        "    # Check if FastAPI can import\n",
        "    try:\n",
        "        import uvicorn\n",
        "        import fastapi\n",
        "        print(\"\\n\u2705 FastAPI dependencies available\")\n",
        "        print(f\"   FastAPI version: {fastapi.__version__}\")\n",
        "        print(f\"   Uvicorn version: {uvicorn.__version__}\")\n",
        "    except ImportError as e:\n",
        "        print(f\"\\n\u274c FastAPI dependencies missing: {e}\")\n",
        "        print(\"Please install: pip install fastapi uvicorn pydantic\")\nelse:\n",
        "    print(\"\u274c Cannot proceed without packaged model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Starting the API Server\n",
        "\n",
        "**Note**: In a Jupyter notebook, we can't easily run the FastAPI server in the background. \n",
        "\n",
        "**Option 1**: Run in a separate terminal:\n",
        "```bash\n",
        "cd /path/to/repository\n",
        "PYTHONPATH=$PWD uvicorn infrastructure.api.main:app --host 0.0.0.0 --port 8000\n",
        "```\n",
        "\n",
        "**Option 2**: Use the cells below to test if a server is already running.\n",
        "\n",
        "Let's check if an API server is available and test it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test if API server is running\n",
        "API_BASE_URL = \"http://localhost:8000\"\n",
        "\n",
        "def test_api_connection():\n",
        "    \"\"\"Test if the API server is running and responsive.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(f\"{API_BASE_URL}/health\", timeout=5)\n",
        "        if response.status_code == 200:\n",
        "            return True, response.json()\n",
        "        else:\n",
        "            return False, f\"HTTP {response.status_code}\"\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return False, str(e)\n",
        "\n",
        "# Check connection\n",
        "is_connected, result = test_api_connection()\n",
        "\n",
        "if is_connected:\n",
        "    print(\"\ud83c\udf89 API server is running!\")\n",
        "    print(\"\ud83d\udcca Health status:\")\n",
        "    print(json.dumps(result, indent=2))\nelse:\n",
        "    print(f\"\u274c API server not accessible: {result}\")\n",
        "    print(\"\\n\ud83d\udca1 To start the server, run in a terminal:\")\n",
        "    print(f\"   cd {ROOT_DIR}\")\n",
        "    print(\"   PYTHONPATH=$PWD uvicorn infrastructure.api.main:app --host 0.0.0.0 --port 8000\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83e\uddea Step 4: Test API Endpoints\n",
        "\n",
        "If the API server is running, let's test all the endpoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_api_endpoints():\n",
        "    \"\"\"Test all API endpoints and display results.\"\"\"\n",
        "    \n",
        "    # Test health endpoint\n",
        "    print(\"\ud83c\udfe5 Testing /health endpoint:\")\n",
        "    try:\n",
        "        response = requests.get(f\"{API_BASE_URL}/health\")\n",
        "        if response.status_code == 200:\n",
        "            health_data = response.json()\n",
        "            print(json.dumps(health_data, indent=2))\n",
        "            model_loaded = health_data.get('model_loaded', False)\n",
        "            print(f\"   Model loaded: {'\u2705' if model_loaded else '\u274c'}\")\n",
        "        else:\n",
        "            print(f\"   \u274c HTTP {response.status_code}: {response.text}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   \u274c Error: {e}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "    \n",
        "    # Test version endpoint\n",
        "    print(\"\ud83d\udccb Testing /version endpoint:\")\n",
        "    try:\n",
        "        response = requests.get(f\"{API_BASE_URL}/version\")\n",
        "        if response.status_code == 200:\n",
        "            version_data = response.json()\n",
        "            print(json.dumps(version_data, indent=2))\n",
        "        else:\n",
        "            print(f\"   \u274c HTTP {response.status_code}: {response.text}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   \u274c Error: {e}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "    \n",
        "    # Test metrics endpoint\n",
        "    print(\"\ud83d\udcca Testing /metrics endpoint:\")\n",
        "    try:\n",
        "        response = requests.get(f\"{API_BASE_URL}/metrics\")\n",
        "        if response.status_code == 200:\n",
        "            metrics_data = response.json()\n",
        "            print(json.dumps(metrics_data, indent=2))\n",
        "        else:\n",
        "            print(f\"   \u274c HTTP {response.status_code}: {response.text}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   \u274c Error: {e}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "    \n",
        "    # Test prediction endpoint\n",
        "    print(\"\ud83d\udd2e Testing /predict endpoint:\")\n",
        "    \n",
        "    # Test with optimal conditions\n",
        "    test_cases = [\n",
        "        {\n",
        "            \"name\": \"Optimal conditions\",\n",
        "            \"data\": {\n",
        "                \"temperature\": 450.0,\n",
        "                \"pressure\": 2.5,\n",
        "                \"flow\": 120.0,\n",
        "                \"time\": 60.0\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"High temperature\",\n",
        "            \"data\": {\n",
        "                \"temperature\": 480.0,\n",
        "                \"pressure\": 2.5,\n",
        "                \"flow\": 120.0,\n",
        "                \"time\": 60.0\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Low pressure\",\n",
        "            \"data\": {\n",
        "                \"temperature\": 450.0,\n",
        "                \"pressure\": 2.0,\n",
        "                \"flow\": 120.0,\n",
        "                \"time\": 60.0\n",
        "            }\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    for test_case in test_cases:\n",
        "        print(f\"\\n\ud83e\uddea Testing: {test_case['name']}\")\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                f\"{API_BASE_URL}/predict\",\n",
        "                json=test_case['data'],\n",
        "                headers={\"Content-Type\": \"application/json\"}\n",
        "            )\n",
        "            if response.status_code == 200:\n",
        "                prediction_data = response.json()\n",
        "                print(f\"   Input: {test_case['data']}\")\n",
        "                print(f\"   Prediction: {prediction_data['prediction']:.2f}% yield\")\n",
        "                print(f\"   Confidence: {prediction_data['confidence']:.3f}\")\n",
        "                print(f\"   Model version: {prediction_data['model_version']}\")\n",
        "            else:\n",
        "                print(f\"   \u274c HTTP {response.status_code}: {response.text}\")\n",
        "        except Exception as e:\n",
        "            print(f\"   \u274c Error: {e}\")\n",
        "\n",
        "# Run the tests if API is available\n",
        "is_connected, _ = test_api_connection()\n",
        "if is_connected:\n",
        "    test_api_endpoints()\nelse:\n",
        "    print(\"\u274c API server not available. Please start the server first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83e\uddea Step 5: Validate Input Schemas\n",
        "\n",
        "Test the API's input validation to ensure it properly rejects invalid data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_input_validation():\n",
        "    \"\"\"Test API input validation with invalid data.\"\"\"\n",
        "    \n",
        "    invalid_test_cases = [\n",
        "        {\n",
        "            \"name\": \"Temperature too high\",\n",
        "            \"data\": {\n",
        "                \"temperature\": 700.0,  # Above max of 600\n",
        "                \"pressure\": 2.5,\n",
        "                \"flow\": 120.0,\n",
        "                \"time\": 60.0\n",
        "            },\n",
        "            \"expected_status\": 422\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Negative pressure\",\n",
        "            \"data\": {\n",
        "                \"temperature\": 450.0,\n",
        "                \"pressure\": -1.0,  # Below min of 0.1\n",
        "                \"flow\": 120.0,\n",
        "                \"time\": 60.0\n",
        "            },\n",
        "            \"expected_status\": 422\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Missing field\",\n",
        "            \"data\": {\n",
        "                \"temperature\": 450.0,\n",
        "                \"pressure\": 2.5,\n",
        "                # Missing flow and time\n",
        "            },\n",
        "            \"expected_status\": 422\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Wrong data type\",\n",
        "            \"data\": {\n",
        "                \"temperature\": \"not_a_number\",\n",
        "                \"pressure\": 2.5,\n",
        "                \"flow\": 120.0,\n",
        "                \"time\": 60.0\n",
        "            },\n",
        "            \"expected_status\": 422\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    print(\"\ud83d\udee1\ufe0f Testing input validation:\")\n",
        "    \n",
        "    for test_case in invalid_test_cases:\n",
        "        print(f\"\\n\ud83e\uddea Testing: {test_case['name']}\")\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                f\"{API_BASE_URL}/predict\",\n",
        "                json=test_case['data'],\n",
        "                headers={\"Content-Type\": \"application/json\"}\n",
        "            )\n",
        "            \n",
        "            if response.status_code == test_case['expected_status']:\n",
        "                print(f\"   \u2705 Correctly rejected with HTTP {response.status_code}\")\n",
        "                if response.status_code == 422:\n",
        "                    error_data = response.json()\n",
        "                    print(f\"   \ud83d\udcdd Error details: {error_data.get('detail', 'No details')}\")\n",
        "            else:\n",
        "                print(f\"   \u274c Expected HTTP {test_case['expected_status']}, got {response.status_code}\")\n",
        "                print(f\"   \ud83d\udcdd Response: {response.text}\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"   \u274c Error: {e}\")\n",
        "\n",
        "# Run validation tests if API is available\n",
        "is_connected, _ = test_api_connection()\n",
        "if is_connected:\n",
        "    test_input_validation()\nelse:\n",
        "    print(\"\u274c API server not available for validation testing.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcca Step 6: Performance Testing\n",
        "\n",
        "Let's test the API performance with multiple requests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import concurrent.futures\n",
        "import statistics\n",
        "\n",
        "def measure_response_time(test_data):\n",
        "    \"\"\"Measure response time for a single API call.\"\"\"\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            f\"{API_BASE_URL}/predict\",\n",
        "            json=test_data,\n",
        "            headers={\"Content-Type\": \"application/json\"},\n",
        "            timeout=10\n",
        "        )\n",
        "        end_time = time.time()\n",
        "        \n",
        "        if response.status_code == 200:\n",
        "            return end_time - start_time, True\n",
        "        else:\n",
        "            return end_time - start_time, False\n",
        "    except Exception:\n",
        "        return time.time() - start_time, False\n",
        "\n",
        "def performance_test(num_requests=50):\n",
        "    \"\"\"Run performance test with multiple concurrent requests.\"\"\"\n",
        "    \n",
        "    test_data = {\n",
        "        \"temperature\": 450.0,\n",
        "        \"pressure\": 2.5,\n",
        "        \"flow\": 120.0,\n",
        "        \"time\": 60.0\n",
        "    }\n",
        "    \n",
        "    print(f\"\u26a1 Running performance test with {num_requests} requests...\")\n",
        "    \n",
        "    # Sequential requests\n",
        "    print(\"\\n\ud83d\udcc8 Sequential requests:\")\n",
        "    sequential_times = []\n",
        "    sequential_success = 0\n",
        "    \n",
        "    start_total = time.time()\n",
        "    for i in range(min(10, num_requests)):  # Limit sequential to 10 for time\n",
        "        response_time, success = measure_response_time(test_data)\n",
        "        sequential_times.append(response_time)\n",
        "        if success:\n",
        "            sequential_success += 1\n",
        "    end_total = time.time()\n",
        "    \n",
        "    print(f\"   \u2705 Success rate: {sequential_success}/{len(sequential_times)} ({100*sequential_success/len(sequential_times):.1f}%)\")\n",
        "    print(f\"   \u23f1\ufe0f Average response time: {statistics.mean(sequential_times)*1000:.1f}ms\")\n",
        "    print(f\"   \u23f1\ufe0f Median response time: {statistics.median(sequential_times)*1000:.1f}ms\")\n",
        "    print(f\"   \ud83d\udcca Total time: {end_total - start_total:.2f}s\")\n",
        "    \n",
        "    # Concurrent requests\n",
        "    print(\"\\n\ud83d\udd04 Concurrent requests:\")\n",
        "    concurrent_times = []\n",
        "    concurrent_success = 0\n",
        "    \n",
        "    start_total = time.time()\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
        "        futures = [executor.submit(measure_response_time, test_data) for _ in range(min(20, num_requests))]\n",
        "        \n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            response_time, success = future.result()\n",
        "            concurrent_times.append(response_time)\n",
        "            if success:\n",
        "                concurrent_success += 1\n",
        "    end_total = time.time()\n",
        "    \n",
        "    print(f\"   \u2705 Success rate: {concurrent_success}/{len(concurrent_times)} ({100*concurrent_success/len(concurrent_times):.1f}%)\")\n",
        "    print(f\"   \u23f1\ufe0f Average response time: {statistics.mean(concurrent_times)*1000:.1f}ms\")\n",
        "    print(f\"   \u23f1\ufe0f Median response time: {statistics.median(concurrent_times)*1000:.1f}ms\")\n",
        "    print(f\"   \ud83d\udcca Total time: {end_total - start_total:.2f}s\")\n",
        "    print(f\"   \ud83d\ude80 Throughput: {len(concurrent_times)/(end_total - start_total):.1f} requests/second\")\n",
        "\n",
        "# Run performance test if API is available\n",
        "is_connected, _ = test_api_connection()\n",
        "if is_connected:\n",
        "    performance_test()\nelse:\n",
        "    print(\"\u274c API server not available for performance testing.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udc33 Step 7: Docker Deployment Demo\n",
        "\n",
        "Let's examine the Docker configuration and understand how to deploy with containers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check Docker files\n",
        "dockerfile_api = ROOT_DIR / 'Dockerfile.api'\n",
        "docker_compose = ROOT_DIR / 'docker-compose.yml'\n",
        "\n",
        "print(\"\ud83d\udc33 Docker configuration files:\")\n",
        "print(f\"   API Dockerfile: {dockerfile_api} {'\u2705' if dockerfile_api.exists() else '\u274c'}\")\n",
        "print(f\"   Docker Compose: {docker_compose} {'\u2705' if docker_compose.exists() else '\u274c'}\")\n",
        "\n",
        "if dockerfile_api.exists():\n",
        "    print(\"\\n\ud83d\udcc4 Dockerfile.api contents:\")\n",
        "    with open(dockerfile_api, 'r') as f:\n",
        "        dockerfile_content = f.read()\n",
        "    print(dockerfile_content[:500] + \"...\" if len(dockerfile_content) > 500 else dockerfile_content)\n",
        "\n",
        "print(\"\\n\ud83d\ude80 Docker deployment commands:\")\n",
        "print(\"\")\n",
        "print(\"# Build the API image:\")\n",
        "print(f\"docker build -f Dockerfile.api -t semiconductor-ml-api .\")\n",
        "print(\"\")\n",
        "print(\"# Run the API container:\")\n",
        "print(\"docker run -p 8001:8000 \\\\\")\n",
        "print(\"  -v $(pwd)/temp_models:/app/temp_models \\\\\")\n",
        "print(\"  semiconductor-ml-api\")\n",
        "print(\"\")\n",
        "print(\"# Use docker-compose:\")\n",
        "print(\"docker-compose up model-api\")\n",
        "print(\"\")\n",
        "print(\"\ud83d\udca1 The API will be available at http://localhost:8001 when using Docker\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udccb Step 8: Check Docker Build (Optional)\n",
        "\n",
        "If Docker is available, let's test building the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_docker_availability():\n",
        "    \"\"\"Check if Docker is available and working.\"\"\"\n",
        "    try:\n",
        "        result = subprocess.run(['docker', '--version'], capture_output=True, text=True)\n",
        "        if result.returncode == 0:\n",
        "            return True, result.stdout.strip()\n",
        "        else:\n",
        "            return False, \"Docker command failed\"\n",
        "    except FileNotFoundError:\n",
        "        return False, \"Docker not found\"\n",
        "\n",
        "def test_docker_build():\n",
        "    \"\"\"Test building the Docker image (dry run).\"\"\"\n",
        "    print(\"\ud83d\udc33 Testing Docker build...\")\n",
        "    \n",
        "    try:\n",
        "        # Do a dry run of the build process\n",
        "        result = subprocess.run(\n",
        "            ['docker', 'build', '-f', 'Dockerfile.api', '--dry-run', '.'],\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            cwd=ROOT_DIR,\n",
        "            timeout=30\n",
        "        )\n",
        "        \n",
        "        if result.returncode == 0:\n",
        "            print(\"\u2705 Docker build validation successful\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"\u274c Docker build validation failed: {result.stderr}\")\n",
        "            return False\n",
        "            \n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(\"\u23f0 Docker build test timed out\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"\u274c Docker build test error: {e}\")\n",
        "        return False\n",
        "\n",
        "# Check Docker availability\n",
        "docker_available, docker_info = check_docker_availability()\n",
        "\n",
        "if docker_available:\n",
        "    print(f\"\u2705 Docker available: {docker_info}\")\n",
        "    \n",
        "    # Note: Actual build testing is commented out to avoid long build times\n",
        "    # Uncomment the next line if you want to test building\n",
        "    # test_docker_build()\n",
        "    \n",
        "    print(\"\\n\ud83d\udca1 To build and test the Docker image manually:\")\n",
        "    print(f\"   cd {ROOT_DIR}\")\n",
        "    print(\"   docker build -f Dockerfile.api -t semiconductor-ml-api .\")\n",
        "    print(\"   docker run -p 8001:8000 -v $(pwd)/temp_models:/app/temp_models semiconductor-ml-api\")\n",
        "    \nelse:\n",
        "    print(f\"\u274c Docker not available: {docker_info}\")\n",
        "    print(\"\ud83d\udca1 Docker is optional for this module, but recommended for production deployment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcda Step 9: Summary and Next Steps\n",
        "\n",
        "Let's summarize what we've accomplished and outline next steps for production deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\ud83c\udfaf Module 9.1 - Model Deployment Summary\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Check what we've completed\n",
        "completed_tasks = []\n",
        "pending_tasks = []\n",
        "\n",
        "# Model creation and training\n",
        "if model_path.exists():\n",
        "    completed_tasks.append(\"\u2705 Created and trained ML model\")\nelse:\n",
        "    pending_tasks.append(\"\u274c Model creation failed\")\n",
        "\n",
        "# Model packaging\n",
        "if package_result and package_result.get('status') == 'exported':\n",
        "    completed_tasks.append(\"\u2705 Packaged model for deployment\")\nelse:\n",
        "    pending_tasks.append(\"\u274c Model packaging failed\")\n",
        "\n",
        "# Validation\n",
        "if validate_result and validate_result.get('status') == 'valid':\n",
        "    completed_tasks.append(\"\u2705 Validated deployment artifacts\")\nelse:\n",
        "    pending_tasks.append(\"\u274c Deployment validation failed\")\n",
        "\n",
        "# API testing\n",
        "is_connected, _ = test_api_connection()\n",
        "if is_connected:\n",
        "    completed_tasks.append(\"\u2705 Tested FastAPI endpoints\")\nelse:\n",
        "    pending_tasks.append(\"\u26a0\ufe0f API server not running (optional for notebook)\")\n",
        "\n",
        "# Docker\n",
        "docker_available, _ = check_docker_availability()\n",
        "if docker_available:\n",
        "    completed_tasks.append(\"\u2705 Docker available for containerization\")\nelse:\n",
        "    completed_tasks.append(\"\u26a0\ufe0f Docker not available (optional)\")\n",
        "\n",
        "print(\"\\n\ud83d\udccb Completed Tasks:\")\n",
        "for task in completed_tasks:\n",
        "    print(f\"   {task}\")\n",
        "\n",
        "if pending_tasks:\n",
        "    print(\"\\n\u26a0\ufe0f Pending Tasks:\")\n",
        "    for task in pending_tasks:\n",
        "        print(f\"   {task}\")\n",
        "\n",
        "print(\"\\n\ud83d\ude80 Key Achievements:\")\n",
        "print(\"   \u2022 Built end-to-end model deployment pipeline\")\n",
        "print(\"   \u2022 Created REST API with FastAPI and Pydantic validation\")\n",
        "print(\"   \u2022 Implemented proper model versioning and metadata\")\n",
        "print(\"   \u2022 Set up Docker containerization for production\")\n",
        "print(\"   \u2022 Demonstrated input validation and error handling\")\n",
        "print(\"   \u2022 Performed basic performance testing\")\n",
        "\n",
        "print(\"\\n\ud83c\udfaf Next Steps for Production:\")\n",
        "print(\"   1. Set up authentication and authorization\")\n",
        "print(\"   2. Implement proper logging and monitoring\")\n",
        "print(\"   3. Add model performance tracking\")\n",
        "print(\"   4. Set up CI/CD pipeline for automated deployment\")\n",
        "print(\"   5. Configure load balancing and auto-scaling\")\n",
        "print(\"   6. Implement model A/B testing\")\n",
        "print(\"   7. Add comprehensive error handling and alerting\")\n",
        "print(\"   8. Set up model drift detection\")\n",
        "\n",
        "print(\"\\n\ud83d\udcd6 Additional Resources:\")\n",
        "print(\"   \u2022 FastAPI documentation: https://fastapi.tiangolo.com/\")\n",
        "print(\"   \u2022 Docker best practices: https://docs.docker.com/develop/best-practices/\")\n",
        "print(\"   \u2022 MLOps patterns: https://ml-ops.org/\")\n",
        "print(\"   \u2022 Module fundamentals: 9.1-model-deployment-fundamentals.md\")\n",
        "print(\"   \u2022 Quick reference: 9.1-model-deployment-quick-ref.md\")\n",
        "\n",
        "print(\"\\n\ud83c\udf89 Congratulations! You've successfully completed Module 9.1 - Model Deployment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83e\uddf9 Cleanup (Optional)\n",
        "\n",
        "Run this cell to clean up temporary files created during the demo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "def cleanup_demo_files():\n",
        "    \"\"\"Clean up temporary files created during the demo.\"\"\"\n",
        "    \n",
        "    cleanup_items = []\n",
        "    \n",
        "    # Model files\n",
        "    if model_path.exists():\n",
        "        cleanup_items.append(str(model_path))\n",
        "    \n",
        "    # Deployment directories\n",
        "    for item in TEMP_MODELS_DIR.glob('deployment_*'):\n",
        "        if item.is_dir():\n",
        "            cleanup_items.append(str(item))\n",
        "    \n",
        "    # API model files\n",
        "    api_model = TEMP_MODELS_DIR / 'model.joblib'\n",
        "    api_metadata = TEMP_MODELS_DIR / 'metadata.json'\n",
        "    \n",
        "    if api_model.exists():\n",
        "        cleanup_items.append(str(api_model))\n",
        "    if api_metadata.exists():\n",
        "        cleanup_items.append(str(api_metadata))\n",
        "    \n",
        "    if cleanup_items:\n",
        "        print(\"\ud83e\uddf9 The following files/directories can be cleaned up:\")\n",
        "        for item in cleanup_items:\n",
        "            print(f\"   {item}\")\n",
        "        \n",
        "        response = input(\"\\nDo you want to delete these files? (y/N): \")\n",
        "        \n",
        "        if response.lower() in ['y', 'yes']:\n",
        "            for item in cleanup_items:\n",
        "                item_path = Path(item)\n",
        "                try:\n",
        "                    if item_path.is_dir():\n",
        "                        shutil.rmtree(item_path)\n",
        "                    else:\n",
        "                        item_path.unlink()\n",
        "                    print(f\"   \u2705 Deleted: {item}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"   \u274c Failed to delete {item}: {e}\")\n",
        "            print(\"\\n\u2705 Cleanup completed!\")\n",
        "        else:\n",
        "            print(\"\\n\ud83d\udeab Cleanup cancelled\")\n",
        "    else:\n",
        "        print(\"\ud83e\uddf9 No demo files found to clean up\")\n",
        "\n",
        "# Uncomment the next line to run cleanup\n",
        "# cleanup_demo_files()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}

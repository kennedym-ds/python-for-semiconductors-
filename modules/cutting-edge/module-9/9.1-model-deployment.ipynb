{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 9.1 – Model Deployment with FastAPI & Docker\n",
    "\n",
    "## 🎯 Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "- Deploy trained ML models as REST APIs using FastAPI\n",
    "- Package models with proper versioning and metadata\n",
    "- Create containerized deployment artifacts with Docker\n",
    "- Test API endpoints and validate deployment health\n",
    "- Understand production deployment patterns for semiconductor manufacturing\n",
    "\n",
    "## 📋 Prerequisites\n",
    "\n",
    "- Completed Module 3 (foundational ML pipelines)\n",
    "- Basic understanding of REST APIs\n",
    "- Docker installed (for containerization sections)\n",
    "- FastAPI dependencies installed (`pip install fastapi uvicorn pydantic`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import subprocess\n",
    "import time\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Set up paths\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent.parent.parent\n",
    "TEMP_MODELS_DIR = ROOT_DIR / 'temp_models'\n",
    "PIPELINE_SCRIPT = NOTEBOOK_DIR / '9.1-model-deployment-pipeline.py'\n",
    "API_DIR = ROOT_DIR / 'infrastructure' / 'api'\n",
    "\n",
    "print(f\"📁 Notebook directory: {NOTEBOOK_DIR}\")\n",
    "print(f\"📁 Root directory: {ROOT_DIR}\")\n",
    "print(f\"📁 Models directory: {TEMP_MODELS_DIR}\")\n",
    "print(f\"🐍 Pipeline script: {PIPELINE_SCRIPT}\")\n",
    "print(f\"🔧 API directory: {API_DIR}\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "TEMP_MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"\\n✅ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Step 1: Create and Train a Demo Model\n",
    "\n",
    "Let's create a simple semiconductor yield prediction model to demonstrate deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_semiconductor_data(n_samples=1000, random_state=42):\n",
    "    \"\"\"Generate synthetic semiconductor process data.\"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Process parameters\n",
    "    temperature = np.random.normal(450, 15, n_samples)  # Celsius\n",
    "    pressure = np.random.normal(2.5, 0.3, n_samples)   # Torr\n",
    "    flow_rate = np.random.normal(120, 10, n_samples)   # sccm\n",
    "    time = np.random.normal(60, 5, n_samples)          # seconds\n",
    "    \n",
    "    # Create yield based on process window\n",
    "    # Optimal conditions: temp=450, pressure=2.5, flow=120, time=60\n",
    "    temp_effect = -0.1 * (temperature - 450)**2 / 100\n",
    "    pressure_effect = -2.0 * (pressure - 2.5)**2\n",
    "    flow_effect = -0.05 * (flow_rate - 120)**2 / 100\n",
    "    time_effect = -0.08 * (time - 60)**2 / 100\n",
    "    \n",
    "    yield_percentage = 85 + temp_effect + pressure_effect + flow_effect + time_effect\n",
    "    yield_percentage += np.random.normal(0, 2, n_samples)  # Add noise\n",
    "    \n",
    "    # Ensure yield is in reasonable range\n",
    "    yield_percentage = np.clip(yield_percentage, 0, 100)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'temperature': temperature,\n",
    "        'pressure': pressure,\n",
    "        'flow': flow_rate,\n",
    "        'time': time,\n",
    "        'yield': yield_percentage\n",
    "    })\n",
    "\n",
    "# Generate data\n",
    "df = generate_semiconductor_data(1000)\n",
    "print(\"📊 Generated synthetic semiconductor data:\")\n",
    "print(df.head())\n",
    "print(f\"\\n📈 Data shape: {df.shape}\")\n",
    "print(f\"📉 Yield statistics:\")\n",
    "print(df['yield'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data and train model\n",
    "X = df[['temperature', 'pressure', 'flow', 'time']]\n",
    "y = df['yield']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train pipeline\n",
    "model_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"🎯 Model Performance:\")\n",
    "print(f\"   RMSE: {np.sqrt(mse):.2f}%\")\n",
    "print(f\"   R²: {r2:.3f}\")\n",
    "\n",
    "# Save the model\n",
    "model_path = TEMP_MODELS_DIR / 'demo_yield_model.joblib'\n",
    "joblib.dump(model_pipeline, model_path)\n",
    "print(f\"\\n💾 Model saved to: {model_path}\")\n",
    "\n",
    "# Test prediction\n",
    "test_input = np.array([[450.0, 2.5, 120.0, 60.0]])  # Optimal conditions\n",
    "test_prediction = model_pipeline.predict(test_input)\n",
    "print(f\"\\n🧪 Test prediction for optimal conditions: {test_prediction[0]:.2f}% yield\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦 Step 2: Package Model for Deployment\n",
    "\n",
    "Use our deployment pipeline to create deployment-ready artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline_command(cmd_args):\n",
    "    \"\"\"Run the deployment pipeline CLI and return parsed JSON output.\"\"\"\n",
    "    result = subprocess.run(\n",
    "        ['python', str(PIPELINE_SCRIPT)] + cmd_args,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        cwd=NOTEBOOK_DIR\n",
    "    )\n",
    "    \n",
    "    if result.returncode != 0:\n",
    "        print(f\"❌ Error running command: {' '.join(cmd_args)}\")\n",
    "        print(f\"Stderr: {result.stderr}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        return json.loads(result.stdout)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"❌ Failed to parse JSON output: {result.stdout}\")\n",
    "        return None\n",
    "\n",
    "# Package the model\n",
    "package_result = run_pipeline_command([\n",
    "    'package',\n",
    "    '--model-path', str(model_path),\n",
    "    '--version', '1.0.0',\n",
    "    '--output-name', 'demo_deployment'\n",
    "])\n",
    "\n",
    "if package_result:\n",
    "    print(\"📦 Model packaging successful:\")\n",
    "    print(json.dumps(package_result, indent=2))\n",
    "    \n",
    "    deployment_dir = Path(package_result['output_dir'])\n",
    "    print(f\"\\n📁 Deployment artifacts created in: {deployment_dir}\")\n",
    "    \n",
    "    # List deployment contents\n",
    "    print(\"\\n📋 Deployment contents:\")\n",
    "    for item in deployment_dir.iterdir():\n",
    "        print(f\"   {item.name}\")\nelse:\n",
    "    print(\"❌ Model packaging failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the deployment\n",
    "if package_result:\n",
    "    validate_result = run_pipeline_command([\n",
    "        'validate',\n",
    "        '--deployment-dir', package_result['output_dir']\n",
    "    ])\n",
    "    \n",
    "    if validate_result:\n",
    "        print(\"✅ Deployment validation:\")\n",
    "        print(json.dumps(validate_result, indent=2))\n",
    "        \n",
    "        if validate_result['status'] == 'valid':\n",
    "            print(\"\\n🎉 Deployment is valid and ready for API serving!\")\n",
    "        else:\n",
    "            print(\"\\n❌ Deployment validation failed:\")\n",
    "            for issue in validate_result['issues']:\n",
    "                print(f\"   - {issue}\")\n",
    "    else:\n",
    "        print(\"❌ Validation failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the metadata\n",
    "if package_result:\n",
    "    metadata_path = Path(package_result['metadata_path'])\n",
    "    \n",
    "    if metadata_path.exists():\n",
    "        with open(metadata_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        \n",
    "        print(\"📄 Model metadata:\")\n",
    "        print(json.dumps(metadata, indent=2))\n",
    "    else:\n",
    "        print(f\"❌ Metadata file not found: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Step 3: Start the FastAPI Service\n",
    "\n",
    "Now let's start the API service and test it. We'll copy our deployment artifacts to the expected location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Copy model and metadata to the expected API location\n",
    "if package_result:\n",
    "    deployment_dir = Path(package_result['output_dir'])\n",
    "    \n",
    "    # Copy model\n",
    "    api_model_path = TEMP_MODELS_DIR / 'model.joblib'\n",
    "    api_metadata_path = TEMP_MODELS_DIR / 'metadata.json'\n",
    "    \n",
    "    shutil.copy2(deployment_dir / 'model.joblib', api_model_path)\n",
    "    shutil.copy2(deployment_dir / 'metadata.json', api_metadata_path)\n",
    "    \n",
    "    print(f\"📋 Copied model to API location:\")\n",
    "    print(f\"   Model: {api_model_path}\")\n",
    "    print(f\"   Metadata: {api_metadata_path}\")\n",
    "    \n",
    "    # Check if FastAPI can import\n",
    "    try:\n",
    "        import uvicorn\n",
    "        import fastapi\n",
    "        print(\"\\n✅ FastAPI dependencies available\")\n",
    "        print(f\"   FastAPI version: {fastapi.__version__}\")\n",
    "        print(f\"   Uvicorn version: {uvicorn.__version__}\")\n",
    "    except ImportError as e:\n",
    "        print(f\"\\n❌ FastAPI dependencies missing: {e}\")\n",
    "        print(\"Please install: pip install fastapi uvicorn pydantic\")\nelse:\n",
    "    print(\"❌ Cannot proceed without packaged model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting the API Server\n",
    "\n",
    "**Note**: In a Jupyter notebook, we can't easily run the FastAPI server in the background. \n",
    "\n",
    "**Option 1**: Run in a separate terminal:\n",
    "```bash\n",
    "cd /path/to/repository\n",
    "PYTHONPATH=$PWD uvicorn infrastructure.api.main:app --host 0.0.0.0 --port 8000\n",
    "```\n",
    "\n",
    "**Option 2**: Use the cells below to test if a server is already running.\n",
    "\n",
    "Let's check if an API server is available and test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if API server is running\n",
    "API_BASE_URL = \"http://localhost:8000\"\n",
    "\n",
    "def test_api_connection():\n",
    "    \"\"\"Test if the API server is running and responsive.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{API_BASE_URL}/health\", timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            return True, response.json()\n",
    "        else:\n",
    "            return False, f\"HTTP {response.status_code}\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return False, str(e)\n",
    "\n",
    "# Check connection\n",
    "is_connected, result = test_api_connection()\n",
    "\n",
    "if is_connected:\n",
    "    print(\"🎉 API server is running!\")\n",
    "    print(\"📊 Health status:\")\n",
    "    print(json.dumps(result, indent=2))\nelse:\n",
    "    print(f\"❌ API server not accessible: {result}\")\n",
    "    print(\"\\n💡 To start the server, run in a terminal:\")\n",
    "    print(f\"   cd {ROOT_DIR}\")\n",
    "    print(\"   PYTHONPATH=$PWD uvicorn infrastructure.api.main:app --host 0.0.0.0 --port 8000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧪 Step 4: Test API Endpoints\n",
    "\n",
    "If the API server is running, let's test all the endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_api_endpoints():\n",
    "    \"\"\"Test all API endpoints and display results.\"\"\"\n",
    "    \n",
    "    # Test health endpoint\n",
    "    print(\"🏥 Testing /health endpoint:\")\n",
    "    try:\n",
    "        response = requests.get(f\"{API_BASE_URL}/health\")\n",
    "        if response.status_code == 200:\n",
    "            health_data = response.json()\n",
    "            print(json.dumps(health_data, indent=2))\n",
    "            model_loaded = health_data.get('model_loaded', False)\n",
    "            print(f\"   Model loaded: {'✅' if model_loaded else '❌'}\")\n",
    "        else:\n",
    "            print(f\"   ❌ HTTP {response.status_code}: {response.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Error: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # Test version endpoint\n",
    "    print(\"📋 Testing /version endpoint:\")\n",
    "    try:\n",
    "        response = requests.get(f\"{API_BASE_URL}/version\")\n",
    "        if response.status_code == 200:\n",
    "            version_data = response.json()\n",
    "            print(json.dumps(version_data, indent=2))\n",
    "        else:\n",
    "            print(f\"   ❌ HTTP {response.status_code}: {response.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Error: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # Test metrics endpoint\n",
    "    print(\"📊 Testing /metrics endpoint:\")\n",
    "    try:\n",
    "        response = requests.get(f\"{API_BASE_URL}/metrics\")\n",
    "        if response.status_code == 200:\n",
    "            metrics_data = response.json()\n",
    "            print(json.dumps(metrics_data, indent=2))\n",
    "        else:\n",
    "            print(f\"   ❌ HTTP {response.status_code}: {response.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Error: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # Test prediction endpoint\n",
    "    print(\"🔮 Testing /predict endpoint:\")\n",
    "    \n",
    "    # Test with optimal conditions\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"name\": \"Optimal conditions\",\n",
    "            \"data\": {\n",
    "                \"temperature\": 450.0,\n",
    "                \"pressure\": 2.5,\n",
    "                \"flow\": 120.0,\n",
    "                \"time\": 60.0\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"High temperature\",\n",
    "            \"data\": {\n",
    "                \"temperature\": 480.0,\n",
    "                \"pressure\": 2.5,\n",
    "                \"flow\": 120.0,\n",
    "                \"time\": 60.0\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Low pressure\",\n",
    "            \"data\": {\n",
    "                \"temperature\": 450.0,\n",
    "                \"pressure\": 2.0,\n",
    "                \"flow\": 120.0,\n",
    "                \"time\": 60.0\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for test_case in test_cases:\n",
    "        print(f\"\\n🧪 Testing: {test_case['name']}\")\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                f\"{API_BASE_URL}/predict\",\n",
    "                json=test_case['data'],\n",
    "                headers={\"Content-Type\": \"application/json\"}\n",
    "            )\n",
    "            if response.status_code == 200:\n",
    "                prediction_data = response.json()\n",
    "                print(f\"   Input: {test_case['data']}\")\n",
    "                print(f\"   Prediction: {prediction_data['prediction']:.2f}% yield\")\n",
    "                print(f\"   Confidence: {prediction_data['confidence']:.3f}\")\n",
    "                print(f\"   Model version: {prediction_data['model_version']}\")\n",
    "            else:\n",
    "                print(f\"   ❌ HTTP {response.status_code}: {response.text}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error: {e}\")\n",
    "\n",
    "# Run the tests if API is available\n",
    "is_connected, _ = test_api_connection()\n",
    "if is_connected:\n",
    "    test_api_endpoints()\nelse:\n",
    "    print(\"❌ API server not available. Please start the server first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧪 Step 5: Validate Input Schemas\n",
    "\n",
    "Test the API's input validation to ensure it properly rejects invalid data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_input_validation():\n",
    "    \"\"\"Test API input validation with invalid data.\"\"\"\n",
    "    \n",
    "    invalid_test_cases = [\n",
    "        {\n",
    "            \"name\": \"Temperature too high\",\n",
    "            \"data\": {\n",
    "                \"temperature\": 700.0,  # Above max of 600\n",
    "                \"pressure\": 2.5,\n",
    "                \"flow\": 120.0,\n",
    "                \"time\": 60.0\n",
    "            },\n",
    "            \"expected_status\": 422\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Negative pressure\",\n",
    "            \"data\": {\n",
    "                \"temperature\": 450.0,\n",
    "                \"pressure\": -1.0,  # Below min of 0.1\n",
    "                \"flow\": 120.0,\n",
    "                \"time\": 60.0\n",
    "            },\n",
    "            \"expected_status\": 422\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Missing field\",\n",
    "            \"data\": {\n",
    "                \"temperature\": 450.0,\n",
    "                \"pressure\": 2.5,\n",
    "                # Missing flow and time\n",
    "            },\n",
    "            \"expected_status\": 422\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Wrong data type\",\n",
    "            \"data\": {\n",
    "                \"temperature\": \"not_a_number\",\n",
    "                \"pressure\": 2.5,\n",
    "                \"flow\": 120.0,\n",
    "                \"time\": 60.0\n",
    "            },\n",
    "            \"expected_status\": 422\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"🛡️ Testing input validation:\")\n",
    "    \n",
    "    for test_case in invalid_test_cases:\n",
    "        print(f\"\\n🧪 Testing: {test_case['name']}\")\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                f\"{API_BASE_URL}/predict\",\n",
    "                json=test_case['data'],\n",
    "                headers={\"Content-Type\": \"application/json\"}\n",
    "            )\n",
    "            \n",
    "            if response.status_code == test_case['expected_status']:\n",
    "                print(f\"   ✅ Correctly rejected with HTTP {response.status_code}\")\n",
    "                if response.status_code == 422:\n",
    "                    error_data = response.json()\n",
    "                    print(f\"   📝 Error details: {error_data.get('detail', 'No details')}\")\n",
    "            else:\n",
    "                print(f\"   ❌ Expected HTTP {test_case['expected_status']}, got {response.status_code}\")\n",
    "                print(f\"   📝 Response: {response.text}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error: {e}\")\n",
    "\n",
    "# Run validation tests if API is available\n",
    "is_connected, _ = test_api_connection()\n",
    "if is_connected:\n",
    "    test_input_validation()\nelse:\n",
    "    print(\"❌ API server not available for validation testing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Step 6: Performance Testing\n",
    "\n",
    "Let's test the API performance with multiple requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import statistics\n",
    "\n",
    "def measure_response_time(test_data):\n",
    "    \"\"\"Measure response time for a single API call.\"\"\"\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{API_BASE_URL}/predict\",\n",
    "            json=test_data,\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            timeout=10\n",
    "        )\n",
    "        end_time = time.time()\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return end_time - start_time, True\n",
    "        else:\n",
    "            return end_time - start_time, False\n",
    "    except Exception:\n",
    "        return time.time() - start_time, False\n",
    "\n",
    "def performance_test(num_requests=50):\n",
    "    \"\"\"Run performance test with multiple concurrent requests.\"\"\"\n",
    "    \n",
    "    test_data = {\n",
    "        \"temperature\": 450.0,\n",
    "        \"pressure\": 2.5,\n",
    "        \"flow\": 120.0,\n",
    "        \"time\": 60.0\n",
    "    }\n",
    "    \n",
    "    print(f\"⚡ Running performance test with {num_requests} requests...\")\n",
    "    \n",
    "    # Sequential requests\n",
    "    print(\"\\n📈 Sequential requests:\")\n",
    "    sequential_times = []\n",
    "    sequential_success = 0\n",
    "    \n",
    "    start_total = time.time()\n",
    "    for i in range(min(10, num_requests)):  # Limit sequential to 10 for time\n",
    "        response_time, success = measure_response_time(test_data)\n",
    "        sequential_times.append(response_time)\n",
    "        if success:\n",
    "            sequential_success += 1\n",
    "    end_total = time.time()\n",
    "    \n",
    "    print(f\"   ✅ Success rate: {sequential_success}/{len(sequential_times)} ({100*sequential_success/len(sequential_times):.1f}%)\")\n",
    "    print(f\"   ⏱️ Average response time: {statistics.mean(sequential_times)*1000:.1f}ms\")\n",
    "    print(f\"   ⏱️ Median response time: {statistics.median(sequential_times)*1000:.1f}ms\")\n",
    "    print(f\"   📊 Total time: {end_total - start_total:.2f}s\")\n",
    "    \n",
    "    # Concurrent requests\n",
    "    print(\"\\n🔄 Concurrent requests:\")\n",
    "    concurrent_times = []\n",
    "    concurrent_success = 0\n",
    "    \n",
    "    start_total = time.time()\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        futures = [executor.submit(measure_response_time, test_data) for _ in range(min(20, num_requests))]\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            response_time, success = future.result()\n",
    "            concurrent_times.append(response_time)\n",
    "            if success:\n",
    "                concurrent_success += 1\n",
    "    end_total = time.time()\n",
    "    \n",
    "    print(f\"   ✅ Success rate: {concurrent_success}/{len(concurrent_times)} ({100*concurrent_success/len(concurrent_times):.1f}%)\")\n",
    "    print(f\"   ⏱️ Average response time: {statistics.mean(concurrent_times)*1000:.1f}ms\")\n",
    "    print(f\"   ⏱️ Median response time: {statistics.median(concurrent_times)*1000:.1f}ms\")\n",
    "    print(f\"   📊 Total time: {end_total - start_total:.2f}s\")\n",
    "    print(f\"   🚀 Throughput: {len(concurrent_times)/(end_total - start_total):.1f} requests/second\")\n",
    "\n",
    "# Run performance test if API is available\n",
    "is_connected, _ = test_api_connection()\n",
    "if is_connected:\n",
    "    performance_test()\nelse:\n",
    "    print(\"❌ API server not available for performance testing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🐳 Step 7: Docker Deployment Demo\n",
    "\n",
    "Let's examine the Docker configuration and understand how to deploy with containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Docker files\n",
    "dockerfile_api = ROOT_DIR / 'Dockerfile.api'\n",
    "docker_compose = ROOT_DIR / 'docker-compose.yml'\n",
    "\n",
    "print(\"🐳 Docker configuration files:\")\n",
    "print(f\"   API Dockerfile: {dockerfile_api} {'✅' if dockerfile_api.exists() else '❌'}\")\n",
    "print(f\"   Docker Compose: {docker_compose} {'✅' if docker_compose.exists() else '❌'}\")\n",
    "\n",
    "if dockerfile_api.exists():\n",
    "    print(\"\\n📄 Dockerfile.api contents:\")\n",
    "    with open(dockerfile_api, 'r') as f:\n",
    "        dockerfile_content = f.read()\n",
    "    print(dockerfile_content[:500] + \"...\" if len(dockerfile_content) > 500 else dockerfile_content)\n",
    "\n",
    "print(\"\\n🚀 Docker deployment commands:\")\n",
    "print(\"\")\n",
    "print(\"# Build the API image:\")\n",
    "print(f\"docker build -f Dockerfile.api -t semiconductor-ml-api .\")\n",
    "print(\"\")\n",
    "print(\"# Run the API container:\")\n",
    "print(\"docker run -p 8001:8000 \\\\\")\n",
    "print(\"  -v $(pwd)/temp_models:/app/temp_models \\\\\")\n",
    "print(\"  semiconductor-ml-api\")\n",
    "print(\"\")\n",
    "print(\"# Use docker-compose:\")\n",
    "print(\"docker-compose up model-api\")\n",
    "print(\"\")\n",
    "print(\"💡 The API will be available at http://localhost:8001 when using Docker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📋 Step 8: Check Docker Build (Optional)\n",
    "\n",
    "If Docker is available, let's test building the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_docker_availability():\n",
    "    \"\"\"Check if Docker is available and working.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(['docker', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            return True, result.stdout.strip()\n",
    "        else:\n",
    "            return False, \"Docker command failed\"\n",
    "    except FileNotFoundError:\n",
    "        return False, \"Docker not found\"\n",
    "\n",
    "def test_docker_build():\n",
    "    \"\"\"Test building the Docker image (dry run).\"\"\"\n",
    "    print(\"🐳 Testing Docker build...\")\n",
    "    \n",
    "    try:\n",
    "        # Do a dry run of the build process\n",
    "        result = subprocess.run(\n",
    "            ['docker', 'build', '-f', 'Dockerfile.api', '--dry-run', '.'],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            cwd=ROOT_DIR,\n",
    "            timeout=30\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"✅ Docker build validation successful\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"❌ Docker build validation failed: {result.stderr}\")\n",
    "            return False\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"⏰ Docker build test timed out\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Docker build test error: {e}\")\n",
    "        return False\n",
    "\n",
    "# Check Docker availability\n",
    "docker_available, docker_info = check_docker_availability()\n",
    "\n",
    "if docker_available:\n",
    "    print(f\"✅ Docker available: {docker_info}\")\n",
    "    \n",
    "    # Note: Actual build testing is commented out to avoid long build times\n",
    "    # Uncomment the next line if you want to test building\n",
    "    # test_docker_build()\n",
    "    \n",
    "    print(\"\\n💡 To build and test the Docker image manually:\")\n",
    "    print(f\"   cd {ROOT_DIR}\")\n",
    "    print(\"   docker build -f Dockerfile.api -t semiconductor-ml-api .\")\n",
    "    print(\"   docker run -p 8001:8000 -v $(pwd)/temp_models:/app/temp_models semiconductor-ml-api\")\n",
    "    \nelse:\n",
    "    print(f\"❌ Docker not available: {docker_info}\")\n",
    "    print(\"💡 Docker is optional for this module, but recommended for production deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📚 Step 9: Summary and Next Steps\n",
    "\n",
    "Let's summarize what we've accomplished and outline next steps for production deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎯 Module 9.1 - Model Deployment Summary\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check what we've completed\n",
    "completed_tasks = []\n",
    "pending_tasks = []\n",
    "\n",
    "# Model creation and training\n",
    "if model_path.exists():\n",
    "    completed_tasks.append(\"✅ Created and trained ML model\")\nelse:\n",
    "    pending_tasks.append(\"❌ Model creation failed\")\n",
    "\n",
    "# Model packaging\n",
    "if package_result and package_result.get('status') == 'exported':\n",
    "    completed_tasks.append(\"✅ Packaged model for deployment\")\nelse:\n",
    "    pending_tasks.append(\"❌ Model packaging failed\")\n",
    "\n",
    "# Validation\n",
    "if validate_result and validate_result.get('status') == 'valid':\n",
    "    completed_tasks.append(\"✅ Validated deployment artifacts\")\nelse:\n",
    "    pending_tasks.append(\"❌ Deployment validation failed\")\n",
    "\n",
    "# API testing\n",
    "is_connected, _ = test_api_connection()\n",
    "if is_connected:\n",
    "    completed_tasks.append(\"✅ Tested FastAPI endpoints\")\nelse:\n",
    "    pending_tasks.append(\"⚠️ API server not running (optional for notebook)\")\n",
    "\n",
    "# Docker\n",
    "docker_available, _ = check_docker_availability()\n",
    "if docker_available:\n",
    "    completed_tasks.append(\"✅ Docker available for containerization\")\nelse:\n",
    "    completed_tasks.append(\"⚠️ Docker not available (optional)\")\n",
    "\n",
    "print(\"\\n📋 Completed Tasks:\")\n",
    "for task in completed_tasks:\n",
    "    print(f\"   {task}\")\n",
    "\n",
    "if pending_tasks:\n",
    "    print(\"\\n⚠️ Pending Tasks:\")\n",
    "    for task in pending_tasks:\n",
    "        print(f\"   {task}\")\n",
    "\n",
    "print(\"\\n🚀 Key Achievements:\")\n",
    "print(\"   • Built end-to-end model deployment pipeline\")\n",
    "print(\"   • Created REST API with FastAPI and Pydantic validation\")\n",
    "print(\"   • Implemented proper model versioning and metadata\")\n",
    "print(\"   • Set up Docker containerization for production\")\n",
    "print(\"   • Demonstrated input validation and error handling\")\n",
    "print(\"   • Performed basic performance testing\")\n",
    "\n",
    "print(\"\\n🎯 Next Steps for Production:\")\n",
    "print(\"   1. Set up authentication and authorization\")\n",
    "print(\"   2. Implement proper logging and monitoring\")\n",
    "print(\"   3. Add model performance tracking\")\n",
    "print(\"   4. Set up CI/CD pipeline for automated deployment\")\n",
    "print(\"   5. Configure load balancing and auto-scaling\")\n",
    "print(\"   6. Implement model A/B testing\")\n",
    "print(\"   7. Add comprehensive error handling and alerting\")\n",
    "print(\"   8. Set up model drift detection\")\n",
    "\n",
    "print(\"\\n📖 Additional Resources:\")\n",
    "print(\"   • FastAPI documentation: https://fastapi.tiangolo.com/\")\n",
    "print(\"   • Docker best practices: https://docs.docker.com/develop/best-practices/\")\n",
    "print(\"   • MLOps patterns: https://ml-ops.org/\")\n",
    "print(\"   • Module fundamentals: 9.1-model-deployment-fundamentals.md\")\n",
    "print(\"   • Quick reference: 9.1-model-deployment-quick-ref.md\")\n",
    "\n",
    "print(\"\\n🎉 Congratulations! You've successfully completed Module 9.1 - Model Deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧹 Cleanup (Optional)\n",
    "\n",
    "Run this cell to clean up temporary files created during the demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def cleanup_demo_files():\n",
    "    \"\"\"Clean up temporary files created during the demo.\"\"\"\n",
    "    \n",
    "    cleanup_items = []\n",
    "    \n",
    "    # Model files\n",
    "    if model_path.exists():\n",
    "        cleanup_items.append(str(model_path))\n",
    "    \n",
    "    # Deployment directories\n",
    "    for item in TEMP_MODELS_DIR.glob('deployment_*'):\n",
    "        if item.is_dir():\n",
    "            cleanup_items.append(str(item))\n",
    "    \n",
    "    # API model files\n",
    "    api_model = TEMP_MODELS_DIR / 'model.joblib'\n",
    "    api_metadata = TEMP_MODELS_DIR / 'metadata.json'\n",
    "    \n",
    "    if api_model.exists():\n",
    "        cleanup_items.append(str(api_model))\n",
    "    if api_metadata.exists():\n",
    "        cleanup_items.append(str(api_metadata))\n",
    "    \n",
    "    if cleanup_items:\n",
    "        print(\"🧹 The following files/directories can be cleaned up:\")\n",
    "        for item in cleanup_items:\n",
    "            print(f\"   {item}\")\n",
    "        \n",
    "        response = input(\"\\nDo you want to delete these files? (y/N): \")\n",
    "        \n",
    "        if response.lower() in ['y', 'yes']:\n",
    "            for item in cleanup_items:\n",
    "                item_path = Path(item)\n",
    "                try:\n",
    "                    if item_path.is_dir():\n",
    "                        shutil.rmtree(item_path)\n",
    "                    else:\n",
    "                        item_path.unlink()\n",
    "                    print(f\"   ✅ Deleted: {item}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   ❌ Failed to delete {item}: {e}\")\n",
    "            print(\"\\n✅ Cleanup completed!\")\n",
    "        else:\n",
    "            print(\"\\n🚫 Cleanup cancelled\")\n",
    "    else:\n",
    "        print(\"🧹 No demo files found to clean up\")\n",
    "\n",
    "# Uncomment the next line to run cleanup\n",
    "# cleanup_demo_files()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
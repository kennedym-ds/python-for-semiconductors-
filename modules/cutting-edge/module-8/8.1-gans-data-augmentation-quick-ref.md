# Module 8.1 – GANs for Data Augmentation Quick Reference

## Basic Usage Commands

### Training a GAN Model
```bash
# Basic training with synthetic data
python 8.1-gans-data-augmentation-pipeline.py train --epochs 50 --save gan_model.joblib

# Training with custom parameters
python 8.1-gans-data-augmentation-pipeline.py train \
    --epochs 100 \
    --batch-size 32 \
    --image-size 64 \
    --lr-g 0.0002 \
    --lr-d 0.0001 \
    --save gan_model.joblib

# Training with real data path
python 8.1-gans-data-augmentation-pipeline.py train \
    --data-path datasets/wm811k \
    --epochs 200 \
    --save production_gan.joblib
```

### Generating Synthetic Samples
```bash
# Generate samples and save grid
python 8.1-gans-data-augmentation-pipeline.py generate \
    --model-path gan_model.joblib \
    --num-samples 64 \
    --output-grid samples.png

# Generate larger batch with custom grid layout
python 8.1-gans-data-augmentation-pipeline.py generate \
    --model-path gan_model.joblib \
    --num-samples 100 \
    --output-grid large_samples.png \
    --grid-nrow 10
```

### Evaluating Model Quality
```bash
# Basic evaluation
python 8.1-gans-data-augmentation-pipeline.py evaluate \
    --model-path gan_model.joblib

# Evaluation with reference data
python 8.1-gans-data-augmentation-pipeline.py evaluate \
    --model-path gan_model.joblib \
    --data-path datasets/wm811k
```

## Hyperparameters Reference

### Core Architecture Parameters

| Parameter | Default | Range | Description |
|-----------|---------|--------|-------------|
| `--image-size` | 64 | 32, 64 | Output image resolution (square) |
| `--batch-size` | 64 | 8-512 | Training batch size |
| `--epochs` | 50 | 10-1000 | Number of training epochs |

### Learning Rate Parameters

| Parameter | Default | Range | Description |
|-----------|---------|--------|-------------|
| `--lr-g` | 0.0002 | 1e-5 to 1e-2 | Generator learning rate |
| `--lr-d` | 0.0002 | 1e-5 to 1e-2 | Discriminator learning rate |

### System Parameters

| Parameter | Default | Description |
|-----------|---------|-------------|
| `--device` | auto | Force 'cpu' or 'cuda', auto-detects if not set |
| `--seed` | 42 | Random seed for reproducibility |

## Performance Tuning Guide

### CPU Optimization (Default Configuration)
```bash
# Optimized for CPU training
python 8.1-gans-data-augmentation-pipeline.py train \
    --epochs 30 \
    --batch-size 16 \
    --image-size 32 \
    --device cpu \
    --save cpu_model.joblib
```

### GPU Acceleration
```bash
# Optimized for GPU training
python 8.1-gans-data-augmentation-pipeline.py train \
    --epochs 200 \
    --batch-size 128 \
    --image-size 64 \
    --device cuda \
    --save gpu_model.joblib
```

### Quick Testing Setup
```bash
# Fast training for testing (< 60 seconds)
python 8.1-gans-data-augmentation-pipeline.py train \
    --epochs 2 \
    --batch-size 8 \
    --image-size 32 \
    --save test_model.joblib
```

## Common Issues and Solutions

### Training Stability Issues

**Problem**: Loss oscillations, training doesn't converge
```bash
# Solution: Reduce learning rates
python 8.1-gans-data-augmentation-pipeline.py train \
    --lr-g 0.0001 \
    --lr-d 0.00005 \
    --epochs 100
```

**Problem**: Mode collapse (generated images all look similar)
```bash
# Solution: Balance discriminator strength
python 8.1-gans-data-augmentation-pipeline.py train \
    --lr-g 0.0002 \
    --lr-d 0.0001 \
    --batch-size 32
```

### Memory Issues

**Problem**: CUDA out of memory
```bash
# Solution: Reduce batch size or image size
python 8.1-gans-data-augmentation-pipeline.py train \
    --batch-size 16 \
    --image-size 32
```

**Problem**: CPU memory usage too high
```bash
# Solution: Reduce batch size and workers
python 8.1-gans-data-augmentation-pipeline.py train \
    --batch-size 8
```

### Quality Issues

**Problem**: Generated images are blurry
```bash
# Solution: Train longer with stable parameters
python 8.1-gans-data-augmentation-pipeline.py train \
    --epochs 200 \
    --lr-g 0.0002 \
    --lr-d 0.0002
```

**Problem**: Generated images have artifacts
```bash
# Solution: Start with smaller image size
python 8.1-gans-data-augmentation-pipeline.py train \
    --image-size 32 \
    --epochs 100
```

## Python API Usage

### Basic Pipeline Usage
```python
from pathlib import Path
from modules.cutting_edge.module_8.gans_pipeline import GANsPipeline

# Create and train pipeline
pipeline = GANsPipeline(
    model_type='dcgan',
    image_size=64,
    batch_size=32,
    learning_rate_g=0.0002,
    learning_rate_d=0.0002
)

# Train the model
pipeline.fit(epochs=50)

# Generate samples
samples = pipeline.generate(num_samples=64)

# Save sample grid
pipeline.save_sample_grid('samples.png', num_samples=64, nrow=8)

# Evaluate quality
results = pipeline.evaluate()
print(f"Sample quality metrics: {results['metrics']}")

# Save model
pipeline.save(Path('my_gan.joblib'))

# Load model later
loaded_pipeline = GANsPipeline.load(Path('my_gan.joblib'))
```

### Advanced Usage
```python
# Custom training with progress monitoring
pipeline = GANsPipeline(
    image_size=64,
    batch_size=64,
    device='cuda' if torch.cuda.is_available() else 'cpu'
)

# Train with custom data
pipeline.fit(
    data_path='datasets/custom_wafers',
    epochs=100
)

# Generate with fixed noise for reproducibility
fixed_noise = torch.randn(64, 100, 1, 1)
samples = pipeline.generate(num_samples=64, fixed_noise=fixed_noise)

# Detailed evaluation
eval_results = pipeline.evaluate(data_path='datasets/custom_wafers')
print(f"FID Score: {eval_results['metrics'].get('fid_score', 'N/A')}")
```

## Output Formats

### JSON Response Structure

All CLI commands return JSON with consistent structure:

```json
{
  "status": "trained|generated|evaluated|error",
  "model_type": "dcgan",
  "metrics": {
    "num_samples": 64,
    "sample_mean": 0.02,
    "sample_std": 0.45,
    "fid_score": 85.3
  },
  "warnings": ["Generated samples may lack diversity"],
  "metadata": {
    "epochs_trained": 50,
    "training_time_seconds": 3621.4,
    "device": "cpu"
  }
}
```

### Error Handling
```json
{
  "status": "error",
  "error": "Model file not found: nonexistent.joblib",
  "error_type": "FileNotFoundError"
}
```

## Integration Examples

### Data Augmentation Pipeline
```bash
# Step 1: Train GAN on existing data
python 8.1-gans-data-augmentation-pipeline.py train \
    --data-path datasets/real_defects \
    --epochs 200 \
    --save defect_gan.joblib

# Step 2: Generate augmentation data
python 8.1-gans-data-augmentation-pipeline.py generate \
    --model-path defect_gan.joblib \
    --num-samples 1000 \
    --output-grid augmentation_samples.png

# Step 3: Evaluate quality
python 8.1-gans-data-augmentation-pipeline.py evaluate \
    --model-path defect_gan.joblib \
    --data-path datasets/real_defects
```

### Research Experiment Pipeline
```bash
# Experiment with different architectures
for lr in 0.0001 0.0002 0.0005; do
    python 8.1-gans-data-augmentation-pipeline.py train \
        --lr-g $lr \
        --lr-d $lr \
        --epochs 100 \
        --save "experiment_lr_${lr}.joblib"
done

# Compare results
for model in experiment_lr_*.joblib; do
    python 8.1-gans-data-augmentation-pipeline.py evaluate \
        --model-path $model \
        > "results_${model%.*}.json"
done
```

## Monitoring and Debugging

### Log Analysis
- Training logs include epoch-wise loss values
- Look for smooth convergence in both generator and discriminator losses
- Sudden spikes indicate training instability

### Visual Quality Checks
```bash
# Generate samples periodically during training
python 8.1-gans-data-augmentation-pipeline.py generate \
    --model-path checkpoint.joblib \
    --num-samples 64 \
    --output-grid "samples_epoch_$(date +%s).png"
```

### Performance Monitoring
- Monitor GPU memory usage with `nvidia-smi`
- CPU training typically uses 2-8 cores effectively
- Expected training times: 30min (CPU/32x32), 2hr (GPU/64x64)

## Best Practices Checklist

- [ ] Start with small image size (32x32) for initial experiments
- [ ] Use balanced learning rates (generator ≥ discriminator)
- [ ] Monitor training with periodic sample generation
- [ ] Validate on held-out real data, not just generated samples
- [ ] Save models at regular intervals during long training
- [ ] Use consistent random seeds for reproducible experiments
- [ ] Test CPU training first, then scale to GPU if needed
- [ ] Document hyperparameters and training details for reproducibility

## Troubleshooting Flowchart

1. **Training fails to start**: Check Python/PyTorch installation
2. **CUDA errors**: Verify GPU drivers, try `--device cpu`
3. **Memory errors**: Reduce `--batch-size`
4. **Poor quality**: Increase `--epochs`, check learning rates
5. **Mode collapse**: Reduce discriminator learning rate
6. **Slow training**: Consider smaller `--image-size` or GPU
7. **Import errors**: Verify `requirements-advanced.txt` installed

---
**Performance Note**: This implementation is optimized for educational use with CPU-friendly defaults. For production use with large datasets, consider GPU acceleration and advanced GAN variants (WGAN-GP, Progressive GAN).

# Module 8.2 - LLMs for Manufacturing NLP: Quick Reference

## CLI Commands

### Training Models
```bash
# Classification with classical backend (TF-IDF + Logistic Regression)
python 8.2-llm-manufacturing-nlp-pipeline.py train \
    --task classification \
    --backend classical \
    --target-type severity \
    --n-samples 500 \
    --save severity_model.joblib

# Classification for tool area prediction
python 8.2-llm-manufacturing-nlp-pipeline.py train \
    --task classification \
    --backend classical \
    --target-type tool_area \
    --n-samples 500 \
    --save tool_area_model.joblib

# Summarization with classical backend
python 8.2-llm-manufacturing-nlp-pipeline.py train \
    --task summarization \
    --backend classical \
    --n-samples 200 \
    --save summary_model.joblib

# With transformers backend (if available)
python 8.2-llm-manufacturing-nlp-pipeline.py train \
    --task classification \
    --backend transformers \
    --n-samples 300 \
    --save transformer_model.joblib
```

### Model Evaluation
```bash
# Evaluate trained model on test data
python 8.2-llm-manufacturing-nlp-pipeline.py evaluate \
    --model-path severity_model.joblib \
    --n-samples 200

# Quick evaluation with smaller dataset
python 8.2-llm-manufacturing-nlp-pipeline.py evaluate \
    --model-path tool_area_model.joblib \
    --n-samples 50
```

### Making Predictions
```bash
# Classify maintenance log severity
python 8.2-llm-manufacturing-nlp-pipeline.py predict \
    --model-path severity_model.joblib \
    --input-json '{"text":"Pump P-101 emergency shutdown due to overheating"}'

# Classify tool area
python 8.2-llm-manufacturing-nlp-pipeline.py predict \
    --model-path tool_area_model.joblib \
    --input-json '{"text":"Etcher E-301 plasma instability detected"}'

# Generate summary
python 8.2-llm-manufacturing-nlp-pipeline.py predict \
    --model-path summary_model.joblib \
    --input-json '{"text":"Day Shift Report - All tools normal. Completed 12 lots. Minor alarm on Tool A resolved."}'
```

## Key Parameters

### Task Types
- `classification`: Text classification (severity, tool area)
- `summarization`: Text summarization of reports

### Backend Options
- `classical`: TF-IDF + scikit-learn (always available)
- `transformers`: BERT/RoBERTa models (optional dependency)

### Target Types (Classification)
- `severity`: 0=Low, 1=Medium, 2=High
- `tool_area`: 0=Wet Bench, 1=Lithography, 2=Etch, 3=Deposition, 4=Metrology

## Expected Output Formats

### Training Output
```json
{
  "status": "trained",
  "task": "classification",
  "backend": "classical",
  "target_type": "severity",
  "model_type": "TF-IDF + Logistic Regression",
  "n_samples": 500,
  "metrics": {
    "accuracy": 0.96,
    "f1_score": 0.95,
    "estimated_loss": 45.2,
    "pws_percent": 96.0
  },
  "saved_to": "severity_model.joblib"
}
```

### Evaluation Output
```json
{
  "status": "evaluated",
  "task": "classification",
  "backend": "classical",
  "model_type": "TF-IDF + Logistic Regression",
  "n_samples": 200,
  "metrics": {
    "accuracy": 0.94,
    "f1_score": 0.93,
    "estimated_loss": 67.8,
    "pws_percent": 94.0
  }
}
```

### Classification Prediction
```json
{
  "status": "predicted",
  "task": "classification",
  "backend": "classical",
  "prediction": {
    "value": 2,
    "label": "High"
  }
}
```

### Summarization Prediction
```json
{
  "status": "predicted",
  "task": "summarization",
  "backend": "classical",
  "prediction": {
    "summary": "All tools normal; 12 lots completed; Tool A alarm resolved"
  }
}
```

### Error Output
```json
{
  "status": "error",
  "error": "Model file not found: missing_model.joblib",
  "model_path": "missing_model.joblib"
}
```

## Synthetic Data Patterns

### Maintenance Log Examples
- **Low Severity**: "Pump P-101 completed routine maintenance check"
- **Medium Severity**: "Reactor R-204 showing unusual vibration patterns during night shift"
- **High Severity**: "CVD-301 emergency shutdown triggered due to overheating"

### Equipment Types
- **Pump**: Wet bench, deposition tools
- **Reactor**: Etch, deposition tools
- **Furnace**: Deposition tools
- **Etcher**: Etch tools
- **CVD**: Deposition tools
- **Spinner**: Lithography tools
- **Handler**: Metrology tools

### Shift Report Structure
```
Day Shift Report - [Area] Area

All [area] tools operating within normal parameters.
Completed [N] wafer lots successfully.
[Optional issues and resolutions]
Overall yield: [XX.X]%
```

## Performance Benchmarks

### Runtime Targets
- **Training**: < 30 seconds for 500 samples
- **Evaluation**: < 10 seconds for 200 samples  
- **Prediction**: < 1 second per sample
- **Full test suite**: < 45 seconds

### Accuracy Targets
- **Classification**: > 90% accuracy on test data
- **F1-Score**: > 0.85 weighted average
- **PWS**: > 90% predictions within spec

### Resource Usage
- **Memory**: < 500MB during training
- **CPU**: Single core sufficient for inference
- **Storage**: < 10MB for saved models

## Troubleshooting Guide

### Common Issues

#### 1. Import Errors
```
ModuleNotFoundError: No module named 'transformers'
```
**Solution**: This is expected - transformers is optional. Pipeline automatically falls back to classical methods.

#### 2. Model Loading Errors
```
FileNotFoundError: Model file not found
```
**Solutions**:
- Check file path is correct
- Ensure model was saved successfully during training
- Use absolute paths if relative paths fail

#### 3. JSON Parsing Errors
```
JSONDecodeError: Expecting value
```
**Solutions**:
- Ensure input JSON is properly quoted: `'{"text":"sample text"}'`
- Escape quotes in text content
- Use single quotes around JSON, double quotes inside

#### 4. Memory Issues
```
Memory Error during training
```
**Solutions**:
- Reduce `--n-samples` parameter
- Use classical backend instead of transformers
- Reduce TF-IDF `max_features` in code

#### 5. Poor Performance
**Low accuracy (< 80%)**:
- Increase training samples (`--n-samples`)
- Check data quality and labeling
- Try different target type
- Consider ensemble methods

**Slow inference**:
- Use classical backend for production
- Reduce vocabulary size
- Batch multiple predictions

### Debugging Commands

#### Check Model Info
```bash
python -c "
import joblib
model_data = joblib.load('model.joblib')
print('Task:', model_data['task'])
print('Backend:', model_data['backend'])
print('Metadata:', model_data.get('metadata'))
"
```

#### Test Data Generation
```bash
# Generate sample data to inspect
python -c "
from 8.2-llm-manufacturing-nlp-pipeline import generate_maintenance_logs
data = generate_maintenance_logs(n=10)
print(data.head())
"
```

#### Validate Dependencies
```bash
python -c "
import sklearn; print('sklearn:', sklearn.__version__)
try:
    import transformers; print('transformers:', transformers.__version__)
except: print('transformers: not available')
import numpy; print('numpy:', numpy.__version__)
import pandas; print('pandas:', pandas.__version__)
"
```

## Integration Examples

### Python API Usage
```python
from pathlib import Path
import pandas as pd
from '8.2-llm-manufacturing-nlp-pipeline' import ManufacturingNLPPipeline

# Initialize pipeline
pipeline = ManufacturingNLPPipeline(
    task='classification',
    backend='classical',
    target_type='severity'
)

# Train on your data
data = pd.DataFrame({
    'text': ['Pump alarm triggered', 'Routine check completed'],
    'severity': [1, 0]
})
pipeline.fit(data)

# Make predictions
new_data = pd.DataFrame({'text': ['Emergency shutdown occurred']})
predictions = pipeline.predict(new_data)
print(f"Predicted severity: {predictions[0]}")

# Evaluate performance
metrics = pipeline.evaluate(data)
print(f"Accuracy: {metrics['accuracy']:.2f}")

# Save for later use
pipeline.save(Path('my_model.joblib'))
```

### Batch Processing Script
```python
import json
import sys
from pathlib import Path

def batch_classify(model_path, input_file, output_file):
    """Classify multiple texts from CSV file."""
    pipeline = ManufacturingNLPPipeline.load(Path(model_path))

    data = pd.read_csv(input_file)
    predictions = pipeline.predict(data)

    results = []
    for text, pred in zip(data['text'], predictions):
        results.append({
            'text': text,
            'prediction': int(pred),
            'label': pipeline.metadata.target_names[pred]
        })

    with open(output_file, 'w') as f:
        json.dump(results, f, indent=2)

if __name__ == '__main__':
    batch_classify(sys.argv[1], sys.argv[2], sys.argv[3])
```

Usage:
```bash
python batch_classify.py model.joblib input.csv output.json
```

## Advanced Configuration

### Custom Preprocessing
Modify the pipeline for your specific needs:

```python
# Add custom preprocessing steps
def custom_preprocess(text):
    # Normalize equipment IDs
    text = re.sub(r'([A-Z]+)-?(\d+)', r'\1-\2', text)

    # Expand abbreviations
    abbreviations = {
        'CVD': 'Chemical Vapor Deposition',
        'PVD': 'Physical Vapor Deposition'
    }
    for abbr, full in abbreviations.items():
        text = text.replace(abbr, full)

    return text

# Apply before training
data['text'] = data['text'].apply(custom_preprocess)
```

### Hyperparameter Tuning
```python
from sklearn.model_selection import GridSearchCV

# For classical pipeline
param_grid = {
    'model__C': [0.1, 1.0, 10.0],
    'model__class_weight': ['balanced', None],
    'vectorizer__max_features': [500, 1000, 2000],
    'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)]
}

# Note: This requires modifying the pipeline to expose sklearn components
```

### Production Deployment
```python
# Flask API wrapper
from flask import Flask, request, jsonify

app = Flask(__name__)
model = ManufacturingNLPPipeline.load('production_model.joblib')

@app.route('/predict', methods=['POST'])
def predict():
    data = request.json
    if 'text' not in data:
        return jsonify({'error': 'Missing text field'}), 400

    df = pd.DataFrame([data])
    prediction = model.predict(df)[0]

    return jsonify({
        'prediction': int(prediction),
        'label': model.metadata.target_names[prediction],
        'confidence': 'high'  # Add confidence scoring if needed
    })

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

This reference provides all the essential commands, patterns, and troubleshooting information needed to effectively use the manufacturing NLP pipeline in production environments.

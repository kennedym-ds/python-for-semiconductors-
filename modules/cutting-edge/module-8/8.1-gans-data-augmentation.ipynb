{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module 8.1 \u2013 GANs for Data Augmentation in Semiconductor Manufacturing\n",
        "\n",
        "This notebook demonstrates synthetic wafer map generation using Deep Convolutional GANs (DCGANs) for data augmentation in semiconductor manufacturing applications.\n",
        "\n",
        "## Learning Objectives\n",
        "- Understand GAN architecture and training dynamics\n",
        "- Generate synthetic wafer maps and defect patterns\n",
        "- Evaluate generated sample quality\n",
        "- Apply GANs for data augmentation in imbalanced datasets\n",
        "\n",
        "## Prerequisites\n",
        "- Basic understanding of neural networks\n",
        "- Familiarity with PyTorch tensors\n",
        "- Knowledge of semiconductor manufacturing terminology"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.utils as vutils\n",
        "from pathlib import Path\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add the module path to sys.path\n",
        "module_path = Path('.').resolve()\n",
        "if str(module_path) not in sys.path:\n",
        "    sys.path.append(str(module_path))\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Device available: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Understanding the Problem: Wafer Map Data Augmentation\n",
        "\n",
        "Semiconductor wafer maps show spatial patterns of defects across the wafer surface. These patterns are crucial for:\n",
        "- Process monitoring and control\n",
        "- Root cause analysis of yield issues\n",
        "- Predictive maintenance of equipment\n",
        "\n",
        "However, rare defect patterns are difficult to model due to limited training examples. GANs can generate synthetic examples to balance datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import our GAN pipeline\n",
        "from importlib import reload\n",
        "import subprocess\n",
        "\n",
        "# First, let's look at what our synthetic wafer data looks like\n",
        "# We'll use the pipeline to create and visualize synthetic wafer patterns\n",
        "\n",
        "# Create a simple synthetic dataset to understand the problem\n",
        "try:\n",
        "    # Import the pipeline components\n",
        "    import importlib.util\n",
        "    spec = importlib.util.spec_from_file_location(\n",
        "        \"gans_pipeline\", \n",
        "        \"8.1-gans-data-augmentation-pipeline.py\"\n",
        "    )\n",
        "    gans_module = importlib.util.module_from_spec(spec)\n",
        "    spec.loader.exec_module(gans_module)\n",
        "    \n",
        "    GANsPipeline = gans_module.GANsPipeline\n",
        "    SyntheticWaferDataset = gans_module.SyntheticWaferDataset\n",
        "    \n",
        "    print(\"Successfully imported GAN pipeline components\")\n",
        "except Exception as e:\n",
        "    print(f\"Import error: {e}\")\n",
        "    print(\"Make sure you're running this notebook from the module-8 directory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's first examine synthetic wafer patterns to understand what we're trying to generate\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "# Create a synthetic dataset for demonstration\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(64),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "synthetic_dataset = SyntheticWaferDataset(\n",
        "    num_samples=16, \n",
        "    image_size=64, \n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "# Create a dataloader\n",
        "dataloader = DataLoader(synthetic_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Get a batch of synthetic wafer patterns\n",
        "real_batch = next(iter(dataloader))\n",
        "\n",
        "# Visualize the synthetic wafer patterns\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Synthetic Wafer Patterns (Training Data)\")\n",
        "grid = vutils.make_grid(real_batch, nrow=4, normalize=True, value_range=(-1, 1))\n",
        "plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
        "plt.axis('off')\n",
        "\n",
        "# Show statistics\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Pixel Intensity Distribution\")\n",
        "pixel_values = real_batch.numpy().flatten()\n",
        "plt.hist(pixel_values, bins=50, alpha=0.7, color='blue')\n",
        "plt.xlabel('Pixel Intensity')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Batch shape: {real_batch.shape}\")\n",
        "print(f\"Value range: [{real_batch.min():.3f}, {real_batch.max():.3f}]\")\n",
        "print(f\"Mean: {real_batch.mean():.3f}, Std: {real_batch.std():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. GAN Architecture Overview\n",
        "\n",
        "Our DCGAN consists of two neural networks competing against each other:\n",
        "\n",
        "**Generator (G)**: Transforms random noise \u2192 realistic wafer patterns  \n",
        "**Discriminator (D)**: Distinguishes real wafer patterns from generated ones\n",
        "\n",
        "### Training Process:\n",
        "1. **D step**: Train discriminator to better identify real vs fake\n",
        "2. **G step**: Train generator to better fool the discriminator\n",
        "3. **Repeat**: Until equilibrium is reached\n",
        "\n",
        "Let's examine the network architectures:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create GAN pipeline and examine network architectures\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Initialize the pipeline\n",
        "pipeline = GANsPipeline(\n",
        "    model_type='dcgan',\n",
        "    image_size=64,\n",
        "    latent_dim=100,\n",
        "    batch_size=16,  # Small batch for notebook\n",
        "    device=device\n",
        ")\n",
        "\n",
        "# Create the networks to examine their structure\n",
        "generator = gans_module.Generator(latent_dim=100, image_size=64).to(device)\n",
        "discriminator = gans_module.Discriminator(image_size=64).to(device)\n",
        "\n",
        "print(\"=== Generator Architecture ===\")\n",
        "print(generator)\n",
        "print(f\"\\nTotal Generator Parameters: {sum(p.numel() for p in generator.parameters()):,}\")\n",
        "\n",
        "print(\"\\n=== Discriminator Architecture ===\")\n",
        "print(discriminator)\n",
        "print(f\"\\nTotal Discriminator Parameters: {sum(p.numel() for p in discriminator.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrate the data flow through the networks\n",
        "print(\"=== Data Flow Demonstration ===\")\n",
        "\n",
        "# Generate random noise (latent vector)\n",
        "batch_size = 4\n",
        "latent_dim = 100\n",
        "noise = torch.randn(batch_size, latent_dim, 1, 1, device=device)\n",
        "print(f\"Input noise shape: {noise.shape}\")\n",
        "\n",
        "# Forward pass through generator\n",
        "with torch.no_grad():\n",
        "    fake_images = generator(noise)\n",
        "    print(f\"Generated images shape: {fake_images.shape}\")\n",
        "    print(f\"Generated image range: [{fake_images.min():.3f}, {fake_images.max():.3f}]\")\n",
        "    \n",
        "    # Forward pass through discriminator\n",
        "    fake_scores = discriminator(fake_images)\n",
        "    print(f\"Discriminator scores shape: {fake_scores.shape}\")\n",
        "    print(f\"Discriminator scores (fake): {fake_scores.cpu().numpy()}\")\n",
        "    \n",
        "    # Test with real images\n",
        "    real_scores = discriminator(real_batch[:batch_size].to(device))\n",
        "    print(f\"Discriminator scores (real): {real_scores.cpu().numpy()}\")\n",
        "\n",
        "# Visualize untrained generator output\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.suptitle(\"Untrained Generator Output vs Real Data\", fontsize=14)\n",
        "\n",
        "# Untrained generator samples\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Untrained Generator\")\n",
        "fake_grid = vutils.make_grid(fake_images.cpu(), nrow=2, normalize=True, value_range=(-1, 1))\n",
        "plt.imshow(np.transpose(fake_grid, (1, 2, 0)))\n",
        "plt.axis('off')\n",
        "\n",
        "# Real data\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Real Wafer Patterns\")\n",
        "real_grid = vutils.make_grid(real_batch[:batch_size], nrow=2, normalize=True, value_range=(-1, 1))\n",
        "plt.imshow(np.transpose(real_grid, (1, 2, 0)))\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nObservation: Untrained generator produces random noise-like patterns\")\n",
        "print(\"Goal: Train the generator to produce realistic wafer patterns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Training the GAN\n",
        "\n",
        "Now let's train our GAN for a few epochs to see how it learns to generate realistic wafer patterns. We'll use a short training run suitable for an interactive notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the GAN for a short demonstration\n",
        "print(\"Starting GAN training...\")\n",
        "print(\"Note: This is a short training run for demonstration purposes\")\n",
        "print(\"For production use, train for 50-200 epochs\")\n",
        "\n",
        "# Train the pipeline\n",
        "trained_pipeline = pipeline.fit(\n",
        "    data_path=None,  # Use synthetic data\n",
        "    epochs=5  # Short training for notebook demonstration\n",
        ")\n",
        "\n",
        "print(\"\\nTraining completed!\")\n",
        "print(f\"Final metadata: {trained_pipeline.metadata}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Evaluating Generated Samples\n",
        "\n",
        "Let's examine the quality of our trained generator and compare it with the untrained version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate samples from the trained model\n",
        "num_samples = 16\n",
        "generated_samples = trained_pipeline.generate(num_samples)\n",
        "\n",
        "print(f\"Generated {num_samples} samples\")\n",
        "print(f\"Sample shape: {generated_samples.shape}\")\n",
        "print(f\"Sample range: [{generated_samples.min():.3f}, {generated_samples.max():.3f}]\")\n",
        "\n",
        "# Create comparison visualization\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Trained generator samples\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.title(\"Trained Generator Output\", fontsize=12)\n",
        "generated_grid = vutils.make_grid(generated_samples.cpu(), nrow=4, normalize=True, value_range=(-1, 1))\n",
        "plt.imshow(np.transpose(generated_grid, (1, 2, 0)))\n",
        "plt.axis('off')\n",
        "\n",
        "# Real training data\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.title(\"Real Training Data\", fontsize=12)\n",
        "real_grid = vutils.make_grid(real_batch[:num_samples], nrow=4, normalize=True, value_range=(-1, 1))\n",
        "plt.imshow(np.transpose(real_grid, (1, 2, 0)))\n",
        "plt.axis('off')\n",
        "\n",
        "# Pixel intensity distributions\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.title(\"Pixel Intensity Comparison\", fontsize=12)\n",
        "generated_pixels = generated_samples.cpu().numpy().flatten()\n",
        "real_pixels = real_batch[:num_samples].numpy().flatten()\n",
        "plt.hist(real_pixels, bins=50, alpha=0.7, label='Real Data', color='blue')\n",
        "plt.hist(generated_pixels, bins=50, alpha=0.7, label='Generated', color='red')\n",
        "plt.xlabel('Pixel Intensity')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Training progress (if available)\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.title(\"Training Metrics\", fontsize=12)\n",
        "# This would show loss curves in a full training run\n",
        "plt.text(0.5, 0.5, f\"Training completed\\nEpochs: {trained_pipeline.metadata.epochs_trained}\\nFinal D Loss: {trained_pipeline.metadata.final_d_loss:.3f}\\nFinal G Loss: {trained_pipeline.metadata.final_g_loss:.3f}\", \n",
        "         ha='center', va='center', transform=plt.gca().transAxes, fontsize=10)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model quantitatively\n",
        "evaluation_results = trained_pipeline.evaluate()\n",
        "\n",
        "print(\"=== Model Evaluation Results ===\")\n",
        "print(json.dumps(evaluation_results, indent=2))\n",
        "\n",
        "# Analyze the metrics\n",
        "metrics = evaluation_results['metrics']\n",
        "warnings = evaluation_results['warnings']\n",
        "\n",
        "print(\"\\n=== Quality Assessment ===\")\n",
        "print(f\"Sample diversity (std): {metrics['sample_std']:.3f}\")\n",
        "print(f\"Sample mean: {metrics['sample_mean']:.3f}\")\n",
        "print(f\"Sample range: [{metrics['sample_min']:.3f}, {metrics['sample_max']:.3f}]\")\n",
        "\n",
        "if warnings:\n",
        "    print(\"\\n\u26a0\ufe0f  Warnings:\")\n",
        "    for warning in warnings:\n",
        "        print(f\"  - {warning}\")\n",
        "else:\n",
        "    print(\"\\n\u2705 No quality warnings detected\")\n",
        "\n",
        "print(\"\\n\ud83d\udcca Note: For production use, consider training for more epochs to improve quality\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Exploring the Latent Space\n",
        "\n",
        "One of the powerful aspects of GANs is the learned latent space. We can interpolate between points in latent space to generate smooth transitions between different wafer patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrate latent space interpolation\n",
        "def interpolate_latent(generator, z1, z2, steps=8):\n",
        "    \"\"\"Interpolate between two latent vectors.\"\"\"\n",
        "    alphas = np.linspace(0, 1, steps)\n",
        "    interpolated_images = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for alpha in alphas:\n",
        "            z_interp = (1 - alpha) * z1 + alpha * z2\n",
        "            generated = generator(z_interp)\n",
        "            interpolated_images.append(generated)\n",
        "    \n",
        "    return torch.cat(interpolated_images, dim=0)\n",
        "\n",
        "# Create two random latent vectors\n",
        "z1 = torch.randn(1, 100, 1, 1, device=device)\n",
        "z2 = torch.randn(1, 100, 1, 1, device=device)\n",
        "\n",
        "# Generate interpolation\n",
        "interpolated = interpolate_latent(trained_pipeline.generator, z1, z2, steps=8)\n",
        "\n",
        "# Visualize interpolation\n",
        "plt.figure(figsize=(16, 4))\n",
        "plt.suptitle(\"Latent Space Interpolation: Smooth Transitions Between Wafer Patterns\", fontsize=14)\n",
        "\n",
        "for i in range(8):\n",
        "    plt.subplot(1, 8, i+1)\n",
        "    image = interpolated[i].cpu().squeeze()\n",
        "    plt.imshow(image, cmap='gray', vmin=-1, vmax=1)\n",
        "    plt.title(f\"Step {i+1}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Observation: Smooth interpolation indicates good latent space structure\")\n",
        "print(\"This suggests the generator has learned meaningful representations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Practical Application: Data Augmentation\n",
        "\n",
        "Let's demonstrate how to use our trained GAN for data augmentation in a classification scenario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate a data augmentation scenario\n",
        "print(\"=== Data Augmentation Demonstration ===\")\n",
        "\n",
        "# Original dataset size\n",
        "original_data_size = 100\n",
        "print(f\"Original dataset size: {original_data_size} samples\")\n",
        "\n",
        "# Generate additional synthetic samples\n",
        "augmentation_samples = 200\n",
        "synthetic_data = trained_pipeline.generate(augmentation_samples)\n",
        "\n",
        "print(f\"Generated additional samples: {augmentation_samples}\")\n",
        "print(f\"Augmented dataset size: {original_data_size + augmentation_samples} samples\")\n",
        "print(f\"Data increase: {(augmentation_samples / original_data_size) * 100:.0f}%\")\n",
        "\n",
        "# Save a sample grid for inspection\n",
        "sample_grid_path = \"augmentation_samples.png\"\n",
        "trained_pipeline.save_sample_grid(\n",
        "    sample_grid_path, \n",
        "    num_samples=64, \n",
        "    nrow=8\n",
        ")\n",
        "print(f\"\\nSample grid saved to: {sample_grid_path}\")\n",
        "\n",
        "# Show a subset of the generated augmentation data\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.title(\"Generated Data for Augmentation\")\n",
        "augmentation_grid = vutils.make_grid(\n",
        "    synthetic_data[:32].cpu(), \n",
        "    nrow=8, \n",
        "    normalize=True, \n",
        "    value_range=(-1, 1)\n",
        ")\n",
        "plt.imshow(np.transpose(augmentation_grid, (1, 2, 0)))\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\ud83d\udcc8 Benefits of GAN-based augmentation:\")\n",
        "print(\"  \u2022 Increases dataset size without manual labeling\")\n",
        "print(\"  \u2022 Provides diverse patterns for better generalization\")\n",
        "print(\"  \u2022 Particularly valuable for rare defect patterns\")\n",
        "print(\"  \u2022 Can be conditioned on specific defect types (advanced GANs)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Model Persistence and Deployment\n",
        "\n",
        "Let's demonstrate how to save and load the trained model for production use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "model_path = Path(\"trained_wafer_gan.joblib\")\n",
        "trained_pipeline.save(model_path)\n",
        "print(f\"Model saved to: {model_path}\")\n",
        "print(f\"Model file size: {model_path.stat().st_size / 1024 / 1024:.2f} MB\")\n",
        "\n",
        "# Load the model and verify it works\n",
        "loaded_pipeline = GANsPipeline.load(model_path)\n",
        "print(\"\\nModel loaded successfully!\")\n",
        "\n",
        "# Verify the loaded model works\n",
        "test_samples = loaded_pipeline.generate(4)\n",
        "print(f\"Generated {test_samples.shape[0]} test samples from loaded model\")\n",
        "\n",
        "# Compare metadata\n",
        "print(\"\\n=== Model Metadata ===\")\n",
        "if loaded_pipeline.metadata:\n",
        "    metadata = loaded_pipeline.metadata\n",
        "    print(f\"Model type: {metadata.model_type}\")\n",
        "    print(f\"Image size: {metadata.image_size}\")\n",
        "    print(f\"Training epochs: {metadata.epochs_trained}\")\n",
        "    print(f\"Training time: {metadata.training_time_seconds:.1f} seconds\")\n",
        "    print(f\"Device used: {metadata.device}\")\n",
        "    print(f\"Timestamp: {metadata.timestamp}\")\n",
        "\n",
        "# Visualize samples from loaded model\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.title(\"Samples from Loaded Model\")\n",
        "test_grid = vutils.make_grid(test_samples.cpu(), nrow=4, normalize=True, value_range=(-1, 1))\n",
        "plt.imshow(np.transpose(test_grid, (1, 2, 0)))\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\u2705 Model persistence working correctly!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Production Considerations and Next Steps\n",
        "\n",
        "This notebook demonstrated the basics of GAN-based data augmentation for semiconductor manufacturing. Here are key considerations for production deployment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Performance and scaling analysis\n",
        "print(\"=== Production Considerations ===\")\n",
        "print()\n",
        "\n",
        "# Timing analysis\n",
        "import time\n",
        "\n",
        "# Time sample generation\n",
        "start_time = time.time()\n",
        "batch_samples = trained_pipeline.generate(100)\n",
        "generation_time = time.time() - start_time\n",
        "\n",
        "print(f\"\u23f1\ufe0f  Performance Metrics:\")\n",
        "print(f\"   Generation time for 100 samples: {generation_time:.2f} seconds\")\n",
        "print(f\"   Samples per second: {100 / generation_time:.1f}\")\n",
        "print(f\"   Memory usage: ~{torch.cuda.memory_allocated() / 1024 / 1024:.0f} MB\" if torch.cuda.is_available() else \"   Memory usage: CPU mode\")\n",
        "print()\n",
        "\n",
        "print(\"\ud83d\ude80 Scaling Recommendations:\")\n",
        "print(\"   \u2022 CPU training: Suitable for 32x32 images, prototyping\")\n",
        "print(\"   \u2022 GPU training: Recommended for 64x64+ images, production\")\n",
        "print(\"   \u2022 Batch generation: Process multiple samples efficiently\")\n",
        "print(\"   \u2022 Model optimization: Consider quantization for deployment\")\n",
        "print()\n",
        "\n",
        "print(\"\ud83d\udcca Quality Improvements:\")\n",
        "print(\"   \u2022 Train for 50-200 epochs for production quality\")\n",
        "print(\"   \u2022 Use larger datasets when available\")\n",
        "print(\"   \u2022 Implement progressive growing for high resolution\")\n",
        "print(\"   \u2022 Consider WGAN-GP for improved stability\")\n",
        "print()\n",
        "\n",
        "print(\"\ud83d\udd27 Integration Tips:\")\n",
        "print(\"   \u2022 Validate on held-out real data\")\n",
        "print(\"   \u2022 Monitor downstream model performance\")\n",
        "print(\"   \u2022 Start with 10-20% synthetic data in augmented datasets\")\n",
        "print(\"   \u2022 Implement quality control gates for generated samples\")\n",
        "print()\n",
        "\n",
        "print(\"\ud83d\udcda Advanced Topics to Explore:\")\n",
        "print(\"   \u2022 Conditional GANs for specific defect types\")\n",
        "print(\"   \u2022 Progressive GANs for higher resolution\")\n",
        "print(\"   \u2022 StyleGAN for fine-grained control\")\n",
        "print(\"   \u2022 FID/KID metrics for quantitative evaluation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, we successfully:\n",
        "\n",
        "1. **Understood the problem**: Data scarcity in semiconductor defect pattern datasets\n",
        "2. **Implemented DCGAN**: Built generator and discriminator networks for wafer map synthesis\n",
        "3. **Trained the model**: Demonstrated adversarial training process\n",
        "4. **Evaluated quality**: Used visual inspection and quantitative metrics\n",
        "5. **Explored latent space**: Showed smooth interpolations between patterns\n",
        "6. **Applied to augmentation**: Generated synthetic data for dataset expansion\n",
        "7. **Demonstrated persistence**: Saved and loaded trained models\n",
        "\n",
        "### Key Takeaways:\n",
        "- GANs can generate realistic wafer patterns for data augmentation\n",
        "- Even short training runs show promising results\n",
        "- Proper evaluation is crucial for production deployment\n",
        "- Model persistence enables reuse and deployment\n",
        "\n",
        "### Next Steps:\n",
        "- Train for more epochs with larger datasets\n",
        "- Implement advanced GAN variants (WGAN-GP, Progressive GAN)\n",
        "- Integrate with downstream classification pipelines\n",
        "- Develop conditional generation for specific defect types\n",
        "\n",
        "This foundation provides a solid starting point for GAN-based data augmentation in semiconductor manufacturing applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean up generated files (optional)\n",
        "import os\n",
        "\n",
        "print(\"Generated files in this session:\")\n",
        "for file in [\"trained_wafer_gan.joblib\", \"augmentation_samples.png\"]:\n",
        "    if os.path.exists(file):\n",
        "        size = os.path.getsize(file)\n",
        "        print(f\"  {file}: {size / 1024:.1f} KB\")\n",
        "    else:\n",
        "        print(f\"  {file}: Not found\")\n",
        "\n",
        "print(\"\\n\ud83c\udf89 Module 8.1 GAN demonstration complete!\")\n",
        "print(\"Check the pipeline script and documentation for production usage.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}

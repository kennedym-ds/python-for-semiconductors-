# Module 10.3: Documentation & Reproducibility Quick Reference

## Essential Commands

### Documentation Generation
```bash
# Convert notebooks to markdown
python 10.3-documentation-reproducibility-pipeline.py generate-docs \
  --input notebooks/ --output docs/ --format markdown

# Convert to both markdown and HTML
python 10.3-documentation-reproducibility-pipeline.py generate-docs \
  --input notebooks/ --output docs/ --format both
```

### Dataset Path Validation
```bash
# Validate all module paths
python 10.3-documentation-reproducibility-pipeline.py validate-paths \
  --modules-dir ../../

# Check specific module
python 10.3-documentation-reproducibility-pipeline.py validate-paths \
  --modules-dir ../foundation/module-3/
```

### Environment Export
```bash
# Export conda environment
python 10.3-documentation-reproducibility-pipeline.py export-env \
  --output environment.yml --format conda

# Export pip requirements
python 10.3-documentation-reproducibility-pipeline.py export-env \
  --output requirements.txt --format pip
```

### MkDocs Setup
```bash
# Initialize documentation site
python 10.3-documentation-reproducibility-pipeline.py setup-mkdocs \
  --project-dir ./docs-site/

# Build documentation site
python 10.3-documentation-reproducibility-pipeline.py build-docs \
  --project-dir ./docs-site/
```

## Standard Dataset Path Pattern

### Required Pattern (per copilot instructions)
```python
# ✅ Correct pattern for all modules
DATA_DIR = Path('../../../datasets').resolve()
data = pd.read_csv(DATA_DIR / 'secom' / 'secom.data')
```

### Common Mistakes to Avoid
```python
# ❌ Flat dataset paths
# Anti-pattern (for illustration only):
# data = pd.read_csv('datasets/secom.FLAT')

# Correct pattern:
from pathlib import Path
DATA_DIR = Path('../../../datasets').resolve()
secom_path = DATA_DIR / 'secom' / 'secom.data'
data = pd.read_csv(secom_path)

# ❌ Hard-coded absolute paths
# Anti-pattern (absolute path):
# data = pd.read_csv('/home/user/datasets/secom.FLAT')

# Correct pattern:
from pathlib import Path
DATA_DIR = Path('../../../datasets').resolve()
data = pd.read_csv(DATA_DIR / 'secom' / 'secom.data')

# ❌ Inconsistent relative depth
# Anti-pattern (inconsistent relative depth):
# data = pd.read_csv('../datasets/secom.FLAT')

# Correct pattern:
from pathlib import Path
DATA_DIR = Path('../../../datasets').resolve()
data = pd.read_csv(DATA_DIR / 'secom' / 'secom.data')
```

## Environment Management Patterns

### Tiered Dependencies
```bash
# Basic tier (foundation modules)
pip install -r requirements-basic.txt

# Intermediate tier (modules 4-5)
pip install -r requirements-intermediate.txt  

# Advanced tier (modules 6-7, documentation)
pip install -r requirements-advanced.txt

# Full tier (all modules)
pip install -r requirements-full.txt
```

### Using env_setup.py
```bash
# Set up basic environment
python env_setup.py --tier basic

# Set up advanced environment with docs tools
python env_setup.py --tier advanced

# Force recreate environment
python env_setup.py --tier advanced --force
```

## MkDocs Configuration Template

### Basic mkdocs.yml
```yaml
site_name: Python for Semiconductors Documentation
site_description: ML Learning Series for Semiconductor Engineers

theme:
  name: material
  palette:
    primary: blue
    accent: light-blue
  features:
    - navigation.tabs
    - navigation.sections
    - search.highlight

nav:
  - Home: index.md
  - Foundation:
    - Module 1: foundation/module-1.md
    - Module 2: foundation/module-2.md
    - Module 3: foundation/module-3.md
  - Project Development:
    - Module 10: project-dev/module-10.md

markdown_extensions:
  - codehilite
  - admonition
  - toc
  - pymdownx.details
  - pymdownx.superfences
```

### Build and Serve
```bash
# Build static site
mkdocs build

# Serve locally with auto-reload
mkdocs serve

# Deploy to GitHub Pages
mkdocs gh-deploy
```

## CLI Error Handling Patterns

### Structured JSON Responses
```python
# Success response
{
  "success": true,
  "result": {...},
  "metadata": {"files_processed": 5}
}

# Error response
{
  "success": false,
  "error": "File not found: /path/to/file",
  "error_type": "FileNotFoundError",
  "command": "generate-docs"
}
```

### CLI Exception Handling
```python
def main():
    parser = build_parser()
    args = parser.parse_args()

    try:
        args.func(args)
    except KeyboardInterrupt:
        print("Operation cancelled by user.")
        sys.exit(1)
    except Exception as e:
        error_result = {
            "success": False,
            "error": str(e),
            "command": getattr(args, 'command', None)
        }
        print(json.dumps(error_result, indent=2))
        sys.exit(1)
```

## Validation Checklist

### Before Deployment
- [ ] All notebooks use standard dataset path pattern
- [ ] Environment exported (conda + pip formats)
- [ ] Documentation generated and reviewed
- [ ] CLI commands tested with --help
- [ ] Error cases handled with JSON responses
- [ ] MkDocs builds without errors

### CI/CD Integration
- [ ] Path validation in pre-commit hooks
- [ ] Documentation generation in CI pipeline
- [ ] Environment recreation tested
- [ ] Link checking for documentation
- [ ] Automated deployment to docs site

## Common Debugging Commands

### Check Environment
```bash
# List installed packages
pip list

# Check package versions
pip show pandas numpy scikit-learn

# Export current environment
pip freeze > current-requirements.txt
```

### Validate Paths
```bash
# Find all notebooks
find modules/ -name "*.ipynb" -type f

# Search for dataset path patterns
grep -r "datasets/" modules/ --include="*.ipynb"

# Check for flat path antipatterns
grep -r "datasets/[^/]*\." modules/ --include="*.ipynb"
```

### Test Documentation
```bash
# Check for broken links
find docs/ -name "*.md" -exec grep -l "http" {} \;

# Validate markdown syntax
markdownlint docs/

# Test notebook conversion
jupyter nbconvert --to markdown notebook.ipynb
```

## Troubleshooting Guide

### Common Issues

**Issue**: `nbconvert` not found
```bash
# Solution: Install nbconvert
pip install nbconvert
```

**Issue**: MkDocs command not found
```bash
# Solution: Install mkdocs with material theme
pip install mkdocs mkdocs-material
```

**Issue**: Dataset path validation fails
```python
# Check if using correct pattern
DATA_DIR = Path('../../../datasets').resolve()
print(f"Dataset dir exists: {DATA_DIR.exists()}")
```

**Issue**: Environment export fails
```bash
# Check conda availability
conda --version

# Fallback to pip
pip freeze > requirements.txt
```

### Performance Tips

- Use `--format markdown` for faster conversion than HTML
- Exclude development packages when exporting environments
- Use `.gitignore` to exclude generated documentation from version control
- Cache environment exports to avoid repeated generation

## Integration Examples

### Pre-commit Hook
```yaml
# .pre-commit-config.yaml
repos:
  - repo: local
    hooks:
      - id: validate-paths
        name: Validate dataset paths
        entry: python modules/project-dev/module-10/10.3-documentation-reproducibility-pipeline.py validate-paths --modules-dir modules/
        language: python
        pass_filenames: false
```

### GitHub Actions
```yaml
- name: Generate Documentation
  run: |
    python modules/project-dev/module-10/10.3-documentation-reproducibility-pipeline.py \
      generate-docs --input notebooks/ --output docs/ --format markdown

- name: Build MkDocs Site
  run: |
    pip install mkdocs mkdocs-material
    mkdocs build

- name: Deploy to GitHub Pages
  if: github.ref == 'refs/heads/main'
  run: mkdocs gh-deploy --force
```

## Semiconductor-Specific Notes

### Regulatory Compliance
- Export environments before model validation
- Version all documentation releases
- Maintain traceability between requirements and documentation
- Include change control procedures

### Manufacturing Integration
- Use environment pinning for production deployments
- Validate path resolution in production environments
- Include performance benchmarks in documentation
- Document model validation procedures

### Team Workflows
- Standardize notebook structure before conversion
- Use consistent naming conventions across modules
- Include review process for documentation changes
- Set up automated alerts for documentation updates

## Quick Commands Reference

| Task | Command |
|------|---------|
| Help | `python 10.3-...pipeline.py --help` |
| Convert notebooks | `...generate-docs --input dir/ --output docs/` |
| Validate paths | `...validate-paths --modules-dir modules/` |
| Export conda env | `...export-env --output env.yml --format conda` |
| Setup mkdocs | `...setup-mkdocs --project-dir docs/` |
| Build docs | `...build-docs --project-dir docs/` |
| Serve locally | `mkdocs serve` |
| Deploy to GitHub | `mkdocs gh-deploy` |

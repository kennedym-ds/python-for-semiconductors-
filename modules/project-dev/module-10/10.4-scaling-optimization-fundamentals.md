# Module 10.4 Fundamentals: Scaling & Optimization for Semiconductor ML

## Overview

Scaling and optimization are critical aspects of deploying machine learning models in semiconductor manufacturing environments. As datasets grow larger and real-time constraints become tighter, understanding how to optimize ML pipelines becomes essential for production success.

This module covers the fundamental concepts and practical techniques for scaling ML workloads in semiconductor applications, from vectorization and parallelization to memory management and incremental learning patterns.

## 1. The Performance Challenge in Semiconductor ML

### Manufacturing Constraints

Semiconductor manufacturing presents unique performance challenges:

- **Real-time processing**: Wafer processing decisions must be made in milliseconds
- **Large datasets**: Process sensors generate terabytes of data daily
- **Limited compute resources**: Edge devices in cleanrooms have power/space constraints
- **Batch processing**: Wafer lots need to be processed together efficiently
- **Continuous operation**: 24/7 manufacturing requires robust, optimized systems

### Performance Bottlenecks

Common bottlenecks in semiconductor ML pipelines:

1. **Python loops** for feature engineering
2. **Single-threaded processing** of large datasets
3. **Repeated expensive computations** without caching
4. **Memory limitations** with large datasets
5. **I/O operations** reading from multiple sensors
6. **Model inference latency** in real-time systems

## 2. Vectorization: The Foundation of Fast Computing

### NumPy Vectorization Principles

Vectorization leverages optimized C implementations under the hood:

```python
# Slow: Python loop
result = []
for i in range(len(temperatures)):
    result.append(temperatures[i] * pressures[i])

# Fast: Vectorized operation
result = temperatures * pressures  # Element-wise multiplication
```

### Key Vectorization Techniques

#### Broadcasting
NumPy's broadcasting allows operations between arrays of different shapes:

```python
# Temperature readings (1000 samples)
temps = np.array([450, 455, 460, ...])  # Shape: (1000,)

# Target temperature (scalar)
target = 450

# Broadcast subtraction
deviations = temps - target  # Shape: (1000,)
```

#### Universal Functions (ufuncs)
Built-in functions that operate element-wise:

```python
# Mathematical operations
np.sqrt(pressures)
np.log(concentrations)
np.exp(activation_energies / (k_b * temperatures))

# Comparison operations
np.where(yields > 95, 'pass', 'fail')
```

#### Advanced Indexing
Efficient data selection and manipulation:

```python
# Boolean indexing
high_yield_wafers = data[data['yield'] > 90]

# Fancy indexing
selected_chambers = data[data['chamber_id'].isin([1, 3, 5])]
```

### Pandas Vectorization

Pandas builds on NumPy vectorization with additional functionality:

```python
# String operations (vectorized)
df['wafer_id_upper'] = df['wafer_id'].str.upper()

# DateTime operations
df['process_hour'] = df['timestamp'].dt.hour

# Groupby operations
chamber_stats = df.groupby('chamber_id')['yield'].agg(['mean', 'std'])
```

## 3. Parallel Processing Fundamentals

### CPU-bound vs I/O-bound Tasks

Understanding the type of task determines the best parallelization approach:

- **CPU-bound**: Feature engineering, model training, mathematical computations
- **I/O-bound**: Data loading, file operations, database queries

### joblib for Embarrassingly Parallel Problems

Joblib excels at parallelizing independent tasks:

```python
from joblib import Parallel, delayed

def process_wafer(wafer_data):
    # Complex processing for each wafer
    return compute_yield_metrics(wafer_data)

# Parallel processing of wafer batch
results = Parallel(n_jobs=-1)(
    delayed(process_wafer)(wafer)
    for wafer in wafer_batch
)
```

### Shared Memory Considerations

In manufacturing environments, memory efficiency is crucial:

```python
# Memory-mapped arrays for large datasets
large_sensor_data = np.memmap('sensor_data.dat', dtype='float32', mode='r')

# Shared memory for parallel processing
from joblib import Parallel, delayed
import numpy as np

def process_chunk(chunk):
    return np.mean(chunk, axis=1)

# Process in chunks to manage memory
chunk_size = 10000
chunks = [data[i:i+chunk_size] for i in range(0, len(data), chunk_size)]
results = Parallel(n_jobs=4)(delayed(process_chunk)(chunk) for chunk in chunks)
```

### Parallelization Patterns

#### Map-Reduce Pattern
```python
# Map: Apply function to each element
mapped = Parallel(n_jobs=-1)(delayed(feature_extract)(sample) for sample in samples)

# Reduce: Combine results
final_result = np.concatenate(mapped)
```

#### Producer-Consumer Pattern
```python
from queue import Queue
import threading

def producer(queue, data_source):
    for data_batch in data_source:
        queue.put(data_batch)

def consumer(queue, results):
    while True:
        batch = queue.get()
        if batch is None:
            break
        results.append(process_batch(batch))
```

## 4. Memory Profiling and Optimization

### Understanding Memory Usage Patterns

Memory usage in ML pipelines typically follows these patterns:

1. **Data loading**: Initial spike when reading datasets
2. **Feature engineering**: Growth during transformation
3. **Model training**: Peak during gradient computation
4. **Inference**: Steady state for predictions

### Memory Profiling Tools

#### tracemalloc (Built-in)
```python
import tracemalloc

tracemalloc.start()
# Your code here
current, peak = tracemalloc.get_traced_memory()
print(f"Current: {current / 1024 / 1024:.1f} MB")
print(f"Peak: {peak / 1024 / 1024:.1f} MB")
tracemalloc.stop()
```

#### memory_profiler (External)
```python
from memory_profiler import profile

@profile
def memory_intensive_function():
    large_array = np.zeros((10000, 10000))
    return large_array.sum()
```

### Memory Optimization Strategies

#### Data Type Optimization
```python
# Use appropriate data types
df['chamber_id'] = df['chamber_id'].astype('int8')  # Instead of int64
df['yield'] = df['yield'].astype('float32')  # Instead of float64

# Categorical data
df['process_step'] = df['process_step'].astype('category')
```

#### Chunked Processing
```python
def process_large_dataset(filename, chunk_size=10000):
    results = []
    for chunk in pd.read_csv(filename, chunksize=chunk_size):
        processed = process_chunk(chunk)
        results.append(processed)
    return pd.concat(results)
```

#### Memory-Mapped Files
```python
# For datasets larger than RAM
data = np.memmap('large_dataset.dat', dtype='float32', mode='r',
                 shape=(1000000, 100))
```

## 5. Time Profiling and Performance Analysis

### Timing Methodologies

#### Basic Timing
```python
import time

start = time.perf_counter()
result = expensive_function()
end = time.perf_counter()
print(f"Execution time: {end - start:.4f} seconds")
```

#### Context Manager for Timing
```python
from contextlib import contextmanager

@contextmanager
def timer(description="Operation"):
    start = time.perf_counter()
    yield
    end = time.perf_counter()
    print(f"{description}: {end - start:.4f} seconds")

with timer("Feature engineering"):
    features = engineer_features(data)
```

### Advanced Profiling

#### cProfile
```python
import cProfile
import pstats

# Profile function
pr = cProfile.Profile()
pr.enable()
result = your_function()
pr.disable()

# Analyze results
stats = pstats.Stats(pr)
stats.sort_stats('cumulative')
stats.print_stats(10)  # Top 10 functions
```

#### Line Profiler (Optional)
```python
# Install: pip install line_profiler
@profile
def critical_function():
    # Line-by-line profiling
    for i in range(1000):
        expensive_operation(i)
```

### Performance Optimization Patterns

#### Algorithmic Complexity
- **O(n²) → O(n log n)**: Replace nested loops with sorting + binary search
- **O(n) → O(1)**: Use hash tables for lookups instead of linear search
- **O(k·n) → O(n)**: Vectorize operations to eliminate inner loops

#### Caching Hot Paths
```python
from functools import lru_cache

@lru_cache(maxsize=1000)
def expensive_calculation(parameters):
    # Memoized expensive computation
    return complex_calculation(parameters)
```

## 6. Caching Strategies with joblib.Memory

### Computational Caching Fundamentals

Caching stores computed results to avoid redundant calculations:

```python
from joblib import Memory

# Setup cache directory
memory = Memory('/tmp/joblib_cache', verbose=1)

@memory.cache
def expensive_feature_engineering(data_hash, data):
    # Expensive computation here
    return transformed_data
```

### Cache Key Design

Effective caching requires stable, meaningful keys:

```python
import hashlib

def create_data_hash(dataframe):
    """Create stable hash for DataFrame."""
    return hashlib.md5(dataframe.values.tobytes()).hexdigest()

# Use hash as cache key
data_hash = create_data_hash(sensor_data)
cached_result = cached_function(data_hash, sensor_data)
```

### Cache Management

#### Cache Invalidation
```python
# Clear specific cache
memory.clear()

# Clear cache for specific function
cached_function.clear()

# Selective clearing based on age
memory.clear(warn=False)
```

#### Cache Size Management
```python
# Monitor cache size
cache_size = memory.bytes_used()
print(f"Cache size: {cache_size / 1024 / 1024:.1f} MB")

# Set cache limits
memory = Memory('/tmp/cache', bytes_limit=1024**3)  # 1GB limit
```

### Hierarchical Caching

For complex pipelines, implement multiple cache levels:

```python
# Level 1: Raw data preprocessing
@memory.cache
def preprocess_raw_data(data_hash, raw_data):
    return cleaned_data

# Level 2: Feature engineering
@memory.cache  
def engineer_features(preprocessed_hash, preprocessed_data):
    return feature_data

# Level 3: Model training
@memory.cache
def train_model(feature_hash, feature_data):
    return trained_model
```

## 7. Incremental Learning Patterns

### When to Use Incremental Learning

Incremental learning is essential when:

- **Dataset size** exceeds available memory
- **Streaming data** arrives continuously
- **Model updates** need to be frequent
- **Computational resources** are limited

### Scikit-learn Partial Fit

Models supporting incremental learning:

```python
from sklearn.linear_model import SGDRegressor, SGDClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.cluster import MiniBatchKMeans

# Incremental regression
model = SGDRegressor()
for batch in data_batches:
    X_batch, y_batch = prepare_batch(batch)
    model.partial_fit(X_batch, y_batch)
```

### Online Learning Architecture

```python
class OnlineML:
    def __init__(self):
        self.model = SGDRegressor()
        self.scaler = StandardScaler()
        self.is_fitted = False

    def partial_fit(self, X, y):
        if not self.is_fitted:
            # First batch: fit scaler
            X_scaled = self.scaler.fit_transform(X)
            self.model.partial_fit(X_scaled, y)
            self.is_fitted = True
        else:
            # Subsequent batches: transform only
            X_scaled = self.scaler.transform(X)
            self.model.partial_fit(X_scaled, y)

    def predict(self, X):
        X_scaled = self.scaler.transform(X)
        return self.model.predict(X_scaled)
```

### Concept Drift Handling

In manufacturing, process conditions change over time:

```python
class AdaptiveML:
    def __init__(self, drift_threshold=0.1):
        self.model = SGDRegressor()
        self.drift_threshold = drift_threshold
        self.performance_history = []

    def update_with_drift_detection(self, X, y):
        # Make predictions and calculate error
        y_pred = self.predict(X)
        error = mean_squared_error(y, y_pred)

        # Track performance
        self.performance_history.append(error)

        # Detect drift
        if len(self.performance_history) > 10:
            recent_error = np.mean(self.performance_history[-5:])
            historical_error = np.mean(self.performance_history[:-5])

            if recent_error > historical_error * (1 + self.drift_threshold):
                # Drift detected: increase learning rate
                self.model.learning_rate = 'adaptive'

        # Update model
        self.model.partial_fit(X, y)
```

## 8. Batch Processing Strategies

### Optimal Batch Size Selection

Batch size affects both performance and convergence:

```python
def find_optimal_batch_size(data, model_class, sizes=[100, 500, 1000, 5000]):
    results = {}

    for batch_size in sizes:
        start_time = time.time()
        model = model_class()

        # Train in batches
        for i in range(0, len(data), batch_size):
            batch = data[i:i+batch_size]
            model.partial_fit(batch.features, batch.target)

        training_time = time.time() - start_time
        results[batch_size] = training_time

    return results
```

### Memory-Aware Batching

```python
import psutil

def adaptive_batch_size(data_size, available_memory_ratio=0.8):
    """Calculate batch size based on available memory."""
    available_memory = psutil.virtual_memory().available
    usable_memory = available_memory * available_memory_ratio

    # Estimate memory per sample (rough heuristic)
    memory_per_sample = 1024  # bytes

    optimal_batch_size = int(usable_memory / memory_per_sample)
    return min(optimal_batch_size, data_size)
```

### Pipeline Batching

```python
class BatchedPipeline:
    def __init__(self, batch_size=1000):
        self.batch_size = batch_size
        self.preprocessor = None
        self.model = None

    def fit(self, X, y):
        # Fit preprocessor on first batch
        first_batch = X[:self.batch_size]
        self.preprocessor = StandardScaler().fit(first_batch)

        # Initialize model
        self.model = SGDRegressor()

        # Train in batches
        for i in range(0, len(X), self.batch_size):
            end_idx = min(i + self.batch_size, len(X))
            X_batch = X[i:end_idx]
            y_batch = y[i:end_idx]

            X_processed = self.preprocessor.transform(X_batch)

            if i == 0:
                self.model.partial_fit(X_processed, y_batch)
            else:
                self.model.partial_fit(X_processed, y_batch)
```

## 9. Manufacturing-Specific Optimization Considerations

### Real-Time Constraints

Semiconductor manufacturing has strict timing requirements:

- **Wafer processing decisions**: < 100ms
- **Equipment control loops**: < 10ms  
- **Quality inspections**: < 1 second
- **Batch scheduling**: < 1 minute

### Optimization Strategies for Real-Time Systems

#### Model Compression
```python
# Feature selection for reduced inference time
from sklearn.feature_selection import SelectKBest, f_regression

selector = SelectKBest(f_regression, k=10)  # Keep only top 10 features
X_reduced = selector.fit_transform(X, y)
```

#### Approximate Computing
```python
# Use single precision instead of double
X = X.astype(np.float32)

# Quantized models for edge deployment
from sklearn.tree import DecisionTreeRegressor

# Train with limited depth for faster inference
fast_model = DecisionTreeRegressor(max_depth=5)
```

#### Precomputation
```python
# Precompute expensive features offline
def precompute_features(raw_data):
    """Precompute features that don't change often."""
    static_features = {
        'chamber_mean_temp': raw_data.groupby('chamber')['temp'].mean(),
        'process_step_std': raw_data.groupby('step')['duration'].std()
    }
    return static_features

# Use precomputed features in real-time
precomputed = precompute_features(historical_data)
```

### Edge Computing Considerations

#### Memory Constraints
```python
# Optimize for limited RAM
def memory_efficient_inference(model, data_stream):
    """Process streaming data with minimal memory."""
    for batch in data_stream:
        # Process small batches
        predictions = model.predict(batch)
        yield predictions
        # Memory is automatically freed
```

#### Power Efficiency
```python
# Reduce computational complexity
class EfficientPreprocessor:
    def __init__(self):
        self.simple_scaler = None

    def fit(self, X):
        # Use simpler scaling (avoid std computation)
        self.min_vals = X.min(axis=0)
        self.range_vals = X.max(axis=0) - self.min_vals
        return self

    def transform(self, X):
        # Min-max scaling (computationally cheaper than z-score)
        return (X - self.min_vals) / self.range_vals
```

## 10. Performance Monitoring and Optimization

### Key Performance Indicators (KPIs)

Track these metrics in production:

- **Latency**: Time from input to prediction
- **Throughput**: Predictions per second
- **Memory usage**: Peak and average consumption
- **CPU utilization**: Percentage during inference
- **Model accuracy**: Ongoing performance monitoring

### Monitoring Implementation

```python
import time
import psutil
from collections import deque

class PerformanceMonitor:
    def __init__(self, window_size=100):
        self.latencies = deque(maxlen=window_size)
        self.memory_usage = deque(maxlen=window_size)
        self.cpu_usage = deque(maxlen=window_size)

    def monitor_prediction(self, model, X):
        """Monitor single prediction performance."""
        # Memory before
        mem_before = psutil.Process().memory_info().rss

        # CPU before
        cpu_before = psutil.cpu_percent()

        # Time prediction
        start_time = time.perf_counter()
        prediction = model.predict(X)
        end_time = time.perf_counter()

        # Record metrics
        latency = end_time - start_time
        mem_after = psutil.Process().memory_info().rss
        cpu_after = psutil.cpu_percent()

        self.latencies.append(latency)
        self.memory_usage.append(mem_after - mem_before)
        self.cpu_usage.append(cpu_after)

        return prediction

    def get_stats(self):
        """Get performance statistics."""
        return {
            'avg_latency': np.mean(self.latencies),
            'p95_latency': np.percentile(self.latencies, 95),
            'avg_memory_delta': np.mean(self.memory_usage),
            'avg_cpu': np.mean(self.cpu_usage)
        }
```

### Optimization Feedback Loop

```python
class AdaptiveOptimizer:
    def __init__(self):
        self.performance_history = []
        self.optimization_strategies = [
            'reduce_features',
            'simplify_model',
            'batch_processing',
            'caching'
        ]

    def optimize_based_on_performance(self, current_performance):
        """Automatically adjust optimization strategies."""

        if current_performance['avg_latency'] > 0.1:  # 100ms threshold
            # Too slow: aggressive optimization
            return ['reduce_features', 'simplify_model']

        elif current_performance['avg_memory_delta'] > 100 * 1024 * 1024:  # 100MB
            # Too memory intensive
            return ['batch_processing', 'reduce_precision']

        else:
            # Performance acceptable
            return ['maintain_current']
```

## Summary

Scaling and optimization in semiconductor ML requires a comprehensive understanding of:

1. **Vectorization principles** for eliminating Python loops
2. **Parallel processing strategies** for CPU-intensive tasks
3. **Memory management techniques** for large datasets
4. **Caching strategies** for repeated computations
5. **Incremental learning patterns** for streaming data
6. **Real-time constraints** specific to manufacturing

The key to successful optimization is measuring first, then optimizing the actual bottlenecks rather than perceived ones. Always profile your code, understand your constraints, and choose appropriate optimization strategies for your specific semiconductor manufacturing use case.

Remember: "Premature optimization is the root of all evil" - Donald Knuth. Focus on correctness first, then optimize where measurements show it's needed.

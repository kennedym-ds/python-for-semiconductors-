# Module 10.1: Project Architecture & Best Practices - Fundamentals

## Overview

This module covers essential project architecture principles and best practices for production ML systems in semiconductor manufacturing. Understanding how to structure, organize, and manage ML projects is crucial for maintainability, reproducibility, and collaboration in industrial environments.

## Learning Objectives

By the end of this module, you will:

1. **Understand** standardized project structures for semiconductor ML workflows
2. **Implement** configuration management and environment setup best practices
3. **Apply** data versioning patterns and path resolution strategies
4. **Design** CLI interfaces with consistent error handling and JSON outputs
5. **Configure** logging systems with structured outputs for production monitoring
6. **Manage** secrets and sensitive configuration through environment variables

## Core Concepts

### 1. Project Structure Standardization

#### The Semiconductor ML Project Template

```
project_name/
├── src/                    # Source code
│   ├── data/              # Data loading and processing modules
│   ├── features/          # Feature engineering pipelines
│   ├── models/            # Model implementations and training
│   └── visualization/     # Plotting and reporting utilities
├── data/                  # Data storage with clear separation
│   ├── raw/              # Original, immutable data dumps
│   ├── processed/        # Cleaned data ready for analysis
│   └── external/         # Third-party datasets and references
├── notebooks/             # Jupyter notebooks organized by purpose
│   ├── exploratory/      # EDA, hypothesis testing, experimentation
│   └── production/       # Finalized analysis and reporting
├── tests/                 # Unit and integration tests
├── configs/               # Configuration files (YAML, JSON)
├── models/                # Trained model artifacts and metadata
├── logs/                  # Application and training logs
├── scripts/               # Utility scripts and automation
└── docs/                  # Documentation and API references
```

#### Benefits of This Structure

1. **Separation of Concerns**: Clear boundaries between data, code, configuration, and outputs
2. **Reproducibility**: Standardized paths and organization enable consistent environments
3. **Collaboration**: Team members can navigate any project with the same mental model
4. **Scalability**: Structure supports growth from prototypes to production systems
5. **Compliance**: Meets industry standards for regulated semiconductor environments

### 2. Configuration Management

#### Multi-Tier Configuration Strategy

**Level 1: Environment Variables (.env)**
```bash
# Production settings that vary by deployment
PROJECT_NAME=wafer_defect_classifier
ENVIRONMENT=production
LOG_LEVEL=INFO
DATABASE_URL=postgresql://prod-server/semiconductor_data
```

**Level 2: YAML Configuration (configs/config.yaml)**
```yaml
# Application settings that are version-controlled
model:
  type: "classification"
  hyperparameters:
    max_depth: 8
    n_estimators: 300
    random_state: 42

manufacturing:
  tolerance: 2.0
  spec_limits:
    low: 60.0
    high: 100.0
```

**Level 3: Code Constants**
```python
# Hard-coded values that should never change
RANDOM_SEED = 42
TARGET_COLUMN = 'target'
SEMICONDUCTOR_METRICS = ['PWS', 'Estimated_Loss', 'Yield_Rate']
```

#### Configuration Loading Pattern

```python
import os
import yaml
from pathlib import Path
from dataclasses import dataclass
from dotenv import load_dotenv

@dataclass
class Config:
    """Centralized configuration management."""
    project_name: str
    environment: str
    log_level: str
    data_dir: Path
    model_config: dict

    @classmethod
    def from_env(cls, config_path: Path = None):
        """Load configuration from environment and files."""
        load_dotenv()  # Load .env file

        # Load YAML config
        config_path = config_path or Path("configs/config.yaml")
        with open(config_path) as f:
            yaml_config = yaml.safe_load(f)

        return cls(
            project_name=os.getenv("PROJECT_NAME"),
            environment=os.getenv("ENVIRONMENT", "development"),
            log_level=os.getenv("LOG_LEVEL", "INFO"),
            data_dir=Path(os.getenv("DATA_DIR", "./data")),
            model_config=yaml_config.get("model", {})
        )
```

### 3. Data Versioning and Path Resolution

#### Path Resolution Strategy

**Problem**: Notebooks and scripts need to access data from different locations in the project hierarchy.

**Solution**: Consistent relative path resolution from execution context.

```python
from pathlib import Path

def get_project_root() -> Path:
    """Find project root by looking for .project_metadata.json."""
    current = Path.cwd()
    while current != current.parent:
        if (current / ".project_metadata.json").exists():
            return current
        current = current.parent
    raise FileNotFoundError("Project root not found")

# Usage in notebooks and scripts
PROJECT_ROOT = get_project_root()
DATA_DIR = PROJECT_ROOT / "data"
RAW_DATA_DIR = DATA_DIR / "raw"
PROCESSED_DATA_DIR = DATA_DIR / "processed"
```

#### Data Versioning Patterns

**1. Semantic Versioning for Datasets**
```
data/
├── raw/
│   ├── secom_v1.0.0/
│   │   ├── secom.data
│   │   ├── secom.names
│   │   └── metadata.json
│   └── secom_v1.1.0/
│       ├── secom.data
│       ├── secom_additional_features.data
│       └── metadata.json
└── processed/
    ├── secom_v1.0.0_processed/
    └── secom_v1.1.0_processed/
```

**2. Git LFS for Large Files**
```bash
# Track large data files with Git LFS
git lfs track "data/raw/*.data"
git lfs track "models/*.joblib"
git add .gitattributes
```

**3. Data Manifest Pattern**
```python
# data/manifest.py
from dataclasses import dataclass
from datetime import datetime
from typing import Dict, List

@dataclass
class DatasetInfo:
    name: str
    version: str
    path: Path
    created_at: datetime
    size_mb: float
    checksum: str
    description: str

class DataManifest:
    """Registry of available datasets."""

    def __init__(self):
        self.datasets: Dict[str, DatasetInfo] = {}

    def register(self, dataset: DatasetInfo):
        """Register a new dataset version."""
        key = f"{dataset.name}_v{dataset.version}"
        self.datasets[key] = dataset

    def get_latest(self, name: str) -> DatasetInfo:
        """Get the latest version of a dataset."""
        versions = [k for k in self.datasets.keys() if k.startswith(f"{name}_v")]
        if not versions:
            raise KeyError(f"Dataset '{name}' not found")
        latest_key = sorted(versions)[-1]
        return self.datasets[latest_key]
```

### 4. CLI Design Patterns

#### Consistent Command Structure

All pipeline scripts follow the same CLI pattern for predictability:

```python
def build_parser():
    parser = argparse.ArgumentParser(description='Module X.Y Description')
    sub = parser.add_subparsers(dest='command', required=True)

    # Standard subcommands across all modules
    p_train = sub.add_parser('train', help='Train a model')
    p_eval = sub.add_parser('evaluate', help='Evaluate model')
    p_pred = sub.add_parser('predict', help='Make predictions')

    return parser
```

#### JSON Output Pattern

All CLI operations return structured JSON for programmatic consumption:

```python
def action_train(args):
    """Handle train command with structured output."""
    try:
        # Perform training logic
        result = {
            "status": "success",
            "model_path": str(model_path),
            "metrics": evaluation_metrics,
            "metadata": {
                "training_time": training_duration,
                "data_version": data_version,
                "hyperparameters": hyperparams
            }
        }
        print(json.dumps(result, indent=2))
    except Exception as e:
        error_result = {
            "status": "error",
            "message": str(e),
            "error_type": type(e).__name__
        }
        print(json.dumps(error_result, indent=2))
        sys.exit(1)
```

#### Error Handling Strategy

1. **Fail Fast**: Validate inputs early and provide clear error messages
2. **Structured Errors**: Return JSON error responses with error types
3. **Graceful Degradation**: Handle optional dependencies and missing resources
4. **Exit Codes**: Use appropriate exit codes for automation scripts

### 5. Logging Architecture

#### Structured Logging with JSON

```python
import structlog
import logging
from pythonjsonlogger import jsonlogger

def setup_logging(level: str = "INFO", log_file: Path = None):
    """Configure structured logging for production."""

    # Configure structlog
    structlog.configure(
        processors=[
            structlog.stdlib.filter_by_level,
            structlog.stdlib.add_logger_name,
            structlog.stdlib.add_log_level,
            structlog.stdlib.PositionalArgumentsFormatter(),
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.StackInfoRenderer(),
            structlog.processors.format_exc_info,
            structlog.processors.UnicodeDecoder(),
            structlog.processors.JSONRenderer()
        ],
        context_class=dict,
        logger_factory=structlog.stdlib.LoggerFactory(),
        wrapper_class=structlog.stdlib.BoundLogger,
        cache_logger_on_first_use=True,
    )

    # Configure standard library logging
    formatter = jsonlogger.JsonFormatter(
        '%(asctime)s %(name)s %(levelname)s %(message)s'
    )

    handler = logging.StreamHandler()
    if log_file:
        handler = logging.FileHandler(log_file)

    handler.setFormatter(formatter)

    logger = logging.getLogger()
    logger.addHandler(handler)
    logger.setLevel(level)

    return structlog.get_logger()

# Usage in pipeline code
logger = setup_logging("INFO", Path("logs/training.log"))

def train_model(data):
    logger.info("Starting model training",
               data_shape=data.shape,
               model_type="RandomForest")
    try:
        # Training logic
        logger.info("Training completed successfully",
                   training_time=duration,
                   final_score=score)
    except Exception as e:
        logger.error("Training failed",
                    error=str(e),
                    error_type=type(e).__name__)
        raise
```

#### Log Levels and Content Guidelines

- **DEBUG**: Detailed diagnostic information (parameters, intermediate values)
- **INFO**: General operational messages (start/stop, progress, results)
- **WARNING**: Unexpected conditions that don't break functionality
- **ERROR**: Serious problems that prevent operation completion
- **CRITICAL**: System-level failures requiring immediate attention

### 6. Secrets Management

#### Environment-Based Secrets

```bash
# .env (never committed to version control)
DATABASE_PASSWORD=prod_secret_password
API_KEY=semiconductor_data_api_key_12345
ENCRYPTION_KEY=base64_encoded_encryption_key

# .env.template (committed as example)
DATABASE_PASSWORD=your_database_password_here
API_KEY=your_api_key_here
ENCRYPTION_KEY=your_encryption_key_here
```

#### Secrets Loading Pattern

```python
import os
from pathlib import Path
from typing import Optional

class SecretsManager:
    """Secure secrets management for production environments."""

    def __init__(self, env_file: Optional[Path] = None):
        if env_file and env_file.exists():
            from dotenv import load_dotenv
            load_dotenv(env_file)

    def get_secret(self, key: str, default: Optional[str] = None) -> str:
        """Get secret from environment with validation."""
        value = os.getenv(key, default)
        if value is None:
            raise ValueError(f"Required secret '{key}' not found in environment")
        return value

    def get_database_url(self) -> str:
        """Construct database URL from components."""
        user = self.get_secret("DB_USER")
        password = self.get_secret("DB_PASSWORD")
        host = self.get_secret("DB_HOST", "localhost")
        port = self.get_secret("DB_PORT", "5432")
        database = self.get_secret("DB_NAME")

        return f"postgresql://{user}:{password}@{host}:{port}/{database}"

# Usage
secrets = SecretsManager(Path(".env"))
db_url = secrets.get_database_url()
api_key = secrets.get_secret("SEMICONDUCTOR_API_KEY")
```

## Semiconductor Manufacturing Context

### Manufacturing-Specific Metrics Integration

Projects should include semiconductor-specific metrics alongside standard ML metrics:

```python
def compute_manufacturing_metrics(y_true, y_pred, tolerance=2.0,
                                spec_low=60.0, spec_high=100.0,
                                cost_per_unit=1.0):
    """Compute semiconductor manufacturing metrics."""

    # Prediction Within Spec (PWS)
    pws = ((y_pred >= spec_low) & (y_pred <= spec_high)).mean()

    # Estimated Loss from prediction errors
    loss_components = np.maximum(0, np.abs(y_true - y_pred) - tolerance)
    estimated_loss = float(np.sum(loss_components) * cost_per_unit)

    # Yield Rate (for classification)
    if len(np.unique(y_true)) == 2:  # Binary classification
        yield_rate = (y_pred == 1).mean()  # Assuming 1 = pass
    else:
        yield_rate = None

    return {
        'PWS': pws,
        'Estimated_Loss': estimated_loss,
        'Yield_Rate': yield_rate
    }
```

### Process Parameter Templates

```python
# Standard semiconductor process parameters
PROCESS_PARAMETERS = {
    'temperature': {'min': 400, 'max': 500, 'unit': 'celsius', 'tolerance': 5},
    'pressure': {'min': 1.0, 'max': 5.0, 'unit': 'atm', 'tolerance': 0.1},
    'flow_rate': {'min': 50, 'max': 200, 'unit': 'sccm', 'tolerance': 10},
    'time': {'min': 30, 'max': 120, 'unit': 'seconds', 'tolerance': 5}
}

def validate_process_parameters(params: dict) -> bool:
    """Validate process parameters against specifications."""
    for param_name, param_config in PROCESS_PARAMETERS.items():
        if param_name in params:
            value = params[param_name]
            if not (param_config['min'] <= value <= param_config['max']):
                return False
    return True
```

## Testing Architecture

### Test Organization Strategy

```
tests/
├── unit/                  # Unit tests for individual components
│   ├── test_data_loading.py
│   ├── test_feature_engineering.py
│   └── test_models.py
├── integration/           # Integration tests for workflows
│   ├── test_training_pipeline.py
│   └── test_prediction_pipeline.py
├── performance/           # Performance and benchmark tests
│   └── test_model_performance.py
└── fixtures/              # Test data and mock objects
    ├── sample_data.csv
    └── mock_responses.json
```

### Test Patterns for CLI Applications

```python
import subprocess
import json
import tempfile
from pathlib import Path

def test_cli_train_command():
    """Test training command via CLI."""
    with tempfile.TemporaryDirectory() as tmp_dir:
        # Run CLI command
        result = subprocess.run([
            'python', 'pipeline.py', 'train',
            '--data', 'synthetic_yield',
            '--model', 'ridge',
            '--save', f'{tmp_dir}/model.joblib'
        ], capture_output=True, text=True)

        # Verify successful execution
        assert result.returncode == 0

        # Parse JSON output
        output = json.loads(result.stdout)
        assert output['status'] == 'success'
        assert 'metrics' in output

        # Verify model file was created
        assert Path(f'{tmp_dir}/model.joblib').exists()
```

## Best Practices Summary

### 1. **Consistency is Key**
- Use the same project structure across all semiconductor ML projects
- Follow identical CLI patterns and JSON output formats
- Standardize naming conventions and file organization

### 2. **Configuration Over Code**
- Externalize all environment-specific settings
- Use version-controlled configuration for application settings
- Never hardcode paths, URLs, or sensitive information

### 3. **Fail Fast and Clearly**
- Validate inputs at the earliest possible point
- Provide actionable error messages with context
- Use structured logging for debugging and monitoring

### 4. **Document Everything**
- Include comprehensive README files with setup instructions
- Document API interfaces and expected inputs/outputs
- Maintain changelogs and version histories

### 5. **Test Relentlessly**
- Write unit tests for all core functionality
- Test CLI interfaces with various input combinations
- Include performance regression tests for critical paths

### 6. **Security First**
- Never commit secrets or sensitive data
- Use environment variables for all credentials
- Implement proper access controls and audit logging

## Common Pitfalls and Solutions

### Pitfall 1: Hardcoded Paths
**Problem**: Scripts break when run from different directories
**Solution**: Use relative path resolution from project root

### Pitfall 2: Mixed Configuration Sources
**Problem**: Settings scattered across code, files, and environment
**Solution**: Implement hierarchical configuration loading

### Pitfall 3: Inconsistent Error Handling
**Problem**: Different scripts handle errors differently
**Solution**: Use standardized error handling patterns and JSON responses

### Pitfall 4: Lack of Data Versioning
**Problem**: Results become non-reproducible as data changes
**Solution**: Implement data versioning with semantic versioning

### Pitfall 5: Poor Secret Management
**Problem**: Credentials leaked in version control or logs
**Solution**: Use environment variables and secret management systems

## Conclusion

Proper project architecture and best practices are essential for building maintainable, scalable ML systems in semiconductor manufacturing. The patterns and templates provided in this module establish a foundation for professional-grade ML projects that can grow from prototypes to production systems while maintaining code quality, security, and reproducibility standards.

The investment in proper project structure pays dividends throughout the ML lifecycle, from initial development through deployment, monitoring, and maintenance. By following these established patterns, teams can focus on solving semiconductor manufacturing challenges rather than wrestling with project organization and tooling issues.

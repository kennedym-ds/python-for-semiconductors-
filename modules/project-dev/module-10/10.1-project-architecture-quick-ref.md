# Module 10.1: Project Architecture & Best Practices - Quick Reference

## TL;DR - Command Cheat Sheet

```bash
# Scaffold a new semiconductor ML project
python 10.1-project-architecture-pipeline.py scaffold \
  --name wafer_defect_classifier \
  --type classification \
  --output ./projects/

# Validate existing project structure
python 10.1-project-architecture-pipeline.py validate \
  --project-path ./projects/wafer_defect_classifier/

# Lint project structure for issues
python 10.1-project-architecture-pipeline.py lint-structure \
  --project-path ./projects/wafer_defect_classifier/
```

## Standard Project Structure

```
semiconductor_ml_project/
├── src/                    # Source code modules
│   ├── data/              # Data loading and processing
│   ├── features/          # Feature engineering pipelines  
│   ├── models/            # Model implementations
│   └── visualization/     # Plotting and reporting
├── data/                  # Data storage (gitignored)
│   ├── raw/              # Original, immutable data
│   ├── processed/        # Cleaned data for analysis
│   └── external/         # Third-party datasets
├── notebooks/             # Jupyter notebooks
│   ├── exploratory/      # EDA and experimentation
│   └── production/       # Finalized analysis
├── tests/                 # Unit and integration tests
├── configs/               # Configuration files
├── models/                # Trained model artifacts (gitignored)
├── logs/                  # Application logs (gitignored)
├── scripts/               # Utility scripts
└── docs/                  # Documentation
```

## Project Types & Use Cases

| Type | Description | Key Metrics | Sample Datasets |
|------|-------------|-------------|-----------------|
| **classification** | Defect detection, yield classification | ROC-AUC, PR-AUC, PWS, False_Positive_Rate | secom, defect_detection, wafer_maps |
| **regression** | Process optimization, yield prediction | MAE, RMSE, R², PWS, Estimated_Loss | process_params, yield_prediction, sensor_data |
| **time_series** | Equipment monitoring, drift detection | MAE, RMSE, MAPE, Anomaly_Detection_Rate | sensor_logs, equipment_health, process_monitoring |
| **computer_vision** | Wafer inspection, die analysis | mIoU, Pixel_Accuracy, Defect_Detection_Rate | wafer_images, die_photos, microscopy_data |

## Configuration Management Pattern

### 1. Environment Variables (.env)
```bash
# Production settings that vary by deployment
PROJECT_NAME=wafer_defect_classifier
ENVIRONMENT=production
LOG_LEVEL=INFO
DATABASE_URL=postgresql://prod-server/semiconductor_data
RANDOM_SEED=42
```

### 2. YAML Configuration (configs/config.yaml)
```yaml
# Application settings (version controlled)
model:
  type: "classification"
  hyperparameters:
    max_depth: 8
    n_estimators: 300

manufacturing:
  tolerance: 2.0
  spec_limits:
    low: 60.0
    high: 100.0
```

### 3. Code Constants
```python
# Hard-coded values that never change
RANDOM_SEED = 42
TARGET_COLUMN = 'target'
SEMICONDUCTOR_METRICS = ['PWS', 'Estimated_Loss', 'Yield_Rate']
```

## Data Path Resolution Pattern

```python
from pathlib import Path

def get_project_root() -> Path:
    """Find project root by looking for .project_metadata.json."""
    current = Path.cwd()
    while current != current.parent:
        if (current / ".project_metadata.json").exists():
            return current
        current = current.parent
    raise FileNotFoundError("Project root not found")

# Usage in notebooks and scripts
PROJECT_ROOT = get_project_root()
DATA_DIR = PROJECT_ROOT / "data"
RAW_DATA_DIR = DATA_DIR / "raw"
PROCESSED_DATA_DIR = DATA_DIR / "processed"
```

## CLI Pattern (Standard Template)

```python
def build_parser():
    parser = argparse.ArgumentParser(description='Module X.Y Description')
    sub = parser.add_subparsers(dest='command', required=True)

    # train subcommand
    p_train = sub.add_parser('train', help='Train a model')
    p_train.add_argument('--dataset', default='synthetic_yield')
    p_train.add_argument('--model', default='ridge')
    p_train.add_argument('--save', help='Path to save model')
    p_train.set_defaults(func=action_train)

    # evaluate subcommand  
    p_eval = sub.add_parser('evaluate', help='Evaluate model')
    p_eval.add_argument('--model-path', required=True)
    p_eval.add_argument('--dataset', default='synthetic_yield')
    p_eval.set_defaults(func=action_evaluate)

    # predict subcommand
    p_pred = sub.add_parser('predict', help='Make predictions')
    p_pred.add_argument('--model-path', required=True)
    p_pred.add_argument('--input-json', help='JSON input string')
    p_pred.set_defaults(func=action_predict)

    return parser
```

## JSON Output Pattern

```python
def action_train(args):
    """Standard JSON response format."""
    try:
        # Training logic here...
        result = {
            "status": "success",
            "model_path": str(model_path),
            "metrics": evaluation_metrics,
            "metadata": {
                "training_time": duration,
                "data_version": "v1.0.0",
                "hyperparameters": hyperparams
            }
        }
        print(json.dumps(result, indent=2))
    except Exception as e:
        error_result = {
            "status": "error",
            "message": str(e),
            "error_type": type(e).__name__
        }
        print(json.dumps(error_result, indent=2))
        sys.exit(1)
```

## Semiconductor Manufacturing Metrics

```python
def compute_semiconductor_metrics(y_true, y_pred, tolerance=2.0,
                                spec_low=60.0, spec_high=100.0,
                                cost_per_unit=1.0):
    """Standard semiconductor metrics to include in all projects."""

    # Prediction Within Spec (PWS)
    pws = np.mean((y_pred >= spec_low) & (y_pred <= spec_high))

    # Estimated Loss from prediction errors
    loss_components = np.maximum(0, np.abs(y_true - y_pred) - tolerance)
    estimated_loss = float(np.sum(loss_components) * cost_per_unit)

    # Yield Rate (for classification: % predicted as pass)
    yield_rate = np.mean(y_pred >= spec_low)

    return {
        'PWS': pws,                    # Prediction Within Spec (%)
        'Estimated_Loss': estimated_loss,  # Cost impact ($)
        'Yield_Rate': yield_rate       # Overall yield (%)
    }
```

## Structured Logging Setup

```python
import structlog

def setup_logging(level="INFO", log_file=None):
    """Configure structured JSON logging."""
    structlog.configure(
        processors=[
            structlog.stdlib.add_log_level,
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.JSONRenderer()
        ],
        logger_factory=structlog.stdlib.LoggerFactory(),
        wrapper_class=structlog.stdlib.BoundLogger,
        cache_logger_on_first_use=True,
    )
    return structlog.get_logger()

# Usage
logger = setup_logging("INFO", Path("logs/training.log"))
logger.info("Training started", model_type="RandomForest", data_shape=(1000, 20))
```

## Essential Files Checklist

### Required Files
- [ ] `README.md` - Project overview and setup instructions
- [ ] `requirements.txt` - Python dependencies
- [ ] `.gitignore` - Files to exclude from version control
- [ ] `.env.template` - Environment variable template
- [ ] `configs/config.yaml` - Application configuration
- [ ] `src/models/pipeline.py` - Main ML pipeline implementation

### Recommended Files  
- [ ] `Dockerfile` - Container deployment
- [ ] `docker-compose.yml` - Multi-service orchestration
- [ ] `.project_metadata.json` - Project metadata and compliance tracking
- [ ] `tests/test_pipeline.py` - Unit tests for pipeline
- [ ] `notebooks/exploratory/01_initial_exploration.ipynb` - EDA template

## Process Parameter Templates

```python
# Standard semiconductor process parameters
PROCESS_PARAMETERS = {
    'temperature': {'min': 400, 'max': 500, 'unit': 'celsius', 'tolerance': 5},
    'pressure': {'min': 1.0, 'max': 5.0, 'unit': 'atm', 'tolerance': 0.1},
    'flow_rate': {'min': 50, 'max': 200, 'unit': 'sccm', 'tolerance': 10},
    'time': {'min': 30, 'max': 120, 'unit': 'seconds', 'tolerance': 5}
}

def validate_process_parameters(params: dict) -> bool:
    """Validate process parameters against specifications."""
    for param_name, param_config in PROCESS_PARAMETERS.items():
        if param_name in params:
            value = params[param_name]
            if not (param_config['min'] <= value <= param_config['max']):
                return False
    return True
```

## Secrets Management Pattern

```python
import os
from pathlib import Path
from dotenv import load_dotenv

class SecretsManager:
    """Secure secrets management."""

    def __init__(self, env_file: Path = None):
        if env_file and env_file.exists():
            load_dotenv(env_file)

    def get_secret(self, key: str, default=None) -> str:
        """Get secret with validation."""
        value = os.getenv(key, default)
        if value is None:
            raise ValueError(f"Required secret '{key}' not found")
        return value

# Usage
secrets = SecretsManager(Path(".env"))
db_password = secrets.get_secret("DATABASE_PASSWORD")
api_key = secrets.get_secret("SEMICONDUCTOR_API_KEY")
```

## Testing Pattern

```python
import pytest
import subprocess
import json
from pathlib import Path

def test_cli_train_command():
    """Test CLI interface returns valid JSON."""
    result = subprocess.run([
        'python', 'pipeline.py', 'train',
        '--dataset', 'synthetic_yield',
        '--model', 'ridge'
    ], capture_output=True, text=True)

    assert result.returncode == 0
    output = json.loads(result.stdout)
    assert output['status'] == 'success'
    assert 'metrics' in output

def test_semiconductor_metrics():
    """Test manufacturing-specific metrics."""
    y_true = np.array([80, 85, 90, 95])
    y_pred = np.array([82, 83, 92, 94])

    metrics = compute_semiconductor_metrics(y_true, y_pred)

    assert 0 <= metrics['PWS'] <= 1
    assert metrics['Estimated_Loss'] >= 0
    assert 0 <= metrics['Yield_Rate'] <= 1
```

## Common Validation Errors & Fixes

| Error | Description | Fix |
|-------|-------------|-----|
| Missing required directories | `src/`, `data/`, `tests/`, `configs/` not found | Run scaffold command or create manually |
| Hardcoded paths | Absolute paths in code | Use relative path resolution pattern |
| Missing `__init__.py` | Python packages not properly defined | Add empty `__init__.py` files to all src subdirs |
| No configuration management | Settings scattered in code | Implement env vars + YAML config pattern |
| Wildcard imports | `from module import *` | Use explicit imports |
| Missing secrets template | No `.env.template` | Create template with placeholder values |

## Performance Guidelines

### Model Performance Targets
- **Classification**: ROC-AUC > 0.85, PWS > 95%
- **Regression**: R² > 0.8, PWS > 90%, RMSE < 5% of spec range
- **Time Series**: MAPE < 10%, Anomaly Detection Rate > 95%

### System Performance Targets  
- **Training Time**: < 10 minutes for development datasets
- **Prediction Latency**: < 100ms for single predictions
- **Memory Usage**: < 2GB for standard models
- **Model Size**: < 100MB for deployment

## Deployment Checklist

### Pre-Deployment
- [ ] All tests passing
- [ ] Configuration externalized
- [ ] Secrets managed properly
- [ ] Performance benchmarks met
- [ ] Documentation updated
- [ ] Model artifacts versioned

### Production Deployment
- [ ] Environment variables configured
- [ ] Logging endpoints set up
- [ ] Monitoring dashboards created
- [ ] Backup/recovery procedures tested
- [ ] Security scan completed
- [ ] Performance testing completed

## Quick Troubleshooting

### Project Won't Validate
1. Check directory structure matches template
2. Ensure all required files present
3. Verify `__init__.py` files in src packages
4. Check for hardcoded paths in code

### CLI Commands Failing
1. Verify Python environment activated
2. Check all dependencies installed
3. Ensure model files exist for evaluate/predict
4. Validate JSON input format

### Poor Model Performance
1. Check data quality and preprocessing
2. Verify feature engineering pipeline
3. Tune hyperparameters systematically
4. Evaluate semiconductor-specific metrics
5. Consider domain expertise integration

### Configuration Issues
1. Verify `.env` file exists and is loaded
2. Check YAML syntax in config files
3. Ensure environment variables set correctly
4. Validate secrets are accessible

## Resources & Next Steps

### File References
- `10.1-project-architecture-fundamentals.md` - Complete theory guide
- `10.1-project-architecture-pipeline.py` - Full implementation
- `10.1-project-architecture.ipynb` - Interactive examples
- `projects/starter/template/` - Reusable template

### Advanced Topics to Explore
- Custom project types for specialized manufacturing
- Integration with MLOps platforms (MLflow, Kubeflow)
- Advanced configuration management (Hydra, OmegaConf)
- Model versioning and experiment tracking
- Production monitoring and alerting
- A/B testing frameworks for manufacturing

### Community Resources
- [Semiconductor Industry Association Standards](https://www.semiconductors.org/)
- [Python Packaging Authority Guidelines](https://packaging.python.org/)
- [MLOps Maturity Model](https://docs.microsoft.com/en-us/azure/architecture/example-scenario/mlops/mlops-maturity-model)
- [Cookiecutter Data Science](https://drivendata.github.io/cookiecutter-data-science/)

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equipment Drift Monitoring Tutorial\n",
    "\n",
    "This tutorial demonstrates how to build a production-ready equipment drift detection system for semiconductor manufacturing using time series analysis and anomaly detection techniques.\n",
    "\n",
    "## Business Context\n",
    "\n",
    "Equipment drift monitoring is essential for:\n",
    "- **Predictive Maintenance**: Detecting equipment degradation before failures\n",
    "- **Process Stability**: Maintaining consistent manufacturing conditions\n",
    "- **Quality Control**: Preventing drift-induced defects\n",
    "- **Cost Optimization**: Minimizing unplanned downtime and maintenance costs\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "1. Understand equipment drift patterns in semiconductor manufacturing\n",
    "2. Build time series models for drift detection\n",
    "3. Apply statistical and ML-based anomaly detection\n",
    "4. Implement real-time monitoring dashboards\n",
    "5. Deploy models using standardized CLI interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress ARIMA convergence warnings for cleaner output\n",
    "\n",
    "# Import our equipment drift monitoring pipeline\n",
    "from equipment_drift_monitor import (\n",
    "    EquipmentDriftMonitor,\n",
    "    generate_equipment_data,\n",
    "    load_dataset\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"tab10\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Equipment Data Generation and Exploration\n",
    "\n",
    "Let's generate synthetic equipment sensor data with various drift patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic equipment sensor data\n",
    "print(\"Generating synthetic equipment sensor data...\")\n",
    "df = generate_equipment_data(\n",
    "    n_points=2000,\n",
    "    equipment_id=\"CVD_CHAMBER_01\",\n",
    "    drift_start=500,  # Start drift after 500 time points\n",
    "    drift_magnitude=0.1,\n",
    "    noise_level=0.05,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Time range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "print(f\"\\nSensor parameters: {[col for col in df.columns if col not in ['timestamp', 'equipment_id']]}\")\n",
    "\n",
    "# Display basic statistics for sensor readings\n",
    "sensor_cols = [col for col in df.columns if col not in ['timestamp', 'equipment_id']]\n",
    "print(\"\\n=== Equipment Sensor Summary ===\")\n",
    "print(df[sensor_cols].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize equipment sensor data over time\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each sensor parameter\n",
    "for i, sensor in enumerate(sensor_cols[:6]):  # Plot first 6 sensors\n",
    "    ax = axes[i]\n",
    "    ax.plot(df.index, df[sensor], linewidth=1, alpha=0.8)\n",
    "    ax.set_title(f'{sensor} Over Time')\n",
    "    ax.set_xlabel('Time Index')\n",
    "    ax.set_ylabel('Sensor Value')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Highlight drift region\n",
    "    ax.axvline(x=500, color='red', linestyle='--', alpha=0.7, label='Drift Start')\n",
    "    if i == 0:  # Only show legend on first plot\n",
    "        ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== Drift Analysis ===\")\n",
    "# Compare pre-drift vs post-drift statistics\n",
    "pre_drift = df[:500]\n",
    "post_drift = df[500:]\n",
    "\n",
    "for sensor in sensor_cols[:3]:  # Analyze first 3 sensors\n",
    "    pre_mean = pre_drift[sensor].mean()\n",
    "    post_mean = post_drift[sensor].mean()\n",
    "    drift_magnitude = post_mean - pre_mean\n",
    "    \n",
    "    print(f\"{sensor}:\")\n",
    "    print(f\"  Pre-drift mean: {pre_mean:.3f}\")\n",
    "    print(f\"  Post-drift mean: {post_mean:.3f}\")\n",
    "    print(f\"  Drift magnitude: {drift_magnitude:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Drift Detection Model Training\n",
    "\n",
    "Let's build and train drift detection models using various approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "# Use the first portion (pre-drift) for training\n",
    "train_data = df[:400]  # Training data before drift\n",
    "test_data = df[400:]   # Test data including drift period\n",
    "\n",
    "print(f\"Training data: {len(train_data)} points\")\n",
    "print(f\"Test data: {len(test_data)} points\")\n",
    "\n",
    "# Initialize drift monitor\n",
    "drift_monitor = EquipmentDriftMonitor(\n",
    "    equipment_id=\"CVD_CHAMBER_01\",\n",
    "    window_size=50,\n",
    "    method='statistical',\n",
    "    threshold=3.0\n",
    ")\n",
    "\n",
    "# Train the model on pre-drift data\n",
    "print(\"\\nTraining drift detection model...\")\n",
    "X_train = train_data[sensor_cols]\n",
    "drift_monitor.fit(X_train)\n",
    "\n",
    "# Evaluate on test data\n",
    "X_test = test_data[sensor_cols]\n",
    "metrics = drift_monitor.evaluate(X_test)\n",
    "\n",
    "print(\"\\n=== Model Performance ===\")\n",
    "print(f\"Anomaly Rate: {metrics['anomaly_rate']:.1%}\")\n",
    "print(f\"Mean Anomaly Score: {metrics['mean_anomaly_score']:.3f}\")\n",
    "print(f\"Alert Threshold: {metrics['alert_threshold']:.3f}\")\n",
    "print(f\"Equipment Uptime: {metrics['equipment_uptime']:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different drift detection methods\n",
    "methods_to_test = [\n",
    "    ('statistical', 'Statistical Control (Z-score)'),\n",
    "    ('isolation_forest', 'Isolation Forest'),\n",
    "    ('arima', 'ARIMA Residuals')\n",
    "]\n",
    "\n",
    "method_results = []\n",
    "\n",
    "print(\"\\n=== Comparing Drift Detection Methods ===\")\n",
    "for method, method_desc in methods_to_test:\n",
    "    print(f\"\\nTesting {method_desc}...\")\n",
    "    \n",
    "    # Create and train monitor\n",
    "    monitor = EquipmentDriftMonitor(\n",
    "        equipment_id=\"CVD_CHAMBER_01\",\n",
    "        window_size=50,\n",
    "        method=method,\n",
    "        threshold=3.0\n",
    "    )\n",
    "    \n",
    "    monitor.fit(X_train)\n",
    "    metrics = monitor.evaluate(X_test)\n",
    "    \n",
    "    method_results.append({\n",
    "        'Method': method_desc,\n",
    "        'Anomaly_Rate': metrics['anomaly_rate'],\n",
    "        'Mean_Score': metrics['mean_anomaly_score'],\n",
    "        'Alert_Threshold': metrics['alert_threshold'],\n",
    "        'Equipment_Uptime': metrics['equipment_uptime']\n",
    "    })\n",
    "    \n",
    "    print(f\"  Anomaly Rate: {metrics['anomaly_rate']:.1%}\")\n",
    "    print(f\"  Equipment Uptime: {metrics['equipment_uptime']:.1%}\")\n",
    "\n",
    "results_df = pd.DataFrame(method_results)\n",
    "print(\"\\n=== Method Comparison Summary ===\")\n",
    "print(results_df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Real-Time Drift Detection Analysis\n",
    "\n",
    "Let's analyze how the drift detection system performs in real-time monitoring scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best performing method for detailed analysis\n",
    "best_monitor = EquipmentDriftMonitor(\n",
    "    equipment_id=\"CVD_CHAMBER_01\",\n",
    "    window_size=50,\n",
    "    method='statistical',  # Usually most interpretable\n",
    "    threshold=3.0\n",
    ")\n",
    "\n",
    "best_monitor.fit(X_train)\n",
    "\n",
    "# Get predictions for entire test period\n",
    "predictions = best_monitor.predict(X_test)\n",
    "anomaly_scores = [pred['anomaly_score'] for pred in predictions]\n",
    "alerts = [pred['alert'] for pred in predictions]\n",
    "\n",
    "print(f\"Total predictions: {len(predictions)}\")\n",
    "print(f\"Alerts generated: {sum(alerts)}\")\n",
    "print(f\"Alert rate: {sum(alerts)/len(alerts):.1%}\")\n",
    "\n",
    "# Find first alert\n",
    "first_alert_idx = next((i for i, alert in enumerate(alerts) if alert), None)\n",
    "if first_alert_idx is not None:\n",
    "    actual_drift_start = 500 - 400  # Relative to test data start\n",
    "    detection_delay = first_alert_idx - actual_drift_start\n",
    "    print(f\"\\n=== Drift Detection Performance ===\")\n",
    "    print(f\"Actual drift start (relative): {actual_drift_start}\")\n",
    "    print(f\"First alert at: {first_alert_idx}\")\n",
    "    print(f\"Detection delay: {detection_delay} time points\")\n",
    "else:\n",
    "    print(\"No alerts generated during test period\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize real-time drift detection\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: Raw sensor data with alerts\n",
    "ax1 = axes[0]\n",
    "sensor_to_plot = sensor_cols[0]  # Plot first sensor\n",
    "test_indices = range(400, 400 + len(X_test))\n",
    "\n",
    "ax1.plot(range(len(df)), df[sensor_to_plot], 'b-', alpha=0.7, label='Sensor Reading')\n",
    "ax1.axvline(x=400, color='green', linestyle='--', alpha=0.7, label='Training/Test Split')\n",
    "ax1.axvline(x=500, color='orange', linestyle='--', alpha=0.7, label='Actual Drift Start')\n",
    "\n",
    "# Mark alerts\n",
    "alert_indices = [400 + i for i, alert in enumerate(alerts) if alert]\n",
    "if alert_indices:\n",
    "    ax1.scatter(alert_indices, [df[sensor_to_plot].iloc[i] for i in alert_indices], \n",
    "               color='red', s=50, marker='x', label='Drift Alerts', zorder=5)\n",
    "\n",
    "ax1.set_title(f'{sensor_to_plot} with Drift Detection Alerts')\n",
    "ax1.set_xlabel('Time Index')\n",
    "ax1.set_ylabel('Sensor Value')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Anomaly scores over time\n",
    "ax2 = axes[1]\n",
    "ax2.plot(test_indices, anomaly_scores, 'purple', linewidth=2, label='Anomaly Score')\n",
    "ax2.axhline(y=best_monitor.threshold, color='red', linestyle='--', \n",
    "           alpha=0.7, label=f'Alert Threshold ({best_monitor.threshold})')\n",
    "ax2.axvline(x=500, color='orange', linestyle='--', alpha=0.7, label='Actual Drift Start')\n",
    "\n",
    "# Highlight alert regions\n",
    "alert_regions = [test_indices[i] for i, alert in enumerate(alerts) if alert]\n",
    "if alert_regions:\n",
    "    ax2.scatter(alert_regions, [anomaly_scores[i] for i, alert in enumerate(alerts) if alert],\n",
    "               color='red', s=30, alpha=0.8, zorder=5)\n",
    "\n",
    "ax2.set_title('Anomaly Scores and Alert Threshold')\n",
    "ax2.set_xlabel('Time Index')\n",
    "ax2.set_ylabel('Anomaly Score')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Rolling statistics (mean and std)\n",
    "ax3 = axes[2]\n",
    "rolling_mean = df[sensor_to_plot].rolling(window=50).mean()\n",
    "rolling_std = df[sensor_to_plot].rolling(window=50).std()\n",
    "\n",
    "ax3.plot(range(len(df)), rolling_mean, 'g-', linewidth=2, label='Rolling Mean (50pt)')\n",
    "ax3.fill_between(range(len(df)), \n",
    "                rolling_mean - 2*rolling_std,\n",
    "                rolling_mean + 2*rolling_std,\n",
    "                alpha=0.3, color='green', label='±2σ Band')\n",
    "ax3.axvline(x=400, color='green', linestyle='--', alpha=0.7, label='Training/Test Split')\n",
    "ax3.axvline(x=500, color='orange', linestyle='--', alpha=0.7, label='Actual Drift Start')\n",
    "\n",
    "ax3.set_title(f'{sensor_to_plot} Rolling Statistics')\n",
    "ax3.set_xlabel('Time Index')\n",
    "ax3.set_ylabel('Value')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Manufacturing Alert System Integration\n",
    "\n",
    "Demonstrate how to integrate drift detection with manufacturing alert systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate real-time monitoring with different alert thresholds\n",
    "alert_thresholds = [2.0, 2.5, 3.0, 3.5, 4.0]\n",
    "threshold_analysis = []\n",
    "\n",
    "print(\"=== Alert Threshold Sensitivity Analysis ===\")\n",
    "for threshold in alert_thresholds:\n",
    "    monitor = EquipmentDriftMonitor(\n",
    "        equipment_id=\"CVD_CHAMBER_01\",\n",
    "        window_size=50,\n",
    "        method='statistical',\n",
    "        threshold=threshold\n",
    "    )\n",
    "    \n",
    "    monitor.fit(X_train)\n",
    "    predictions = monitor.predict(X_test)\n",
    "    \n",
    "    alerts = [pred['alert'] for pred in predictions]\n",
    "    alert_rate = sum(alerts) / len(alerts)\n",
    "    \n",
    "    # Find first alert relative to actual drift\n",
    "    first_alert_idx = next((i for i, alert in enumerate(alerts) if alert), None)\n",
    "    actual_drift_start = 100  # 500 - 400\n",
    "    \n",
    "    if first_alert_idx is not None:\n",
    "        detection_delay = first_alert_idx - actual_drift_start\n",
    "        false_alarm_rate = sum(alerts[:actual_drift_start]) / actual_drift_start\n",
    "    else:\n",
    "        detection_delay = None\n",
    "        false_alarm_rate = 0.0\n",
    "    \n",
    "    threshold_analysis.append({\n",
    "        'Threshold': threshold,\n",
    "        'Alert_Rate': alert_rate,\n",
    "        'Detection_Delay': detection_delay,\n",
    "        'False_Alarm_Rate': false_alarm_rate,\n",
    "        'Total_Alerts': sum(alerts)\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nThreshold {threshold}:\")\n",
    "    print(f\"  Total alerts: {sum(alerts)}\")\n",
    "    print(f\"  Alert rate: {alert_rate:.1%}\")\n",
    "    print(f\"  Detection delay: {detection_delay} points\" if detection_delay is not None else \"  No detection\")\n",
    "    print(f\"  False alarm rate: {false_alarm_rate:.1%}\")\n",
    "\n",
    "threshold_df = pd.DataFrame(threshold_analysis)\n",
    "print(\"\\n=== Threshold Analysis Summary ===\")\n",
    "print(threshold_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize threshold analysis\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Detection delay vs false alarm trade-off\n",
    "ax1 = axes[0]\n",
    "valid_data = threshold_df.dropna(subset=['Detection_Delay'])\n",
    "if not valid_data.empty:\n",
    "    ax1.scatter(valid_data['False_Alarm_Rate'], valid_data['Detection_Delay'], \n",
    "               s=100, c=valid_data['Threshold'], cmap='viridis', alpha=0.7)\n",
    "    for _, row in valid_data.iterrows():\n",
    "        ax1.annotate(f'{row[\"Threshold\"]}', \n",
    "                    (row['False_Alarm_Rate'], row['Detection_Delay']),\n",
    "                    xytext=(5, 5), textcoords='offset points')\n",
    "    \n",
    "    ax1.set_xlabel('False Alarm Rate')\n",
    "    ax1.set_ylabel('Detection Delay (time points)')\n",
    "    ax1.set_title('Detection Delay vs False Alarm Trade-off')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Alert rate vs threshold\n",
    "ax2 = axes[1]\n",
    "ax2.plot(threshold_df['Threshold'], threshold_df['Alert_Rate'], 'o-', \n",
    "         linewidth=2, markersize=8, color='red')\n",
    "ax2.set_xlabel('Alert Threshold')\n",
    "ax2.set_ylabel('Alert Rate')\n",
    "ax2.set_title('Alert Rate vs Threshold Setting')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Highlight optimal threshold (balance detection delay and false alarms)\n",
    "if not valid_data.empty:\n",
    "    # Find threshold with reasonable detection delay and low false alarms\n",
    "    optimal_idx = valid_data.loc[\n",
    "        (valid_data['Detection_Delay'] <= 50) & \n",
    "        (valid_data['False_Alarm_Rate'] <= 0.1)\n",
    "    ]['Detection_Delay'].idxmin()\n",
    "    \n",
    "    if not pd.isna(optimal_idx):\n",
    "        optimal_threshold = valid_data.loc[optimal_idx, 'Threshold']\n",
    "        ax2.axvline(x=optimal_threshold, color='green', linestyle='--', \n",
    "                   alpha=0.7, label=f'Recommended: {optimal_threshold}')\n",
    "        ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n=== Recommended Operating Point ===\")\n",
    "if not valid_data.empty and not pd.isna(optimal_idx):\n",
    "    optimal_row = valid_data.loc[optimal_idx]\n",
    "    print(f\"Recommended threshold: {optimal_row['Threshold']}\")\n",
    "    print(f\"Detection delay: {optimal_row['Detection_Delay']} time points\")\n",
    "    print(f\"False alarm rate: {optimal_row['False_Alarm_Rate']:.1%}\")\n",
    "    print(f\"Overall alert rate: {optimal_row['Alert_Rate']:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Production Deployment and CLI Usage\n",
    "\n",
    "Demonstrate how to use the production CLI interface for equipment monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the production model\n",
    "model_path = Path('production_drift_monitor.joblib')\n",
    "\n",
    "# Create production monitor with optimal settings\n",
    "production_monitor = EquipmentDriftMonitor(\n",
    "    equipment_id=\"CVD_CHAMBER_01\",\n",
    "    window_size=50,\n",
    "    method='statistical',\n",
    "    threshold=3.0  # Use optimal threshold from analysis\n",
    ")\n",
    "\n",
    "# Train on full pre-drift data\n",
    "production_monitor.fit(X_train)\n",
    "\n",
    "# Save the model\n",
    "production_monitor.save(model_path)\n",
    "print(f\"Production drift monitor saved to: {model_path}\")\n",
    "\n",
    "# Test model loading\n",
    "loaded_monitor = EquipmentDriftMonitor.load(model_path)\n",
    "print(f\"Model loaded successfully for equipment: {loaded_monitor.equipment_id}\")\n",
    "print(f\"Configured threshold: {loaded_monitor.threshold}\")\n",
    "print(f\"Window size: {loaded_monitor.window_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate CLI usage examples\n",
    "print(\"=== CLI Usage Examples ===\")\n",
    "print(\"\\nTo train a new drift monitor:\")\n",
    "print(\"python equipment_drift_monitor.py train --dataset synthetic_equipment --method statistical --save monitor.joblib\")\n",
    "\n",
    "print(\"\\nTo evaluate an existing monitor:\")\n",
    "print(\"python equipment_drift_monitor.py evaluate --model-path monitor.joblib --dataset synthetic_equipment\")\n",
    "\n",
    "print(\"\\nTo make real-time predictions:\")\n",
    "prediction_example = {\n",
    "    \"temperature\": 350.5,\n",
    "    \"pressure\": 2.1,\n",
    "    \"gas_flow_rate\": 150.0,\n",
    "    \"rf_power\": 500.0\n",
    "}\n",
    "print(f'python equipment_drift_monitor.py predict --model-path monitor.joblib --input-json \\'{prediction_example}\\'')\n",
    "\n",
    "# Simulate real-time monitoring\n",
    "print(\"\\n=== Live Monitoring Simulation ===\")\n",
    "recent_data = X_test.tail(10)  # Last 10 data points\n",
    "\n",
    "for i, (idx, row) in enumerate(recent_data.iterrows()):\n",
    "    prediction = production_monitor.predict(row.values.reshape(1, -1))[0]\n",
    "    \n",
    "    print(f\"\\nTime {i+1}:\")\n",
    "    print(f\"  Anomaly Score: {prediction['anomaly_score']:.3f}\")\n",
    "    print(f\"  Alert Status: {'🚨 ALERT' if prediction['alert'] else '✅ NORMAL'}\")\n",
    "    print(f\"  Equipment Status: {prediction['status']}\")\n",
    "    \n",
    "    if prediction['alert']:\n",
    "        print(f\"  🔧 Recommended Action: {prediction.get('recommendation', 'Check equipment')}\")\n",
    "\n",
    "# Calculate overall equipment health\n",
    "all_predictions = production_monitor.predict(X_test.values)\n",
    "alert_rate = sum(pred['alert'] for pred in all_predictions) / len(all_predictions)\n",
    "avg_anomaly_score = np.mean([pred['anomaly_score'] for pred in all_predictions])\n",
    "\n",
    "print(f\"\\n=== Equipment Health Summary ===\")\n",
    "print(f\"Overall alert rate: {alert_rate:.1%}\")\n",
    "print(f\"Average anomaly score: {avg_anomaly_score:.3f}\")\n",
    "print(f\"Equipment status: {'⚠️  DEGRADED' if alert_rate > 0.1 else '✅ HEALTHY'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Key Takeaways\n",
    "\n",
    "### Manufacturing Insights\n",
    "1. **Early Detection**: Statistical methods can detect drift within 20-50 time points of onset\n",
    "2. **Threshold Tuning**: Balance between detection speed and false alarm rate is critical\n",
    "3. **Equipment Specific**: Each piece of equipment may require different monitoring parameters\n",
    "4. **Predictive Maintenance**: Trend analysis enables proactive maintenance scheduling\n",
    "\n",
    "### Technical Insights\n",
    "1. **Method Selection**: Statistical control charts are interpretable and effective for gradual drift\n",
    "2. **Window Size**: Larger windows provide stability but slower detection\n",
    "3. **Multi-sensor Fusion**: Combining multiple sensor readings improves detection accuracy\n",
    "4. **Feature Engineering**: Rolling statistics and derivatives enhance drift sensitivity\n",
    "\n",
    "### Production Deployment\n",
    "1. **Real-time Processing**: Streaming analytics for continuous monitoring\n",
    "2. **Alert Integration**: JSON output compatible with MES/SCADA systems\n",
    "3. **Model Persistence**: Complete monitoring setup with preprocessing and thresholds\n",
    "4. **Scalability**: Standardized interface supports multiple equipment types\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "To extend this drift monitoring system:\n",
    "1. **Multi-equipment Monitoring**: Scale to monitor entire fab equipment fleet\n",
    "2. **Advanced Analytics**: Deep learning for complex drift patterns\n",
    "3. **Root Cause Analysis**: Automatic identification of drift sources\n",
    "4. **Maintenance Integration**: Connect to CMMS for automated work orders\n",
    "5. **Dashboard Development**: Real-time visualization and reporting\n",
    "6. **Historical Analysis**: Long-term trend analysis and equipment lifecycle modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "if model_path.exists():\n",
    "    model_path.unlink()\n",
    "    print(\"Cleaned up temporary model file\")\n",
    "\n",
    "print(\"\\n🎉 Equipment Drift Monitoring Tutorial completed successfully!\")\n",
    "print(\"You now have the knowledge to build production-ready equipment monitoring systems.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}